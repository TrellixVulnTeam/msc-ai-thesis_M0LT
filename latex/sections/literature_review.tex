% \len{TODO - Add a brief general introduction to the chapter here. See Sandro's comment. E.g:}

\textit{This chapter is a two-part literature review. The first section, Background or Section \ref{sec:background}, provides an overview of this thesis' central problem of controllable dialogue generation, and the components involved, i.e., dialogue, (controllable) language generation, dialogue response generation, and age modeling. In the second section, Related work or Section \ref{sec:related_work}, I discuss previous approaches, relevant to my work, that have been proposed to tackle each of these components, either separately or jointly. Approaches to different, but strongly related, problems, like text style transfer, are also described in Section \ref{sec:related_work}.} 

\section{Background}
\label{sec:background}

% \textit{What is the relevant theoretical background material to cover?}
% \begin{itemize}
%     \item Language modelling.
%     \item (Controllable) Text Generation.
%     \item GPT-x.
%     \item Transformers.
%     \item Dialogue Modelling.
%     \begin{itemize}
%         \item Adaptive dialogue systems.
%     \end{itemize}
%     \item Age and language.
%     \begin{itemize}
%         \item The theoretical relationship between age and language.
%         \item Age(-group) detection from text.
%     \end{itemize}
% \end{itemize}

% \textit{Writing goals of this subsection:}
% \begin{itemize}
%     \item Position my research (i.e., dialogue response generation that is adaptive to age-groups) in its relevant background.
%     \item Explain concepts that must be understood to grasp my research topic (i.e., give theoretical background information for the rest of your thesis).
% \end{itemize}

\len{Keep in mind the following distinction between Background and Related Work - The Background section should give
an overview of the problem and the components involved: dialogue,
language generation, dialogue response generation, age modelling, etc.,
without focusing on one or the other approach — in Related Work, you
describe approaches that have been proposed to tackle each of these
components, separately or jointly, and which are related or relevant to
your own work for some reason}


% \len{Comment by Sandro - \textit{This intro needs to be more explicitly connected to your work. I would recap once more what you are after (“We focus on controllable generation, i.e. … and apply it to dialogue … This naturally involves having a model for language generation that can be controlled to … In what follows, we introduce the crucial concepts behind this: models for language generation, methods to control the output … dialogue … ”}}

We focus on controllable language generation, i.e., endowing automatically produced text with certain desired linguistic characteristics, and apply it to dialogue. This naturally involves having a model for language generation that can be controlled to write texts passages with different linguistic styles. In what follows, we introduce the crucial concepts behind this: models for language generation, methods to control the output, dialogue, and age modeling.

\len{isn't this redundant, given the chapter's introduction?}

\subsection{Language Models}

Generally speaking, language modeling is central to many NLP tasks. A language model (LM) is a probability distribution over words in a sentence or document. Language models are trained to predict the probability of the next word in an sentence, given the preceding sequence of words. The language modeling task is formulated as an unsupervised distribution estimation problem of datapoints $\{\textbf{x}_1, ..., \textbf{x}_N\}$ (e.g., documents), each representing sequences (of e.g., symbols or tokens) of varying lengths $(s_{i, 1}, ..., s_{i, n}), i \in \{1, ..., N\}$. Note that $N$ denotes the corpus size, and $n$ the sequence length of datapoint $i$. To avoid cluttered notation, the subscript $i$ will sometimes be omitted when discussing an arbitrary datapoint. The probability distribution over an observation $\textbf{x}$  (i.e., the joint probability of an ordered sequence) can then be factorized as the product of its constituent conditionals \citep{radford2019language}:

\begin{equation}
    p(\textbf{x}) = \prod_{j = 1}^n  p(s_j | s_1, ..., s_{j - 1}).
\end{equation}

This formulation allows language models to detect and learn patterns in language. The learned representations of these patterns can then be used for a plethora of applications, such as classification, and text generation. Moreover, this results in a framework for tractable sampling from the unconditional language model $p(\textbf{x})$. $p(\textbf{x})$ can therefore be seen as a base generative model that can generate sample sentences \citep{dathathri2019plug}.

In recent years, the attention-based models, Transformers \citep{vaswani2017attention}, have replaced recurrent neural networks (RNNs) as the dominant architecture for LMs, with major improvements in distribution estimation, long-range dependency handling, sample diversity, and parallel processing. Another recent development in language modeling is that of pre-training LMs on massive corpora. So-called large-scale general purpose LMs have demonstrated significant improvements in downstream tasks, i.e., other NLP tasks for which the model was not specifically trained or fine-tuned. Most famously the OpenAI's series of Generative Pre-trained Transformer (GPT) models have improved numerous NLP benchmarks \citep{radford2018improving,radford2019language, brown2020language}. 



% \begin{itemize}
%     \item What are language models? / What is language modelling?
%     \item Why is it important for many NLP tasks?
%     \item How is it typically formulated or approached (very brief mathematical explanation)?
%     \item Why is it important (to understand this) for my research?
%     \begin{itemize}
%         \item Tractable sampling from the joint $\rightarrow$ (text) generation.
%     \end{itemize}
%     \item Introduce pre-trained language models.
%     \item Briefly introduce the Transformer (but not in too much technical detail, as it could be necessary to explain it in Methods).
%     \item Same for GPT-2.
% \end{itemize}

\subsection{(Controllable) Text Generation}

% \begin{itemize}
%     \item Describe the text generation task.
%     \item What is controllability in text generation? Why is it challenging?
%     \item One of the main challenges in CTG using large-scale LMs is the cost of fine-tuning. Expand on this. How can this be solved?
% \end{itemize}

In text generation, a language model $p(\textbf{x})$ is asked to produce text $\textbf{x}$ given a prompt by sampling from the distribution of words that are assigned the highest likelihood of following the primer text. Text generation in itself is the task of generating a piece of text given an input text. This process can be seen as sampling from a conditional distribution. Controllable text generation refers to the more restrictive problem of enforcing higher-level linguistic features on the generated text during sampling. This can be seen as a sub-problem of vanilla text generation, because the conditioning factor for the output text is further constrained to also include some predefined textual attribute. This attribute represents a linguistic characteristic of the text, like sentiment, topic, or writing style. 

% \begin{itemize}
%     \item base language model $p(\textbf{x})$
%     \item attribute model $p(a | \textbf{x})$
%     \item CTG model $p(\textbf{x} | a ) \propto p(a | \textbf{x})p(\textbf{x})$
% \end{itemize}

Controllable text generation or CTG is a more challenging problem than vanilla text generation for a number of reasons. First, defining the desired attribute to be controlled for in a manner that it is intelligible for a machine is a challenge in itself. Second, like many NLP problems, there are not many parallel corpora. In the context of controllable generation, parallel corpora are datasets of target and source texts that only differ with respect to some attribute. Furthermore, the measure of attribute adherence is a very vague and ambiguous concept. Namely, a text can be written in an extremely positive sentiment in multiple formulations, all of which adhere to the positive sentiment. Another important hurdle for controllable text generation, especially when CTG is combined to leverage the linguistic power of large-scale language models, is that the cost of fine-tuning or pre-training a model to control for a linguistic attribute can be very high. 

%=================================================================================
%%%%%%% THE FOLLOWING PARAGRAPH HAS BEEN MOVED TO THE RELATED WORK SECTION %%%%%%%
% PPLM \citep{dathathri2019plug} is an example of a recent work whose primary focus is to leverage powerful large-scale language models and making them controllable for a wide variety of linguistic attributes, while avoiding incurring significant costs of fine-tuning. Nevertheless avoiding these costs is anything but trivial. The plug and play set up of the PPLM model forms one of the main theoretical foundations of this work. It is both logical and promising for every day engineers to be able to leverage the grammatical fluency of pre-trained language models for more specific downstream tasks, e.g., specifying linguistic characteristic to enforce on an automatically written text. Their setup consists of a symbiosis of GPT-2 as their powerful large-scale language model, and a significantly smaller and therefore easier to train and fine-tune attribute model. This attribute model is often a small classifier, and can range in complexity from a simple bag of words model with a logistic classifier to a more complicated transformer encoder head. The main benefit of this setup is the extensibility it brings with it. Namely, such large-scale language models are open-source and available online and can be tailored to their specific needs using a significantly easier to train attribute model of your own liking. \cite{dathathri2019plug} demonstrate the applicability of their model on a wide variety of tasks ranging from text style transfer to language detoxification (all of which can be seen as sub-problems of controllable text generation). Other real-world applications include: being able to automatically re-write or adjust a draft text for an editorial, automatic generation of brand specific vacancy ads, or personalized chatbot assistance or even personalized education. What this work also provides is a starting point for new applications, namely controllable dialogue generation.
%=================================================================================

% \paragraph{Transformers}

% The transformer architecture in recent years has dominated numerous NLP tasks and has for the basis for many of the state of the art architecture is in natural language processing. Its masked self-attention and compatibility with parallel processing have made it both effective and handling long-range dependencies in texts, as well attractive in terms of training time. This ability to handle long-range dependencies is exploited in particular in the domain of pretraining large language models. Namely this allows for transformer models to be pre-trained by applying language modelling objectives to long stretches of texts that contain longer range dependencies compared to e.g. tweets or short reviews. 

% The transformer architecture mainly consists of a encoder and decoder structure. Where the encoder processes the embedded text inputs and produces a hidden state using self attention mechanisms and fully connected layers. This hidden state is then passed to the decoder layer which Produces an output which contains a distribution over the vocabulary and can be used for next word prediction.

% \paragraph{GPT}

% Following the success of open AI's pre-trained transformer model they went on to produce a series of generative pre-train transformers that I have been trained in a unsupervised language modelling session.

\subsection{Dialogue}

% \len{TODO - Add a sub-section here about dialogue (also think of a better title for the sub-section). This is necessary because dialogue is the main focus of your thesis. So before you discuss dialogue response generation (which is the NLP-operationalization of dialogue), formally introduce the concept of dialogue. What is it? What does it look like? How is it different from discourse? Provide some examples like we did in the paper-submission.}

% \len{See Sandro's suggestions for this subsection.}


% Contents: 
% \begin{itemize}
%     \item introduce what is dialogue, 
%     \item what it looks like, 
%     \item how it differs from discourse, etc. 
%     \item Some examples would also be useful. (maybe from the BNC?)
% \end{itemize}

Dialogue can be described as a written or spoken conversational exchange between two or more interlocutors. Generally speaking, its purpose is to exchange information or build relationships between interlocutors. A dialogue typically consists of interlocutors exchanging utterances in turns. 

\len{\textbf{TODO} - Give an example of a dialogue snippet (from the BNC)}

Dialogue distinguishes itself from discourse in that it necessarily involves two or more participants exchanging information and contributing to the conversation, whereas discourse can be a one-way exchange of information, like a lecture or blog-post.

The NLP operationalization of dialogue, dialogue generation, is a fundamental component for real-world virtual assistants such as Siri and Alexa. It is the task of automatically generate a response given a prompt by the user.

Computational dialogue modeling distinguishes itself from most NLP domains due to the challenges associated with modeling human conversation: informal, noisy, unstructured, and even erroneous real-world responses, possibly competing goals of interlocutors, or an inherently more diverse set of acceptable responses.


\subsection{Dialogue response generation}
Text generation is suitable to tackle tasks such as machine translation, abstractive summarization, and paraphrasing. Dialogue response generation is also a special case of language generation. It can be seen as language generation where the prompt is a turn in a dialogue session. Conversational response generation shares open-domain text generation's overarching objective of producing grammatically correct fluent text, while remaining relevant to the prompt. 
% However, computational dialogue modeling distinguishes itself from most NLP domains due to the challenges associated with modeling human conversation: informal, noisy, unstructured, and even erroneous real-world responses, possibly competing goals of interlocutors, or an inherently more diverse set of acceptable responses. \len{Comment by SF about the previous sentence: \textit{all these aspects could be introduced/described in this subsection about (human) dialogue}}

%%%%%% THE FOLLOWING PARAGRAPH HAS BEEN MOVED TO THE METHODOLOGY. FROM HERE ..... %%%%%%%%%
% \len{Consider moving the following paragraph to the methodology. FROM HERE...}

% Despite these differences, conversational response generation can be modeled in similar ways to open-domain text generation. \cite{zeng-etal-2020-meddialog} suggest to either formulate it in terms of source-target pairs, much like neural machine translation, or as a language modeling objective, where the next token or utterance is conditioned on the dialogue history. To remain close to the training objectives of my baseline models (GPT-2 \citep{radford2019language} and DialoGPT \citep{zhang2019dialogpt}) I choose to adopt the language modeling formulation for conversation modeling. I.e., concatenate all dialogue turns in a multi-turn dialogue session into a long text: $x_1, ..., x_N$. Denote the source sentence or dialogue history as $S = x_1, ..., x_m$ and the target sentence (ground truth response) as $T = x_{m + 1}, ..., x_N$. The conditional probability of dialogue continuation given its history $P(T | S)$ can be written as

% \begin{equation}
%     p(T | S) = \prod_{n = m + 1}^N p(x_n | x_1, ..., x_{n - 1}).
% \end{equation}

% A multi-turn dialogue session $T_1, ..., T_K$ can be written as $p(T_K, ..., T_2 | T_1)$ which is essentially the product of all source-target pairs probabilities $p(T_i | T_1, ..., T_{i - 1})$. This formulation also shows that optimising the single objective $p(T_K, ..., T_2 | T_1)$ is equivalent to optimising all source-target pair probabilities.


% % \begin{itemize}
% %     \item What is (computational) dialogue modeling?
% %     \item What do we aim to understand with CDM?
% %     \item How is (controllable) text generation related to CDM?
% %     \item Is dialogue generation ``simply'' a special case of text generation? If so, explain what are the conditions that constitute this special case.
% % \end{itemize}


% \len{...TO HERE.}
%%%%%%%%%%%%%%%% ...TO HERE

\subsection{Controllable dialogue generation}

% \len{Sandro suggests to move the entire following subsection to the Related Work section. See comment. FROM HERE...}

Endowing a dialogue system with personality traits to generate human-like conversation is a long-standing goal in AI. This objective is difficult to reach because of the challenge of representing personality traits via language expression and the lack of large-scale persona-labeled dialogue datasets. Assuming an encoder-decoder setup, most personalized neural conversation models can be classified as one of two types: implicit and explicit personalisation models \citep{zheng2019personalized}. For implicit personalization models, each speaker has its own vector representation, which implicitly captures the speaking style of the speaker in the decoding process. These models enjoy the benefit of having a more granular and realistic representation of speaking style, as opposed to a simple discrete set of traits (as is the case for explicit personalization models). On the other hand, it is unclear how speaker style is captured and should be interpreted, as all the information about a speaker's style is encoded in a real-valued vector. Furthermore, these methods suffer from a data sparsity issue, because each dialogue should be tagged with a speaker identifier and there should be sufficient dialogues from each trait-group to train a reliable trait-adaptive model. 
% \len{This should be in the related work. See comment.} 
% This last drawback is a bigger hurdle for the method proposed by \cite{zheng2019personalized} than it is for mine, as their work deals with personalization for intersections of multiple traits, whereas this thesis focuses on adaptation to a small number of age groups.

When generating responses, \textit{explicit} personalization models are conditioned either on a given personal profile, text-described persona, or simply an attribute label. That is, speaker traits are represented as key-value pairs or descriptions about age, gender, etc. This can be seen as conditioning the decoder's output on an attribute $a$. Speakers with same set of personality traits can share attribute representations, so it does not require a speaker-specific representation vector. Such structured character descriptions are more explicit, straight-forward, and interpretable. However, explicit personalization models require manually labeled or crowdsourced datasets for development, making it difficult to scale these models to large-scale dialogue datasets.

% \len{...TO HERE}

% \begin{enumerate}
%     \item \textit{Implicit personalization models}
%         \begin{itemize}
%             \item Each speaker has its own vector representation, and this vector is fed into the decoder to capture the speaking style of the speaker implicitly.
%             \item \textbf{Pros}: more granular and realistic representation of speaking style, as opposed to a simple discrete set of traits.
%             \item \textbf{Cons}: (1) It is unclear how personality is captured and how it can be interpreted as all the information about a speaker's style is encoded in a real-valued vector. (2) These methods suffer from a data sparsity issue: each dialogue should be tagged with a speaker identifier and there should be sufficient dialogues from each speaker to train a reliable user-specific model.
%         \end{itemize}
%     \item \textit{Explicit personalisation models}
%         \begin{itemize}
%             \item The generated responses are conditioned either on a given personal profile or a text-described persona. I.e., personality is represented via key-value pairs or natural language descriptions about age, gender, etc. So this can be seen as conditioning the decoder's output on an attribute $a$, which represents one of the descriptions in the previous two sentences.
%             \item \textbf{Pros:} (1) The persona of a speaker can be viewed as a composite of diversified personality traits, suggesting that this approach is a sensible approximation of reality. (2) Data sparsity problem is solved. Speakers with same set of personality traits can share attribute representations. So it does not require a speaker-specific representation vector. (3) Such structured personality descriptions are more explicit, straight-forward, and interpretable.
%             \item \textbf{Cons:} (1) These methods are limited to either manually-labelled data or crowdsourced dialogues, and thereby not scalable to large-scale dialogue datasets.
%         \end{itemize}
% \end{enumerate}

\subsection{Language and age}
The relationship between a person's age and use of language is a thoroughly studied subject with a decades long history and inherent challenges \citep{pennebaker2003words, nguyen2014gender, zheng2019personalized}. A number factors like community membership (e.g., gender, socioeconomic status, or political affiliation), experimental condition (e.g., emotional versus non-emotional disclosure), mode of disclosure (writing versus talking), and other confounding variables complicate the study of age's relation to language \citep{nguyen-etal-2011-author}. The relatively recent advent of widely available computational resources and vast amounts of textual data made it possible to leverage machine learning methods to help detect patterns in language that eluded conventional sociolinguistic research. Early computational investigations into the connection between a person's age and use of language is typically a combination of qualitative and statistical methods. For instance, using a mix between their proprietary count-based text analysis framework, Linguistic Inquiry and Word Count (LIWC) and sociolinguistic theory, \cite{pennebaker2003words} study the changes in written and spoken language use with increasing age. They discuss four important areas of a person's character that have been found to change with age: emotional experience and expression, identity and social relationships, time orientation, and cognitive abilities. These four axes and their hypothesized relationships with language use and age can be interpreted in the following ways:
\begin{enumerate}
    \item \textit{Emotional experience and expression:} This is the relationship between increasing age and linguistically observable manifestations of a person's experienced emotions. In practical terms, this is framed as detectable instances of positive and negative affect in language. This complex relationship between age and emotional expression is characterized by decreased levels of negative affect and slightly non-decreasing levels of positive affect. This is also confirmed by the findings of \cite{schler2006effects}.
    
    \item \textit{Sense of identity and social relationships:} These terms refer to developmental tends in one's relation to self and others, as expressed in their language, e.g., as references to self (\textit{I, me, my}, and \textit{we, us, our}) or others (\textit{they, them, theirs}). \cite{pennebaker2003words} report that the \textit{quantity} of social connections decreases and the \textit{quality} of remaining relationships increases with age.
    
    \item \textit{Time orientation:} This relationship describes how people express their perception of and orientation towards time. For instance, this can be indicated by the use of time-related verb tenses. The authors suggest that older individuals tend to be more past-oriented than their younger future-oriented counterparts.
    
    \item \textit{Cognitive abilities:} This refers to markers of cognitive capacity in language. Aging is expected to be associated with less use of cognitively complex words after a certain mid-adulthood peak. Specifically, the relationship between markers of cognitive complexity in natural language (cognitive mechanisms, causal insight, and exclusive words) and age is hypothesized to be curvilinear. And because verbal ability does not decline until very late in life, markers of verbal ability (e.g., use of big words) are not expected to show changes with age.
\end{enumerate}

\cite{pennebaker2003words} consider the following variables: positive and negative emotions, first-person singular and first-person plural pronouns, social references, time-related words (past-tense, present-tense, and future-tense verbs), big words ($>6$ letters), cognitive mechanisms, causal insight, and exclusive words. Their main findings suggest that increasing with age, people use more positive and fewer negative affect words, use fewer self-references, use more future-tense and fewer past-tense verbs, and exhibit a general pattern of increasing cognitive complexity.

Detectable linguistic differences between age-groups can often be attributed to the use of language fads or references to age-specific popular culture. For instance, \cite{schler2006effects} find that the use of slang and neologisms (such as \textit{lol} and \textit{ur}) are strong indicators of youth. Similarly, words like `facebook', `instagram', and `netflix' appear in the most frequently used words by younger participants of conversational data collection efforts, like that of the British National Corpus' spoken component \citep{love-spoken-bnc-2014}.

% More recent studies, like that of \cite{nguyen-etal-2011-author}, \cite{zheng2019personalized}, and \cite{abdallah2020age}, frame age prediction from text as traditional machine learning problems, like linear regression, support vector machines, or neural architectures. These modeling approaches tend to reveal that strong indicators of age lie at the syntactic or structural level of language use, as opposed to the more content-based lexical level. Furthermore, this could explain why automatic detection from text of more content-based traits, like topic or sentiment, tend to be easier problems to solve than age prediction from text. To emphasize one such complicating factor, \cite{nguyen2014gender} argue that differences in language use are often relation to the speaker's social identity, which could differ from their biological identity. 
% This idea that age prediction from text is more challenging than topic or sentiment prediction could be an indication that controlled language generation for age-differences is also a more nuanced problem than topical steered text generation.


% \textbf{Keep in mind:}
% \begin{itemize}
%     \item What is known about the relationship between a speaker's (or author's) age and their linguistic characteristics? I.e., how does language use develop with age according to the existing literature?
%     \item How can we automatically detect a speaker's age(-group) from their utterances using machine learning?
%     \item Link findings from the papers you cite to the hypothesis that linguistic differences in age lie more are the phrase/constructional level than at the single word/lexical level. However, is this really the case? \cite{nguyen-etal-2011-author} mention single words like `well', `like`, and `just' being predictive of age.
%     \item Mention that age differences in language could/should also be interpreted as indications of language fads during a person's formative years.
%     \item Hypothesize that age-related linguistic variation is a more subtle and nuanced factor to control for during text generation than, e.g., topic (science, business, religion), or sentiment.
%     \item Mention confounding factors like community membership (like gender, socioeconomic status, or political affiliation), experimental condition (e.g., emotional versus non-emotional disclosure), mode of disclosure (writing versus talking), and other confounding factors that complicate age prediction from language.
% \end{itemize}

\section{Related work}
\label{sec:related_work}

\len{Keep in mind the following distinction between Background and Related Work - The Background section should give
an overview of the problem and the components involved: dialogue,
language generation, dialogue response generation, age modeling, etc.,
without focusing on one or the other approach — in Related Work, you
describe approaches that have been proposed to tackle each of these
components, separately or jointly, and which are related or relevant to
your own work for some reason}

\subsection{Automated age detection}

\len{Consider adding a small sub-section about automated age detection from text, because you often bring up the problem and other researchers' approaches to solving it in the Background section.}

\dots

\len{work this into this subsection. Taken from workshop paper submission}

\textit{Previous work on age detection in dialogue has focused on speech features, which are known to systematically vary across age groups. For example,  \citet{wolters2009age} learn logistic regression age classifiers from a small dialogue dataset %of 448 dialogues 
using different acoustic cues supplemented with a small set of hand-crafted lexical features, while \citet{li2013automatic} develop SVM classifiers using acoustic and prosodic features extracted from scripted utterances spoken by participants interacting with an artificial system. In contrast to this line of work, we investigate whether different age groups can be detected from textual linguistic information rather than voice-related cues. We explore whether, and to what extent, various state-of-the-art NLP models are able to capture such differences in dialogue data as a preliminary step to age-group adaptation by conversational agents.
We build on the work of~\citet{schler2006effects}, who focus on age detection in written discourse using a corpus of blog posts. The authors learn a Multi-Class Real Winnow classifier leveraging a set of pre-determined style- and content-based features, including part-of-speech categories, function words, and the 1000 unigrams with the highest information gain in the training set. They find that content features (lexical unigrams) yield higher accuracy ($\sim$ 74\%) than style features ($\sim$72\%), while their best results are obtained with their combination ($\sim$76\%). 
We extend this investigation in several key ways: (1) we leverage state-of-the-art NLP models that allow us to learn representations end-to-end, without the need to specify concrete features in advance; (2) we apply this approach to dialogue data, using a large-scale dataset of transcribed, spontaneous open-domain dialogues; (3) we show that text-based models can indeed detect age-related differences in both discourse and dialogue, even in the case of very sparse signal at the level of dialogue utterances; and finally (4) we carry out an in-depth analysis of the models' predictions to gain insight on which elements of language use are most informative. }

\dots

More recent studies, like that of \cite{nguyen-etal-2011-author}, \cite{zheng2019personalized}, and \cite{abdallah2020age}, frame age prediction from text as traditional machine learning problems, like linear regression, support vector machines, or neural architectures. These modeling approaches tend to reveal that strong indicators of age lie at the syntactic or structural level of language use, as opposed to the more content-based lexical level. Furthermore, this could explain why automatic detection from text of more content-based traits, like topic or sentiment, tend to be easier problems to solve than age prediction from text. To emphasize one such complicating factor, \cite{nguyen2014gender} argue that differences in language use are often relation to the speaker's social identity, which could differ from their biological identity. 


\subsection{Controllable language generation}
Previous approaches to controlled language generation require fine-tuning large Transformer-based language models or training conditional generative LMs from scratch. Most notably CTRL \citep{keskarCTRL2019}, which achieves controllable generation by training a generative Transformer for a number of control codes. CTG models that require fine-tuning for control, like CTRL, can produce high quality fluent text because they are specifically trained to maximize the likelihood of generated sequences, given an attribute (denoted $p(\textbf{x} | a)$), but require training massive language models with computational costs.

Other recent examples of controllable language generation models that are not Transformer-based also exist. \cite{li-etal-2020-optimus} introduce OPTIMUS, a large pre-trained Variational Autoencoder (VAE) \citep{Kingma2014} that can be fine-tuned for specific natural language tasks, like guided sentence generation. They demonstrate OPTIMUS' ability to perform controlled text generation from latent style-embeddings, with fluency at par with GPT-2. They also show how OPTIMUS generalizes better for low-resource languages than BERT \citep{devlin-etal-2019-bert}. Nevertheless, much like the previously mentioned CTG models, OPTIMUS still incurs a significant computational cost for fine-tuning per NLP task.

% The plug-and-play language model (PPLM) \citep{dathathri2019plug} is a recent approach to leverage powerful large-scale language models and make them controllable for a wide variety of linguistic attributes, while avoiding incurring significant costs of fine-tuning these massive language models. Nevertheless avoiding these costs is anything but trivial. The plug-and-play setup of the PPLM model forms one of the main theoretical foundations of this work. It is both logical and promising for every day engineers to be able to leverage the grammatical fluency of pre-trained language models for more specific downstream tasks, e.g., specifying linguistic characteristic to enforce on an automatically written text. Their setup consists of a symbiosis of GPT-2 as their powerful large-scale language model, and a significantly smaller and therefore easier to train and fine-tune attribute model. This attribute model is often a small classifier, and can range in complexity from a simple bag of words model with a logistic classifier to a more complicated transformer encoder head. The main benefit of this setup is the extensibility it brings with it. Namely, such large-scale language models are open-source and available online and can be tailored to their specific needs using a significantly easier to train attribute model of your own liking. \cite{dathathri2019plug} demonstrate the applicability of their model on a wide variety of tasks ranging from text style transfer to language detoxification (all of which can be seen as sub-problems of controllable text generation). Other real-world applications include: being able to automatically re-write or adjust a draft text for an editorial, automatic generation of brand specific vacancy ads, or personalized chatbot assistance or even personalized education. What this work also provides is a starting point for new applications, namely controllable dialogue generation.

\len{TODO: Where does the following sentence fit best? ``The plug-and-play setup of PPLM forms one of the main theoretical foundations of this work.''}

The plug-and-play language model (PPLM) \citep{dathathri2019plug} is a recent solution to the problem of high re-training costs of controlled language generation. This approach, inspired by a similar technique for style-control of generated images \citep{nguyen2017plug}, leverages the fluency of large-scale language models when controlling them for a specific linguistic attribute, while avoiding incurring significant costs of fine-tuning these massive language models. The main benefit of this setup is its low-cost extensibility. Namely, such large-scale language models are often open-source and available online, and can now be tailored to users' specific needs using a significantly easier to train attribute model. 
The original architecture proposed by \citeauthor{dathathri2019plug} uses GPT-2 as a base language model which provides grammatical fluency, combined with a significantly easier to train attribute model (i.e., a simple BoW or single-layer classifier). Using gradient updates to the activation space of the much smaller attribute model, they manage to generate language that combines (some of) the fluency of GPT-2 with the stylistic control of the attribute model, without the cost of retraining a specialised architecture. They demonstrate that PPLM achieves desirable fluency (i.e., perplexity measured with GPT(-1) \citep{radford2018improving}), as well as measurable attribute control. Their architecture's applicability is also demonstrated on tasks such as controlled story writing and language detoxification. They also show a clear trade-off between attribute control and grammatical correctness and diversity. 

% Recent examples of controllable language generation models that are not Transformer-based also exist. \cite{li-etal-2020-optimus} introduce OPTIMUS, a large pre-trained Variational Autoencoder (VAE) \citep{Kingma2014} that can be fine-tuned for specific natural language tasks, like guided sentence generation. They demonstrate OPTIMUS' ability to perform controlled text generation from latent style embeddings, with fluency at par with GPT-2. They also show how OPTIMUS generalizes better for low-resource languages than BERT \citep{devlin-etal-2019-bert}. Nevertheless, much like the previously mentioned non-plug-and-play CTG models, OPTIMUS still incurs a significant computational cost for fine-tuning per NLP task.

% Dialogue generation is not explored as an original application of PPLM, nor is their tested with more complex attribute models to hopefully allow for less deterioration of fluency as attribute control increases. 



\subsection{Text style transfer}
Text style transfer is the task of changing a text's stylistic properties, while retaining its style-independent properties, like content and fluency \citep{dai2019style}. Text style transfer is a closely related problem to controllable language generation. Its similarity lies in trying to modify the output distribution of a language generation model, such that stylistic characteristics of the produced text are controllable, keeping content and fluency preserved. It involves rewriting an input text with a specific style. More formally, given a text $\textbf{x}$, its corresponding style-representing vector $\textbf{s}^{(i)}$, the number of different styles $K$ over which there exists a distribution, and a desired style $\hat{\textbf{s}} \in \{\textbf{s}^{(i)}\}_{i = 1}^{K}$, the goal of text style transfer is to produce output text $\hat{\textbf{x}}$ with style $\hat{\textbf{s}}$, and the style-independent properties of $\textbf{x}$. 
% Text style transfer can also be seen as a special case of (abstractive) summarization, for which Transformers have also demonstrated applicability \citep{baan-etal-2019-abstractive}.

Previous approaches to text style transfer involve passing input text through an RNN-based encoder, yielding a style-dependent latent representation $\textbf{z}$ \citep{zhang2018styletranslation}. Typically, these approaches then attempt to ``disentangle'' $\textbf{z}$ into a style-independent content representation and a latent representation of the stylistic properties of the input text. The subsequent decoder then receives the content representation and a new latent style variable as input, to ultimately produce a style-altered output text with unchanged content. This style-disentanglement approach has a number of drawbacks: \textbf{(1)} It is difficult to evaluate the quality of disentanglement of the latent space. \textbf{(2)} It is hard to capture rich semantic information in the latent representation due to limited capacity of vector representations (especially for long texts). \textbf{(3)} To disentangle style and content in the latent representations, all previous approaches have to assume all input texts can be encoded by a fixed-size latent vector. \textbf{(4)} Since most previous approaches use RNN-based encoder-decoder frameworks, they have problems capturing long-range dependencies in the input sentences. Furthermore, disentanglement might be unnecessary, as \cite{lample2018multipleattribute} have shown a proper decoder can perform controllable text generation from an entangled latent representation by ``overwriting'' the original style.

% \begin{enumerate}
%     \item It is difficult to evaluate the quality of disentanglement of the latent space.
%     \item Disentanglement is unnecessary, as contemporary work by \cite{lample2018multipleattribute} has shown a good decoder can perform controllable text generation from an entangled latent representation by ``overwriting'' the original style.
%     \item It is hard to capture rich semantic information in the latent representation due to limited capacity of vector representations (especially for long texts).
%     \item To disentangle style and content in the latent representations, all previous approaches have to assume all input texts can be encoded by a fixed-size latent vector.
%     \item Since most previous approaches use RNN-based encoder-decoder frameworks, they have problems capturing long-range dependencies in the input sentences.
% \end{enumerate}

To address these drawbacks, \cite{dai2019style} propose Style Transformer, a Transformer-based alternative encoder-decoder framework for text style transfer. The authors' approach does not require any manipulation (i.e., disentanglement) of the latent space, eliminates the need for a fixed-size vector representation of the input, and handles long-range dependencies better due to Transformers' attention mechanism. Aside from this being the first application of Transformers for text style transfer, \cite{dai2019style} contribute a novel training algorithm for such models, that boasts significant improvements of results on two text style transfer datasets.

\subsection{Dialogue Generation}
Dialogue generation is task of automatically generating a response given a user's prompt. \cite{zhang2019dialogpt} introduce DialoGPT, a tunable large-scale language model for generation of conversational responses, trained on Reddit discussion chain data. DialoGPT therefore extends GPT-2 \citep{radford2019language} to address a more restrictive sub-category of text generation, i.e., conversational response generation. DialoGPT inherits from GPT-2 a 12-to-48 layer transformer with layer normalization, a custom initialization scheme that accounts for model depth, and byte pair encodings \citep{sennrich-etal-2016-neural} as a tokenizer. The generation task remains framed as language modeling, where a multi-turn dialogue session is modeled as a long text. 

To address the well-known problem of open-domain text generation models producing bland and uninformative samples, \cite{zhang2019dialogpt} implement a maximum mutual information (MMI) scoring function. MMI uses a pre-trained backward model to predict $p(\texttt{source} | \texttt{target})$: i.e., the source sentences (dialogue history) given the target (responses, dialogue continuation). First, top-K sampling is used to generate a set of hypotheses. Then the probability $p(\texttt{source} | \texttt{hypothesis})$ is used to re-rank all hypotheses. As frequent and repetitive hypotheses can be associated with many possible queries/sources (i.e., a hypothesis that frequently occurs is one that is apparently applicable to many queries), and maximizing backward model likelihood penalizes repetitive hypotheses, MMI yields a lower probability for highly frequent hypotheses, thereby reducing blandness and promoting diversity. 

DialoGPT is evaluated on the Dialog System Technology Challenge (DSTC) 7 track, an end-to-end conversational modeling task in which the goal is to generate conversation responses that go beyond chitchat by injecting information that is grounded in external knowledge. The model achieves state-of-the-art results on both the human and automatic evaluation results, by achieving near human-like responses that are diverse, relevant to the prompt, much like GPT-2 for open-domain language generation. They train 3 models of small (117M), medium (345M), and large (762M) parameter sizes. The medium-sized 345M model achieves the best automatic evaluation results across most metrics, and is used as one of the baselines in later experiments in this thesis. Their Hugging Face PyTorch implementation can be tested here: \url{https://huggingface.co/microsoft/DialoGPT-medium}.

Dialogue generation is the essential precursor to this thesis' ultimate task of controllable dialogue generation.

\len{The previous sentence feels out of the blue. Consider removing it or think of a way to create a natural flow towards it.}



\subsection{Controlled Dialogue Generation}
Controlled dialogue generation is the task of steering automatically generated conversational responses to possess desired attributes, like sentiment, topic, or more abstract writing style characteristics.
% Nowadays, dialogue systems like Siri, Alexa, or Google Assistant, play large roles making technology easier to use, it is of great commercial interest to be able to control (e.g., personalize) the style of their responses. Medical applications too have been found for controllable dialogue generation.
\cite{zeng-etal-2020-meddialog} explore the applications of fine-tuning large language models, like GPT, on (Mandarin and English) medical consultation data. The resulting dialogue systems succeed at generating clinically correct and human-like responses to patients' medical questions. Medical dialogue systems like these can help make healthcare services more accessible and aid medical doctors to improve patient care.

\cite{zheng2019personalized} investigate the problem of incorporating explicit personal characteristics in dialogue generation to deliver personalized conversation. They introduce a dataset \texttt{PersonalDialog}, which is a large-scale multi-turn dialogue dataset with personality trait labeling (i.e., \texttt{Age}, \texttt{Gender}, \texttt{Location}, \texttt{Interest Tags}, etc.) for a large number of speakers. \cite{zheng2019personalized} also propose persona-aware models that include a trait fusion module in the encoder-decoder framework to capture and address personality traits in dialogue generation. Persona-aware attention mechanisms and bias are used to incorporate personality information in the decoding process. All their tested classification and dialogue generation models are either variations of RNNs (such as LSTMs or gated recurrent units (GRUs)), convolutional neural networks (CNNs), or hybrids of these systems (LSTM-outputs fed into a CNN, known as recurrent convolutional neural networks (RCNNs)). The authors study the influence of age, gender, and location on dialogue classification and generation, and use both automatic (perplexity, trait accuracy, and generated response diversity measures) and human evaluation. They find dialogues to be distinguishable by gender (about 90.61\% test accuracy), then age (78.32\% test accuracy), and finally location (62.04\% test accuracy). Both automatic and human evaluation of the generated responses show that the best performing models benefit greatly from the persona-aware attention mechanism, possibly making a case to consider more attention-based architectures instead of RNNs.

Although the previously mentioned architectures are able to produce human-like conversational responses, sometimes even leveraging the fluency of large pre-trained LMs, they all suffer from the same computational drawback. They all require massive amounts of computational power to adapt their language styles, because in their cases, guided generation implies fine-tuning (or even retraining) large attribute-specific dialogue datasets. For general controlled language generation, this obstacle is overcome by \cite{dathathri2019plug}'s previously mentioned PPLM setup. The conversational analog of this idea, plug-and-play conversational model (PPCM), is proposed by \cite{madotto-etal-2020-plug}. Similar to PPLM, PPCM achieves guided dialogue generation via activation-space perturbations using easy to train attribute models. 
% In this configuration, they can achieve controllable response generation without needing dialogue data or having to fine-tune a large language model. 
Due to the computational complexity of PPLM's decoding process, PPLM is unusable as practical conversational system. PPCM solves this problem by using residual adapters \citep{bapna-firat-2019-simple} to tweak the decoding procedure such that it does not require more computational resources. See Section \ref{sec:ppm} for a detailed explanation of the mechanisms behind PPLM and PPCM. \cite{madotto-etal-2020-plug} show, using both human and automatic evaluation, that PPCM can balance grammatical fluency and high degrees of attribute-adherence in its generated responses. PPCM uses DialoGPT as its base language model, and is tested for topical or sentimental attributes (i.e., positive, negative, sports, business, or science \& tech). 
Previous work on controllable language generation focuses on content (e.g., topical attributes, or sentiment), rather than more abstract linguistic features, which I hypothesize are more challenging to model and control. The previously mentioned work by \cite{zheng2019personalized} is a notable exception, as their approach deals with controlling dialogue systems for linguistic features, like age, gender, and geographical region. However, \cite{zheng2019personalized} still suffers from significant computational costs, because control is achieved by fine-tuning a large system for every specific set of attributes. Furthermore, their proposed architectures are RNN-based, as opposed to my Transformer-based approach. My work therefore aims to extend the applicability of plug-and-play controlled generation to more abstract linguistic characteristics than those explored by \cite{dathathri2019plug} and \cite{madotto-etal-2020-plug}, and without the significant fine-tuning cost of \cite{zheng2019personalized}.

 

\len{TODO \begin{itemize}
    \item Ask for Sandro's feedback on this last rephrased paragraph.
    \item Is it worth mentioning that Zheng et al 2019 deals with Chinese Mandarin dialogue systems, and mine with English?
\end{itemize} }