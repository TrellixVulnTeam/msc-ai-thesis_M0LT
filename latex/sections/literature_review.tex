% \len{TODO - Add a brief general introduction to the chapter here. See Sandro's comment. E.g:}

This chapter is a two-part literature review. The first section, Background or Section \ref{sec:background}, provides an overview of this thesis' central problem of controllable dialogue generation, and the components involved, i.e., 
modeling age in language, language models, controlled text generation, dialogue, dialogue systems, dialogue generation, Transformers, and Plug-and-Play language models. 
In the second section, Related work or Section \ref{sec:related_work}, I discuss previous approaches, relevant to my work, that have been proposed to tackle each of these components, either separately or jointly. Approaches to different, but strongly related, problems, like text style transfer, are also described in Section \ref{sec:related_work}.

\section{Background}
\label{sec:background}

% \textit{What is the relevant theoretical background material to cover?}
% \begin{itemize}
%     \item Language modelling.
%     \item (Controllable) Text Generation.
%     \item GPT-x.
%     \item Transformers.
%     \item Dialogue Modelling.
%     \begin{itemize}
%         \item Adaptive dialogue systems.
%     \end{itemize}
%     \item Age and language.
%     \begin{itemize}
%         \item The theoretical relationship between age and language.
%         \item Age(-group) detection from text.
%     \end{itemize}
% \end{itemize}

% \textit{Writing goals of this subsection:}
% \begin{itemize}
%     \item Position my research (i.e., dialogue response generation that is adaptive to age-groups) in its relevant background.
%     \item Explain concepts that must be understood to grasp my research topic (i.e., give theoretical background information for the rest of your thesis).
% \end{itemize}

% \len{Keep in mind the following distinction between Background and Related Work - The Background section should give an overview of the problem and the components involved: dialogue, language generation, dialogue generation, age modelling, etc., without focusing on one or the other approach — in Related Work, you describe approaches that have been proposed to tackle each of these components, separately or jointly, and which are related or relevant to your own work for some reason}


% \len{Comment by Sandro - \textit{This intro needs to be more explicitly connected to your work. I would recap once more what you are after (“We focus on controllable generation, i.e. … and apply it to dialogue … This naturally involves having a model for language generation that can be controlled to … In what follows, we introduce the crucial concepts behind this: models for language generation, methods to control the output … dialogue … ”}}

% We focus on controlled text generation, i.e., endowing automatically produced text with certain desired linguistic characteristics, and apply it to dialogue. Moreover, we seek to generate dialogue responses that possess linguistic characteristics of certain age groups. This naturally involves having a model for text generation that can be controlled to write texts passages with different age-related linguistic styles. In what follows, we therefore introduce the crucial components involved in developing such models: modeling age in language, language models, controlled text generation, dialogue, dialogue systems, dialogue generation, Transformers, and Plug-and-Play language models.

% \len{isn't this redundant, given the chapter's introduction?}

\subsection{Language and Age}
The relationship between a person's age and use of language is a thoroughly studied subject with a decades long history and inherent challenges \citep{pennebaker2003words, nguyen2014gender, zheng2019personalized}. A number factors like community membership (e.g., gender, socioeconomic status, or political affiliation), experimental condition (e.g., emotional versus non-emotional disclosure), mode of disclosure (writing versus talking), and other confounding variables complicate the study of age's relation to language \citep{nguyen-etal-2011-author}. The relatively recent advent of widely available computational resources and vast amounts of textual data made it possible to leverage machine learning methods to help detect patterns in language that eluded previous conventional sociolinguistic research. Early computational investigations into the connection between a person's age and use of language is typically a combination of qualitative and statistical methods. For instance, using a mix between their proprietary count-based text analysis framework, Linguistic Inquiry and Word Count (LIWC) and sociolinguistic theory, \cite{pennebaker2003words} study the changes in written and spoken language use with increasing age. They discuss four important areas of a person's character that have been found to change with age: emotional experience and expression, identity and social relationships, time orientation, and cognitive abilities. These four axes and their hypothesized relationships with language use and age can be interpreted in the following ways:
\begin{enumerate}
    \item \textit{Emotional experience and expression:} This is the relationship between increasing age and linguistically observable manifestations of a person's experienced emotions. In practical terms, this is framed as detectable instances of positive and negative affect in language. This complex relationship between age and emotional expression is characterized by decreased levels of negative affect and slightly non-decreasing levels of positive affect. This is also confirmed by the findings of \cite{schler2006effects}.
    
    \item \textit{Sense of identity and social relationships:} These terms refer to developmental tends in one's relation to self and others, as expressed in their language, e.g., as references to self (\textit{I, me, my}, and \textit{we, us, our}) or others (\textit{they, them, theirs}). \cite{pennebaker2003words} report that the \textit{quantity} of social connections decreases and the \textit{quality} of remaining relationships increases with age.
    
    \item \textit{Time orientation:} This relationship describes how people express their perception of and orientation towards time. For instance, this can be indicated by the use of time-related verb tenses. The authors suggest that older individuals tend to be more past-oriented than their younger future-oriented counterparts.
    
    \item \textit{Cognitive abilities:} This refers to markers of cognitive capacity in language. Aging is expected to be associated with less use of cognitively complex words after a certain mid-adulthood peak. Specifically, the relationship between markers of cognitive complexity in natural language (cognitive mechanisms, causal insight, and exclusive words) and age is hypothesized to be curvilinear. And because verbal ability does not decline until very late in life, markers of verbal ability (e.g., use of big words) are not expected to show changes with age.
\end{enumerate}

\cite{pennebaker2003words} consider the following variables: positive and negative emotions, first-person singular and first-person plural pronouns, social references, time-related words (past-tense, present-tense, and future-tense verbs), big words ($>6$ letters), cognitive mechanisms, causal insight, and exclusive words. Their main findings suggest that increasing with age, people use more positive and fewer negative affect words, use fewer self-references, use more future-tense and fewer past-tense verbs, and exhibit a general pattern of increasing cognitive complexity.

Detectable linguistic differences between age-groups can often be attributed to the use of language fads or references to age-specific popular culture. For instance, \cite{schler2006effects} find that the use of slang and neologisms (such as \textit{lol} and \textit{ur}) are strong indicators of youth. Similarly, words like `facebook', `instagram', and `netflix' appear in the most frequently used words by younger participants of conversational data collection efforts, like that of the British National Corpus' spoken component \citep{love-spoken-bnc-2014}.

Despite the demonstrated utility of using handcrafted age-related linguistic features for age group detection from text \citep{schler2006effects}, modern approaches leverage statistical language models that represent a probability distribution over sequences of words, often parameterized by neural network architectures \citep{zheng2019personalized}. These approaches based on language models show impressive efficacy for many NLP tasks, and can be trained end-to-end, often not requiring domain-knowledge. The following section provides further details about language models.

% More recent studies, like that of \cite{nguyen-etal-2011-author}, \cite{zheng2019personalized}, and \cite{abdallah2020age}, frame age prediction from text as traditional machine learning problems, like linear regression, support vector machines, or neural architectures. These modeling approaches tend to reveal that strong indicators of age lie at the syntactic or structural level of language use, as opposed to the more content-based lexical level. Furthermore, this could explain why automatic detection from text of more content-based traits, like topic or sentiment, tend to be easier problems to solve than age prediction from text. To emphasize one such complicating factor, \cite{nguyen2014gender} argue that differences in language use are often relation to the speaker's social identity, which could differ from their biological identity. 
% This idea that age prediction from text is more challenging than topic or sentiment prediction could be an indication that controlled language generation for age-differences is also a more nuanced problem than topical steered text generation.


% \textbf{Keep in mind:}
% \begin{itemize}
%     \item What is known about the relationship between a speaker's (or author's) age and their linguistic characteristics? I.e., how does language use develop with age according to the existing literature?
%     \item How can we automatically detect a speaker's age(-group) from their utterances using machine learning?
%     \item Link findings from the papers you cite to the hypothesis that linguistic differences in age lie more are the phrase/constructional level than at the single word/lexical level. However, is this really the case? \cite{nguyen-etal-2011-author} mention single words like `well', `like`, and `just' being predictive of age.
%     \item Mention that age differences in language could/should also be interpreted as indications of language fads during a person's formative years.
%     \item Hypothesize that age-related linguistic variation is a more subtle and nuanced factor to control for during text generation than, e.g., topic (science, business, religion), or sentiment.
%     \item Mention confounding factors like community membership (like gender, socioeconomic status, or political affiliation), experimental condition (e.g., emotional versus non-emotional disclosure), mode of disclosure (writing versus talking), and other confounding factors that complicate age prediction from language.
% \end{itemize}

\subsection{Language Models}

Generally speaking, language modeling is central to many NLP tasks. A language model (LM) is a probability distribution over words in a sentence or document. Language models are trained to predict the probability of the next word in an sentence, given the preceding sequence of words. The language modeling task is formulated as an unsupervised distribution estimation problem of datapoints $\{\textbf{x}_1, ..., \textbf{x}_N\}$ (e.g., documents), each representing sequences (of e.g., symbols or tokens) of varying lengths $(s_{i, 1}, ..., s_{i, n}), i \in \{1, ..., N\}$. Note that $N$ denotes the corpus size, and $n$ the sequence length of datapoint $i$. To avoid cluttered notation, the subscript $i$ will sometimes be omitted when discussing an arbitrary datapoint. The probability distribution over an observation $\textbf{x}$  (i.e., the joint probability of an ordered sequence) can then be factorized as the product of its constituent conditionals \citep{radford2019language}:

\begin{equation}
    p(\textbf{x}) = \prod_{j = 1}^n  p(s_j | s_1, ..., s_{j - 1}).
\end{equation}

This formulation allows language models to detect and learn patterns in language. The learned representations of these patterns can then be used for a plethora of applications, such as classification, and text generation. Moreover, this results in a framework for tractable sampling from the unconditional language model $p(\textbf{x})$. $p(\textbf{x})$ can therefore be seen as a base generative model that can generate sample sentences \citep{dathathri2019plug}.

In recent years, the attention-based models, Transformers \citep{vaswani2017attention}, have replaced recurrent neural networks (RNNs) as the dominant architecture for LMs, with major improvements in distribution estimation, long-range dependency handling, sample diversity, and parallel processing. Another recent development in language modeling is that of pre-training LMs on massive corpora. So-called large-scale general purpose LMs have demonstrated significant improvements in downstream tasks, i.e., other NLP tasks for which the model was not specifically trained or fine-tuned. Most famously the OpenAI's series of Generative Pre-trained Transformer (GPT) models have improved numerous NLP benchmarks \citep{radford2018improving,radford2019language,brown2020language-models-few-shot-gpt3}. In particular, this series of autoregressive language models has demonstrated impressive advancements in the task of text generation, to produce human-like text.



% \begin{itemize}
%     \item What are language models? / What is language modelling?
%     \item Why is it important for many NLP tasks?
%     \item How is it typically formulated or approached (very brief mathematical explanation)?
%     \item Why is it important (to understand this) for my research?
%     \begin{itemize}
%         \item Tractable sampling from the joint $\rightarrow$ (text) generation.
%     \end{itemize}
%     \item Introduce pre-trained language models.
%     \item Briefly introduce the Transformer (but not in too much technical detail, as it could be necessary to explain it in Methods).
%     \item Same for GPT-2.
% \end{itemize}

\subsection{Text Generation and Controlled Text Generation}
\label{subsec:text_gen_and_ctg}

% \begin{itemize}
%     \item Describe the text generation task.
%     \item What is controllability in text generation? Why is it challenging?
%     \item One of the main challenges in CTG using large-scale LMs is the cost of fine-tuning. Expand on this. How can this be solved?
% \end{itemize}

In \textit{text generation}, a language model $p(\textbf{x})$ is asked to produce text $\textbf{x}$ given a prompt by sampling from the distribution of words that are assigned the highest likelihood of following the prompt \citep{radford2019language}. More concisely, text generation in itself is the task of generating a piece of text given an input text. This process can be seen as sampling from a conditional distribution, $p(\textbf{x} | \texttt{prompt})$. \textit{Controlled text generation} refers to the more restrictive problem of enforcing higher-level linguistic features on the generated text during sampling \citep{dathathri2019plug, prabhumoye-etal-2020-exploring}. This can be seen as a sub-problem of vanilla text generation, because the conditioning factor for the output text is further constrained to also include some predefined textual attribute, $a$. That is, controlled text generation is analogous to sampling from the conditional distribution, $p(\textbf{x} | \texttt{prompt}, a)$, where the attribute, $a$, represents a linguistic characteristic of the text, like sentiment, topic, or writing style. 

% \begin{itemize}
%     \item base language model $p(\textbf{x})$
%     \item attribute model $p(a | \textbf{x})$
%     \item CTG model $p(\textbf{x} | a ) \propto p(a | \textbf{x})p(\textbf{x})$
% \end{itemize}

Controlled text generation or CTG is a more challenging problem than vanilla text generation for a number of reasons. First, defining the desired attribute to be controlled for in a manner that it is intelligible for a machine is a challenge in itself \citep{zheng2019personalized}. Second, like many NLP problems, there are not many parallel corpora \citep{dai2019style}. In the context of controlled generation, parallel corpora are datasets of target and source texts that only differ with respect to some attribute. Furthermore, the measure of attribute adherence is a very vague and ambiguous concept \citep{dathathri2019plug, dai2019style}. Namely, a text can be written to have an extremely positive sentiment in multiple formulations, all of which adhere to the positive sentiment. Another important hurdle for controlled text generation, especially when CTG is combined to leverage the linguistic power of large-scale language models, is that the cost of fine-tuning or pre-training a model to control for a linguistic attribute can be very high \citep{dathathri2019plug, madotto-etal-2020-plug}. 

%=================================================================================
%%%%%%% THE FOLLOWING PARAGRAPH HAS BEEN MOVED TO THE RELATED WORK SECTION %%%%%%%
% PPLM \citep{dathathri2019plug} is an example of a recent work whose primary focus is to leverage powerful large-scale language models and making them controllable for a wide variety of linguistic attributes, while avoiding incurring significant costs of fine-tuning. Nevertheless avoiding these costs is anything but trivial. The plug and play set up of the PPLM model forms one of the main theoretical foundations of this work. It is both logical and promising for every day engineers to be able to leverage the grammatical fluency of pre-trained language models for more specific downstream tasks, e.g., specifying linguistic characteristic to enforce on an automatically written text. Their setup consists of a symbiosis of GPT-2 as their powerful large-scale language model, and a significantly smaller and therefore easier to train and fine-tune attribute model. This attribute model is often a small classifier, and can range in complexity from a simple bag of words model with a logistic classifier to a more complicated transformer encoder head. The main benefit of this setup is the extensibility it brings with it. Namely, such large-scale language models are open-source and available online and can be tailored to their specific needs using a significantly easier to train attribute model of your own liking. \cite{dathathri2019plug} demonstrate the applicability of their model on a wide variety of tasks ranging from text style transfer to language detoxification (all of which can be seen as sub-problems of controllable text generation). Other real-world applications include: being able to automatically re-write or adjust a draft text for an editorial, automatic generation of brand specific vacancy ads, or personalized chatbot assistance or even personalized education. What this work also provides is a starting point for new applications, namely controllable dialogue generation.
%=================================================================================

% \paragraph{Transformers}

% The transformer architecture in recent years has dominated numerous NLP tasks and has for the basis for many of the state of the art architecture is in natural language processing. Its masked self-attention and compatibility with parallel processing have made it both effective and handling long-range dependencies in texts, as well attractive in terms of training time. This ability to handle long-range dependencies is exploited in particular in the domain of pretraining large language models. Namely this allows for transformer models to be pre-trained by applying language modelling objectives to long stretches of texts that contain longer range dependencies compared to e.g. tweets or short reviews. 

% The transformer architecture mainly consists of a encoder and decoder structure. Where the encoder processes the embedded text inputs and produces a hidden state using self attention mechanisms and fully connected layers. This hidden state is then passed to the decoder layer which Produces an output which contains a distribution over the vocabulary and can be used for next word prediction.

% \paragraph{GPT}

% Following the success of open AI's pre-trained transformer model they went on to produce a series of generative pre-train transformers that I have been trained in a unsupervised language modelling session.

\subsection{On Dialogue, Dialogue Systems, and Dialogue Generation}
\label{subsec:background_dialogue}\label{subsec:dialogue_generation_as_lm}

% \len{
%     \begin{itemize}
%         \item Think of better title.
%         \item Flesh out this section more.
%         \item Add more references. E.g., \cite{welleck-etal-2019-dialogue} have good definitions for Dialogue Generation and Persona-Based Dialogue.
%         \item Properly introduce the concept of a dialogue with references.
%         \item Properly introduce Dialogue Systems and their general scheme. E.g., \cite{Kushneryk2019IntelligentDS} provide good figures for these concepts.
%         \item Emphasize that the focus of this thesis is on Open-Domain dialogue systems. Talk about open-domain dialogue systems
%         \item \textit{Open-domain conversational systems are a special case of language models where the prefix is the dialogue history and the continuation is a humanlike response.} \citep{madotto-etal-2020-plug}
%         \item Very briefly mention that the focus of your research is on the natural language generation part of a dialogue system.
%     \end{itemize}
% }


% \len{TODO - Add a sub-section here about dialogue (also think of a better title for the sub-section). This is necessary because dialogue is the main focus of your thesis. So before you discuss dialogue response generation (which is the NLP-operationalization of dialogue), formally introduce the concept of dialogue. What is it? What does it look like? How is it different from discourse? Provide some examples like we did in the paper-submission.}

% \len{See Sandro's suggestions for this subsection.}


% Contents: 
% \begin{itemize}
%     \item introduce what is dialogue, 
%     \item what it looks like, 
%     \item how it differs from discourse, etc. 
%     \item Some examples would also be useful. (maybe from the BNC?)
% \end{itemize}

% \begin{itemize}
%     \item Describe dialogue in a sentence. There is no need to dive into an explicit definition of something so general.
%     \item Explain what a dialogue systems is, and which components there are (briefly). Chen et al has good brief definitions.
%     \item The focus of this thesis is on languag generation. (where does the discriminator module fit in tho?)
% \end{itemize}

Because the focus of this thesis is on controlled text generation in the context of dialogue, we provide a section explaining key concepts about dialogue in general and in NLP. This section covers the relevant definition of dialogue, what dialogue systems are and why they are developed and studied, and dialogue generation as a language modeling problem.

A dialogue is a written or spoken conversational exchange between two or more interlocutors (e.g., two people, or a person and a virtual assistant like Amazon Alexa) \citep{MerriamWebster2021Dialogue_Entry}, and it is the most natural form of interaction between people \citep{burtsev-etal-2018-deeppavlov}.
% Between people, dialogue is the most natural way of interaction \citep{burtsev-etal-2018-deeppavlov}.
Generally speaking, a dialogue's purpose is to exchange information or build relationships between interlocutors \citep{bohm2013dialogue}, and it typically consists of interlocutors exchanging utterances in turns. In the context of spoken language analysis, an utterance is considered the smallest unit of speech, that is followed by a change in speaker or the end of a conversation, thus representing a dialogue turn \citep{traum1996utterance}.

In our age group detection experiment presented in the Chapter \ref{ch:experiment1} (i.e., Experiment 1), we also experiment with a so-called discourse dataset (i.e., a dataset of blog posts), in addition to dialogue data. It is therefore useful to establish a distinction between dialogue and discourse. Discourse has multiple definitions, but for the purpose of this thesis, we adopt the definition of discourse as a linguistic unit (e.g., a long talk or a piece of writing), typically longer than a sentence, whose purpose is to convey thoughts or ideas \citep{MerriamWebster2021Dialogue_Entry}. Dialogue therefore distinguishes itself from discourse in that it necessarily involves two or more participants exchanging information and contributing to the conversation, whereas discourse can be a one-way exchange of information, like a lecture or blog-post. See Figure \ref{fig:examples_dialogue_blog_post} for an example of a dialogue between people, and discourse in the form of a blog post.


\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/dialogue_example.png}
        \caption{\textit{Original image source:} Figure 1 of \cite{liu-etal-2020-impress}.}
        \label{}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/Example-blog-from-wordpresscom.png}
        \caption{}
        \label{}
     \end{subfigure}
        \caption{Examples of a dialogue ((a) / left), and discourse in the form of a blog post ((b) / right).}
        \label{fig:examples_dialogue_blog_post}
\end{figure}

% \len{\textbf{TODO} - Give an example of a dialogue snippet (from the BNC) and a blog post from the BAC side-by-side}

%  \len{Verify if this is true. Is that really the difference? Why does dialogue require at least two participants?}

It remains an open challenge for NLP researchers to endow a machine with the capability to engage in meaningful dialogue \citep{burtsev-etal-2018-deeppavlov}, and the development of so-called dialogue systems is an active field of study.
A dialogue system is a computer program that supports spoken, text-based, or multi-modal conversational interactions with humans \citep{mctear2020conversational}.
Dialogue systems typically fall into one of two categories: task-oriented and non-task-oriented dialogue systems. The former engages in an interaction with the user to complete some task, whereas the latter engages in a general conversational interaction with the user \citep{Kushneryk2019IntelligentDS}. The focus of this thesis is on non-task-oriented dialogue.
The development of dialogue systems distinguishes itself from most NLP domains due to the inherent challenges associated with modeling human conversation: informal, noisy, unstructured, and even erroneous real-world responses, possibly competing goals of interlocutors, and extremely diverse sets of acceptable responses to prompts.
% Due to the unsolved and challenging nature of the problem, the development of so-called dialogue systems is an active field of study.

Nevertheless, \cite{mctear2020conversational} suggests that there are three main motivations for researches to investigate and develop dialogue systems:

\begin{enumerate}
    \item Dialogue systems can provide users with a convenient and intuitive way to interact technological services. Furthermore, they can help providers of these services by taking over simple and mundane tasks. However, it must be noted that the replacement of human workers by dialogue systems has ethical and societal consequences that should be taken into account by researchers \citep{ivanov2020impact}. 
    \item The development of dialogue systems requires researchers to model human conversational dynamics, and doing so can broaden our understanding of human behavior.
    \item Research about dialogue systems might one day result in human conversational behavior being simulated so accurately that users could be convinced they are interacting with another human (e.g., by passing the Turing test \citep{oppy2003turing}). However, it is important to note that convincing human users that they are conversing with another human, while it is in fact a dialogue system, is by no means a requirement for an effective dialogue system. And despite this being a core goal of AI \citep{zheng2019personalized}, the ethics of deceiving humans into believing they are talking to another human are highly debatable.
\end{enumerate}

Developing dialogue systems is a very complex task and many approaches have been proposed for this \citep{mctear2020conversational}.
These approaches can differ greatly with respect to their methodologies, ranging from the use of recurrent neural networks \citep{li-etal-2016-deep}, to reinforcement learning \citep{mo2018personalizing}, variational auto-encoders \citep{ruan2019condition}, Transformers \citep{madotto-etal-2020-plug}, and multi-modal models \citep{shuster-etal-2021-multi}.
Despite the many types of modules that can comprise a dialogue system, generally, the basic components of a dialogue system are automatic speech recognition (ASR), language understanding (LU), dialogue management (DM), natural language generation (NLG), and text-to-speech synthesis (TTS) \citep{chen-etal-2017-deep}. Figure~\ref{fig:dialogue_system_overview} shows a schematic overview of how information is routed through such a pipeline. Note that the first and last components (i.e., ASR, and TTS) are omitted if the dialogue system does not support auditory signals and responses. The focus of this thesis is on dialogue generation, a particular operationalization of dialogue in NLP, which falls under the ``\textit{Natural Language Generation (NLG)}'' category of Figure~\ref{fig:dialogue_system_overview}.

\begin{figure}[H]
    \centering
    % \includegraphics[width=\textwidth]{figures/dialogue_system_schema.png}
    \includegraphics[width=\textwidth]{figures/dialogue_system_overview_jansen.png}
    \caption{Schematic overview of a pipeline for a dialogue system.}% \textit{Original image source:} Figure 1 of \cite{chen-etal-2017-deep}.}
    \label{fig:dialogue_system_overview}
\end{figure}



% The focus of my thesis is on dialogue generation, a particular operationalization of dialogue in NLP. 

% Dialogue response generation, sometimes referred to simply as dialogue generation, is the task of automatically generating a response given a prompt \citep{madotto-etal-2020-plug}. 
% Dialogue generation can be framed as a next utterance prediction problem \citep{welleck-etal-2019-dialogue}. In this framework, an utterance is a sequence of tokens representing a dialogue turn. The next utterance utterance, $\textbf{x}_{t + 1}$, is predicted conditioned on a dialogue prefix or prompt, $\textbf{x}_{\leq t}$ (e.g., a single previous dialogue turn, or the entire conversation history). And a succession of utterances can be seen as a dialogue between agents.
% Continuing with the framework of \cite{welleck-etal-2019-dialogue}, a sequence of utterances can be interpreted as a dialogue between agents.

% Computational dialogue modeling distinguishes itself from most NLP domains due to the challenges associated with modeling human conversation: informal, noisy, unstructured, and even erroneous real-world responses, possibly competing goals of interlocutors, or an inherently more diverse set of acceptable responses.

% \len{TODO - work out best way to merge previous and next paragraph(s)}

% Text generation is suitable to tackle tasks such as machine translation, abstractive summarization, and paraphrasing. Dialogue response generation is also a special case of language generation. It can be seen as language generation where the prompt is a turn in a dialogue session. Conversational response generation shares open-domain text generation's overarching objective of producing grammatically correct fluent text, while remaining relevant to the prompt. 
% However, computational dialogue modeling distinguishes itself from most NLP domains due to the challenges associated with modeling human conversation: informal, noisy, unstructured, and even erroneous real-world responses, possibly competing goals of interlocutors, or an inherently more diverse set of acceptable responses. \len{Comment by SF about the previous sentence: \textit{all these aspects could be introduced/described in this subsection about (human) dialogue}}

%%%%%% THE FOLLOWING PARAGRAPH HAS BEEN MOVED TO THE METHODOLOGY. FROM HERE ..... %%%%%%%%%
% \len{Consider moving the following paragraph to the methodology. FROM HERE...}

% Despite these differences, conversational response generation can be modeled in similar ways to open-domain text generation. \cite{zeng-etal-2020-meddialog} suggest to either formulate it in terms of source-target pairs, much like neural machine translation, or as a language modeling objective, where the next token or utterance is conditioned on the dialogue history. To remain close to the training objectives of my baseline models (GPT-2 \citep{radford2019language} and DialoGPT \citep{zhang2019dialogpt}) I choose to adopt the language modeling formulation for conversation modeling. I.e., concatenate all dialogue turns in a multi-turn dialogue session into a long text: $x_1, ..., x_N$. Denote the source sentence or dialogue history as $S = x_1, ..., x_m$ and the target sentence (ground truth response) as $T = x_{m + 1}, ..., x_N$. The conditional probability of dialogue continuation given its history $P(T | S)$ can be written as

% \begin{equation}
%     p(T | S) = \prod_{n = m + 1}^N p(x_n | x_1, ..., x_{n - 1}).
% \end{equation}

% A multi-turn dialogue session $T_1, ..., T_K$ can be written as $p(T_K, ..., T_2 | T_1)$ which is essentially the product of all source-target pairs probabilities $p(T_i | T_1, ..., T_{i - 1})$. This formulation also shows that optimising the single objective $p(T_K, ..., T_2 | T_1)$ is equivalent to optimising all source-target pair probabilities.


% % \begin{itemize}
% %     \item What is (computational) dialogue modeling?
% %     \item What do we aim to understand with CDM?
% %     \item How is (controllable) text generation related to CDM?
% %     \item Is dialogue generation ``simply'' a special case of text generation? If so, explain what are the conditions that constitute this special case.
% % \end{itemize}


% \len{...TO HERE.}
%%%%%%%%%%%%%%%% ...TO HERE

% \subsection{Dialogue Response Generation as a Language Modeling Task} 
% \label{subsec:dialogue_generation_as_lm}

% \len{Depending on how the preceding subsection unfolds, you could remove this subsection's title and merge the two subsections (maybe not just concatenation).}

Dialogue response generation, also referred to simply as dialogue generation, is the task of automatically generating a response given a prompt \citep{madotto-etal-2020-plug}. 
% Dialogue generation can be framed as a next utterance prediction problem \citep{welleck-etal-2019-dialogue}. In this framework, an utterance is a sequence of tokens representing a dialogue turn. The next utterance utterance, $\textbf{x}_{t + 1}$, is predicted conditioned on a dialogue prefix or prompt, $\textbf{x}_{\leq t}$ (e.g., a single previous dialogue turn, or the entire conversation history). And a succession of utterances can be seen as a dialogue between agents.
Dialogue generation can be formulated as a language modeling task \citep{welleck-etal-2019-dialogue, zhang2019dialogpt}, where the next utterance is conditioned on the dialogue history.
In this framework, an utterance is a sequence of tokens representing a dialogue turn. The next utterance utterance, $\textbf{x}_{t + 1}$, is predicted conditioned on a dialogue prefix or prompt, $\textbf{x}_{\leq t}$ (e.g., a single previous dialogue turn, or the entire conversation history). And a succession of utterances can be seen as a dialogue between agents.
% \len{TODO - Do I need the following sentence?}
% To remain close to the training objectives of my baseline models (GPT-2 \citep{radford2019language} and DialoGPT \citep{zhang2019dialogpt}) I choose to adopt the language modeling formulation for conversation modeling. 
The language modeling formulation of dialogue generation consists of concatenating all dialogue turns in a multi-turn dialogue session into a long text: $\textbf{x}_1, ..., \textbf{x}_N$. Denote the source sentence or dialogue history as $S = \textbf{x}_1, ..., \textbf{x}_m$ and the target sentence (ground truth response) as $T = x_{m + 1}, ..., x_N$. The conditional probability of dialogue continuation given its history $P(T | S)$ can be written as

\begin{equation}
    p(T | S) = \prod_{n = m + 1}^N p(\textbf{x}_n | \textbf{x}_1, ..., \textbf{x}_{n - 1}).
\end{equation}

A multi-turn dialogue session $T_1, ..., T_K$ can be written as $p(T_K, ..., T_2 | T_1)$ which is essentially the product of all source-target pairs probabilities $p(T_i | T_1, ..., T_{i - 1})$. This formulation also shows that optimising the single objective $p(T_K, ..., T_2 | T_1)$ is equivalent to optimising all source-target pair probabilities.

\subsection{Controlled Dialogue Generation}
\label{subsec:controlled_dialogue_generation}

% \len{Sandro suggests to move the entire following subsection to the Related Work section. See comment. FROM HERE...}

Analogous to the definition of controlled text generation given earlier in Section \ref{subsec:text_gen_and_ctg}, \textit{controlled dialogue generation} refers to the process of enforcing a particular linguistic style on an automatically generated dialogue response, and it is the core task of this thesis.

\len{Revise this section}

Endowing a dialogue system with personality traits to generate human-like conversation is a long-standing goal in AI \citep{edlund2008towards, scheutz2011toward, madotto-etal-2020-plug}. \cite{zheng2019personalized} argue that this objective is difficult to reach because of the challenge of representing personality traits via language expression and the lack of large-scale persona-labeled dialogue datasets. Assuming an encoder-decoder setup, the same authors postulate that most personalized neural conversation models can be classified as one of two types: implicit and explicit personalisation models. For implicit personalization models, each speaker has its own vector representation, which implicitly captures the speaking style of the speaker in the decoding process \citep{ijcai2017-521, li-etal-2016-persona}. These models enjoy the benefit of having a more granular and realistic representation of speaking style, as opposed to a simple discrete set of traits (as is the case for explicit personalization models). On the other hand, it is unclear how speaker style is captured and should be interpreted, as all the information about a speaker's style is encoded in a real-valued vector. Furthermore, these methods suffer from a data sparsity issue, because each dialogue should be tagged with a speaker identifier and there should be sufficient dialogues from each trait-group to train a reliable trait-adaptive model. 
% \len{This should be in the related work. See comment.} 
% This last drawback is a bigger hurdle for the method proposed by \cite{zheng2019personalized} than it is for mine, as their work deals with personalization for intersections of multiple traits, whereas this thesis focuses on adaptation to a small number of age groups.

When generating responses, \textit{explicit} personalization models are conditioned either on a given personal profile \citep{ijcai2018-595}, text-described persona \citep{zhang-etal-2018-personalizing}, or simply an attribute label \citep{madotto-etal-2020-plug}. That is, speaker traits are represented as key-value pairs or descriptions about age, gender, etc. This can be seen as conditioning the decoder's output on an attribute $a$. Speakers with same set of personality traits can share attribute representations, so it does not require a speaker-specific representation vector. Such structured character descriptions are more explicit, straight-forward, and interpretable. However, explicit personalization models require manually labeled or crowdsourced datasets for development, making it difficult to scale these models to large-scale dialogue datasets \cite{zheng2019personalized, madotto-etal-2020-plug}.

% \len{...TO HERE}

% \begin{enumerate}
%     \item \textit{Implicit personalization models}
%         \begin{itemize}
%             \item Each speaker has its own vector representation, and this vector is fed into the decoder to capture the speaking style of the speaker implicitly.
%             \item \textbf{Pros}: more granular and realistic representation of speaking style, as opposed to a simple discrete set of traits.
%             \item \textbf{Cons}: (1) It is unclear how personality is captured and how it can be interpreted as all the information about a speaker's style is encoded in a real-valued vector. (2) These methods suffer from a data sparsity issue: each dialogue should be tagged with a speaker identifier and there should be sufficient dialogues from each speaker to train a reliable user-specific model.
%         \end{itemize}
%     \item \textit{Explicit personalisation models}
%         \begin{itemize}
%             \item The generated responses are conditioned either on a given personal profile or a text-described persona. I.e., personality is represented via key-value pairs or natural language descriptions about age, gender, etc. So this can be seen as conditioning the decoder's output on an attribute $a$, which represents one of the descriptions in the previous two sentences.
%             \item \textbf{Pros:} (1) The persona of a speaker can be viewed as a composite of diversified personality traits, suggesting that this approach is a sensible approximation of reality. (2) Data sparsity problem is solved. Speakers with same set of personality traits can share attribute representations. So it does not require a speaker-specific representation vector. (3) Such structured personality descriptions are more explicit, straight-forward, and interpretable.
%             \item \textbf{Cons:} (1) These methods are limited to either manually-labelled data or crowdsourced dialogues, and thereby not scalable to large-scale dialogue datasets.
%         \end{itemize}
% \end{enumerate}


\subsection{Transformers}

The Transformer architecture plays a central role in most of the recent advances in NLP. The same holds for the methods used in this thesis to investigate controlled dialogue generation and automated detection of age-related linguistic patterns in dialogue utterances. For a more detailed review of the model architecture, the reader is referred to the original paper \citep{vaswani2017attention} or this blog post\footnote{\url{https://jalammar.github.io/illustrated-transformer/}}.

The Transformer, like most neural sequence processing models, has an encoder-decoder structure. On a high level, the encoder receives an input sequence $\textbf{x} = (x_1, ..., x_n)$ (e.g., a sentence), and maps this to a sequence of latent continuous variables $\textbf{z} = (z_1, ..., z_n)$. The decoder then takes $\textbf{z}$ as input, and maps this to an output sequence $\textbf{y} = (y_1, ..., y_m)$. Note that the use of positional encodings of the input and output embeddings enables the Transformer to process and generate sequences in arbitrary order, allowing for a high degree of parallelization. The generation of $\textbf{y}$ happens element-by-element in an auto-regressive fashion, where at step $t$, element $y_{t - 1}$ is also taken as input.

Both the encoder and decoder are comprised of $N$ identical layers (denoted by the `N $\times$' in the left part of Figure \ref{fig:transformer_architecture}). Every sub-layer performs a succession of transformations using multi-head self-attention mechanisms and point-wise, fully connected layers, along with residual connections \citep{he2016residual} around every sub-layer followed by layer normalization \citep{DBLP:journals/corr/BaKH16}. The decoder's first self-attention sub-layer is masked to ensure that the output predictions at sequence position $i$ cannot depend on output positions greater than $i$. Finally, the decoder passes its output through a linear and softmax layer to produce a probability distribution over the problem space (e.g., the vocabulary) from which the most likely symbols for the generated output sequence $\textbf{y}$ can be sampled.

A key aspect of the Transformer architecture is its use of attention \citep{DBLP:journals/corr/BahdanauCB14}. This allows the encoder-decoder architecture to selectively focus on parts of the input sequence to produce a more informative hidden representation. \cite{vaswani2017attention} formulate an attention function as a mapping of queries and sets of key-value pairs to an attention output, where matrices represent the queries $Q$, keys $K$, and values $V$. The attention output is a weighted sum of the values, based on the relevance of the corresponding keys to a query. In particular, they employ scaled dot-product attention:

\begin{equation}
    \texttt{Attention}(Q, K, V) = \texttt{softmax} \left( \frac{QK^T}{\sqrt{d_k}}\right) V.
\end{equation}

Furthermore, \cite{vaswani2017attention} propose to use multi-head attention by using learned linear projections to project the queries, keys and values $h$ times, and apply the aforementioned attention function to these projections in parallel. The concatenation of these attention outputs, passed through a linear layer, ultimately produces the final output of the Transformer's attention sub-layers. This allows the model to attend to the relevant information from all representation sub-spaces at various sequence positions. See Figure \ref{fig:transformer_architecture} for a schematic illustration of the Transformer's structure described above.


\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/transformer_lillog.png}
    \caption{An overview of the full Transformer model architecture. \textit{Collated image source:} Fig. 17 in this blog post \url{https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html}. \textit{Original image source:} Figures 1 and 2 in \cite{vaswani2017attention}}
    \label{fig:transformer_architecture}
\end{figure}

\subsection{Causal Language Modeling with Transformers for Dialogue Generation}
As described in Section \ref{subsec:background_dialogue}, here we focus on dialogue generation. A formulation of dialogue generation as a language modeling task is described in Section \ref{subsec:dialogue_generation_as_lm}. Following the conventions of \cite{dathathri2019plug} and \cite{madotto-etal-2020-plug}, a dialogue is comprised of multiple alternating turns (sometimes referred to as utterances) between more than one speaker. For simplicity, this project only focuses on dialogues between two speakers. The conversation history at turn $t$ is defined as $\mathcal{D}_t = \{S^{(1)}_1, S^{(2)}_1, ..., S^{(1)}_t\}$, where $S^{(j)}_t$ is speaker $j$'s utterance at time $t$. \cite{madotto-etal-2020-plug} denote speaker $1$ as the user $U$, and speaker $2$ as the conversational system $S$, yielding dialogue history $\mathcal{D}_t = \{U_1, S_1, ..., U_t\}$. This notational convention will also be used for the user-system experiments later on in this thesis.

A Transformer-based language model (denoted $\texttt{LM}$) is used in this thesis to model the distribution of dialogues, using dialogue history at time $t$, $\mathcal{D}_t$, as a prompt to auto-regressively generate the dialogue continuation $S_t$. More specifically, let the concatenation of the dialogue history at $t$ and its continuation, $\{\mathcal{D}_t, S_t\}$, be represented as a sequence of tokens $\textbf{x}= \{x_0, ..., x_n\}$. Then, by recursively applying the product rule of probability (\cite{bishop2006pattern}), the unconditional probability of the sequence $p(\textbf{x})$ can be expressed as:

\begin{equation}
    p(\textbf{x}) = \prod_{i = 1}^n p(x_i | x_0, ..., x_{i - 1}).
\end{equation}

\cite{dathathri2019plug} and \cite{madotto-etal-2020-plug} define the Transformer's decoding process in a recursive fashion. Let $H_t$ denote the conversation history's key-value pairs, i.e., $H_t = \left[ (K_t^{(1)}, V_t^{(1)}), ..., (K_t^{(l)}, V_t^{(l)}) \right]$, with $(K_t^{(i)}, V_t^{(i)})$ representing the key-value pairs from the $\texttt{LM}$'s $i$-th layer generated at all time steps $0$ through $t$. This results in the recurrent dedocing process being expressed as:

\begin{equation}
    o_{t + 1}, H_{t + 1} = \texttt{LM} \left( x_t, H_t \right),
\end{equation}

where $o_{t + 1}$ is the hidden state of the last layer. Finally, after applying a softmax transformation, the next token $x_{t + 1}$ is sampled from the resulting probability distribution, i.e.,  $x_{t + 1} \sim p_{t + 1} = \texttt{softmax} \left( W o_{t + 1} \right)$, where $W$ is a linear mapping from the model's last hidden state to a vector of vocabulary size. This recursive formulation allows for efficient text generation by leveraging cached memories, without repeated forward passes.

\subsection{Plug-and-Play Language Modeling}
\label{sec:ppm}

The Plug-and-Play Language Model (PPLM) \cite{dathathri2019plug} works by using a text classifier, referred to as an attribute model, to control the text generated by a language model. Let $p(X)$ denote the output distribution of a Transformer-based language model (e.g., GPT-2 or DialoGPT), where $X$ represents the generated text. And $p(a | X)$ denotes the attribute model (e.g., a single-layer or BoW classifier) that represents the degree of adherence of text $X$ to a certain attribute $a$ (e.g., topic or sentiment (previous work), or age-group characteristics (this work)). Then PPLM can be seen as modeling the conditional distribution of generated text $X$ given attribute $a$, i.e., $p(X | a)$. Note that Bayes' theorem ties these three definitions together as follows:

\begin{equation}
    p(X | a) \overbrace{=}^{\text{Bayes' theorem}} 
    % \frac{p(a, X)}{p(a)} = 
    \frac{p(X) p(a | X)}{p(a)} \propto
    p(X)p(a | X).
\end{equation}

% \len{TODOs -
% \begin{itemize}
%     \item Maybe this isn't the best spot, but somewhere in the methodology motivate the choice of using a unigram wordlist as BoW, and a linear classifier trained with a transformer-based architecture.
%     \item Also emphasize the continuing narrative between Experiment 1 and Experiment 2. Namely, how the best performing systems in Exp1 are used to inform choices during Exp2 (trigram and BERT best classifiers --> use unigram and linear layer used for PPLM).
%     \item Also explain how the PPLM setup is not compatible with lists of $n$-grams (for $n>1$), as it makes perturbations at the unigram level. And adapting the system to fit trigram BoW's implies retraining the entire underlying language model (like GPT-2) for trigrams, defeating the purpose of PPLM (leveraging large scale language models for controllability, without having to finetune the massive architectures).
%     \item Then go on to argue that the unigram classifier is on par with trigram, making it a viable choice for the 100MIU BoW.
%     \item Also mention that your work extends the original BoW-PPLM by using various empirically generated BoWs, instead of curated wordlists. Making it more reproducible.
%     \item Double-check if you should make this last argument in the methodology, and not in related work or experimental details.
% \end{itemize}}

To control the generated text, PPLM shifts the aforementioned history $H_t$ (i.e., all Transformer key-value pairs generated up to time $t$) in the direction of the sum of two gradients:

\begin{enumerate}
    \item Ascending $\nabla \log p(a | X)$: maximizing the log-likelihood of the desired attribute $a$ under the conditional attribute model. This enforces attribute control.
    \item Ascending $\nabla \log p(X)$: maximizing the log-likelihood of the generated language under the original (possibly conversational) language model. This promotes fluency of the generated text.
\end{enumerate}

These two incentive-representing gradients are combined with various coefficients, yielding a set of tunable parameters to steer the generated text in the direction of the desired fluency, attribute control, and length.

Let's first focus on the first of the two gradients, i.e., the attribute control promoting $\nabla \log p(a | X)$. $\Delta H_t$ represents the update to history $H_t$ that pushes the distribution of the generated text $X$ in the direction that has a higher likelihood of adhering to desired attribute $a$. The gradient update rule can be expressed as:

\begin{equation}
    \Delta H_t \leftarrow \Delta H_t + \alpha
    \frac{\nabla_{\Delta H_t} \log p(a | H_t + \Delta H_t)}
    {\norm{\nabla_{\Delta H_t} \log p(a | H_t + \Delta H_t)}^{\gamma}}
\label{eq:H_update_rule}
\end{equation}

where $\alpha$ is the step size, and $\gamma$ denotes the normalization term's scaling coefficient. Both step size ($\alpha$) and the scaling coefficient ($\gamma$) influence attribute control. Attribute control can be softened by either decreasing $\alpha$ or increasing $\gamma$ and vice versa. Note that $\alpha = 0$ recovers the original uncontrolled underlying language model (e.g., GPT-2 or DialoGPT). In practice, $\Delta H_t$ is initialized at zero, and the update rule in Equation \ref{eq:H_update_rule} is applied $m$ times (usually 3 to 10), resulting in the updated key-value pair history $\tilde{H}_t  = H_t + \Delta H_t$. Then the updated history $\tilde{H}_t$ is passed through the language model, yielding the updated logits (final Transformer-layer): $\tilde{o}_{t + 1}, H_t = \texttt{LM}(x_t, \tilde{H}_t)$. And finally the shifted $\tilde{o}_{t + 1}$ is linearly mapped through a softmax layer to produce a new, more attribute-adherent, distribution from which to sample, i.e., $x_{t + 1} \sim \tilde{p}_{t + 1} = \texttt{softmax} \left( W \tilde{o}_{t + 1} \right)$.

The method described until now will generate attribute-adherent text, but will likely yield fooling examples \citep{nguyen2015deep} that are gibberish to humans, but get assigned high $p(a | x)$ by the attribute model \citep{dathathri2019plug}. That is why \cite{dathathri2019plug} apply two methods to ensure fluency of the generated text. The first is to update $\Delta H_t$ such to minimize the Kullback-Leibler (KL) divergence (denoted $D_{KL})$ between the shifted and original distributions. In practice, $D_{KL}$ is scaled by a coefficient $\lambda_{KL}$, typically found to work well for most tasks when set to 0.01. Repetitive text generation (i.e., high $p(a | x)$ but low $p(x)$) can therefore sometimes be avoided by increasing $\lambda_{KL}$. The second method to ensure fluency is Post-norm Geometric Mean Fusion \citep{stahlberg-etal-2018-simple} which, instead of directly influencing $\Delta H_t$ like minimizing $D_{KL}$, fuses the altered generative distribution $\tilde{p}_{t + 1}$ with the unconditional language distribution $p(x)$. This is done during generation by sampling the next token as follows:

\begin{equation}
    x_{t + 1} \sim \frac{1}{\beta}
    \left( 
    \tilde{p}_{t + 1}^{\gamma_{gm}} p_{t + 1}^{1 - \gamma_{gm}}
    \right)
    \label{eq:gm_fusion}
\end{equation}

where $\beta$ is a normalization constant, $p_{t + 1}$ and $\tilde{p}_{t + 1}$ denote the original and modified distributions, respectively, and $\gamma_{gn}$ is a scaling term that interpolates between the two distributions. Because the new sampling distribution in Equation \ref{eq:gm_fusion} converges towards the unconditional language model as $\gamma_{gm} \rightarrow 0$, repetitive text generation can be avoided by decreasing the scaling term.


\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/pplm_fig1.png}
    \caption{A schematic overview of the plug-and-play interaction between attribute model $p(a | \textbf{x})$ and language model $p(\textbf{x})$. \textit{Original image source:} Figure 1 of \cite{dathathri2019plug}}
    \label{fig:pplm_schematic_overview}
\end{figure}


% \subsubsection{PPLM is not fine-tuning}

It is worth mentioning that the plug-and-play method applied by \cite{dathathri2019plug} and \cite{madotto-etal-2020-plug} is different from fine-tuning. Note that in Equation \ref{eq:H_update_rule} the gradient updates are restricted to the history $H_t$, and do not affect the model's parameters. Because the key-value pairs $(K_t^{(i)}, V_t^{(i)})$ that comprise $H_t$ are activations and not model-weights, the updates only take place in the activation-space. This means that PPLM leaves the underlying (conversational) language model untouched.

Contrary to fine-tuning often massive LMs, PPLM does not incur a significant training cost (depending of course on the complexity of the discriminator or attribute model). However, \cite{madotto-etal-2020-plug} show that PPLM needs a fixed number of $m$ update-steps to for every generated token. This makes the original PPLM setup unsuitable for online interactive applications, like conversational systems. Addressing this problem, they introduce plug-and-play conversational model (PPCM), which extends PPLM by using the original model setup to generate dialogue datasets with the desired attribute $a$, and then use optimized residual adapters \citep{bapna-firat-2019-simple} to control $\texttt{LM}$'s output distribution. More specifically, \cite{madotto-etal-2020-plug} use PPLM to generate $n$ attribute-adherent dialogue datasets $\mathscr{D}^a = \{\mathcal{D}^1, ..., \mathcal{D}^n\}$, for attribute $a$. These generated dialogue datasets are then used to train the residual adapter modules that control the language model's output distribution.

% \subsection{Language and Age}
% The relationship between a person's age and use of language is a thoroughly studied subject with a decades long history and inherent challenges \citep{pennebaker2003words, nguyen2014gender, zheng2019personalized}. A number factors like community membership (e.g., gender, socioeconomic status, or political affiliation), experimental condition (e.g., emotional versus non-emotional disclosure), mode of disclosure (writing versus talking), and other confounding variables complicate the study of age's relation to language \citep{nguyen-etal-2011-author}. The relatively recent advent of widely available computational resources and vast amounts of textual data made it possible to leverage machine learning methods to help detect patterns in language that eluded conventional sociolinguistic research. Early computational investigations into the connection between a person's age and use of language is typically a combination of qualitative and statistical methods. For instance, using a mix between their proprietary count-based text analysis framework, Linguistic Inquiry and Word Count (LIWC) and sociolinguistic theory, \cite{pennebaker2003words} study the changes in written and spoken language use with increasing age. They discuss four important areas of a person's character that have been found to change with age: emotional experience and expression, identity and social relationships, time orientation, and cognitive abilities. These four axes and their hypothesized relationships with language use and age can be interpreted in the following ways:
% \begin{enumerate}
%     \item \textit{Emotional experience and expression:} This is the relationship between increasing age and linguistically observable manifestations of a person's experienced emotions. In practical terms, this is framed as detectable instances of positive and negative affect in language. This complex relationship between age and emotional expression is characterized by decreased levels of negative affect and slightly non-decreasing levels of positive affect. This is also confirmed by the findings of \cite{schler2006effects}.
    
%     \item \textit{Sense of identity and social relationships:} These terms refer to developmental tends in one's relation to self and others, as expressed in their language, e.g., as references to self (\textit{I, me, my}, and \textit{we, us, our}) or others (\textit{they, them, theirs}). \cite{pennebaker2003words} report that the \textit{quantity} of social connections decreases and the \textit{quality} of remaining relationships increases with age.
    
%     \item \textit{Time orientation:} This relationship describes how people express their perception of and orientation towards time. For instance, this can be indicated by the use of time-related verb tenses. The authors suggest that older individuals tend to be more past-oriented than their younger future-oriented counterparts.
    
%     \item \textit{Cognitive abilities:} This refers to markers of cognitive capacity in language. Aging is expected to be associated with less use of cognitively complex words after a certain mid-adulthood peak. Specifically, the relationship between markers of cognitive complexity in natural language (cognitive mechanisms, causal insight, and exclusive words) and age is hypothesized to be curvilinear. And because verbal ability does not decline until very late in life, markers of verbal ability (e.g., use of big words) are not expected to show changes with age.
% \end{enumerate}

% \cite{pennebaker2003words} consider the following variables: positive and negative emotions, first-person singular and first-person plural pronouns, social references, time-related words (past-tense, present-tense, and future-tense verbs), big words ($>6$ letters), cognitive mechanisms, causal insight, and exclusive words. Their main findings suggest that increasing with age, people use more positive and fewer negative affect words, use fewer self-references, use more future-tense and fewer past-tense verbs, and exhibit a general pattern of increasing cognitive complexity.

% Detectable linguistic differences between age-groups can often be attributed to the use of language fads or references to age-specific popular culture. For instance, \cite{schler2006effects} find that the use of slang and neologisms (such as \textit{lol} and \textit{ur}) are strong indicators of youth. Similarly, words like `facebook', `instagram', and `netflix' appear in the most frequently used words by younger participants of conversational data collection efforts, like that of the British National Corpus' spoken component \citep{love-spoken-bnc-2014}.

% % More recent studies, like that of \cite{nguyen-etal-2011-author}, \cite{zheng2019personalized}, and \cite{abdallah2020age}, frame age prediction from text as traditional machine learning problems, like linear regression, support vector machines, or neural architectures. These modeling approaches tend to reveal that strong indicators of age lie at the syntactic or structural level of language use, as opposed to the more content-based lexical level. Furthermore, this could explain why automatic detection from text of more content-based traits, like topic or sentiment, tend to be easier problems to solve than age prediction from text. To emphasize one such complicating factor, \cite{nguyen2014gender} argue that differences in language use are often relation to the speaker's social identity, which could differ from their biological identity. 
% % This idea that age prediction from text is more challenging than topic or sentiment prediction could be an indication that controlled language generation for age-differences is also a more nuanced problem than topical steered text generation.


% % \textbf{Keep in mind:}
% % \begin{itemize}
% %     \item What is known about the relationship between a speaker's (or author's) age and their linguistic characteristics? I.e., how does language use develop with age according to the existing literature?
% %     \item How can we automatically detect a speaker's age(-group) from their utterances using machine learning?
% %     \item Link findings from the papers you cite to the hypothesis that linguistic differences in age lie more are the phrase/constructional level than at the single word/lexical level. However, is this really the case? \cite{nguyen-etal-2011-author} mention single words like `well', `like`, and `just' being predictive of age.
% %     \item Mention that age differences in language could/should also be interpreted as indications of language fads during a person's formative years.
% %     \item Hypothesize that age-related linguistic variation is a more subtle and nuanced factor to control for during text generation than, e.g., topic (science, business, religion), or sentiment.
% %     \item Mention confounding factors like community membership (like gender, socioeconomic status, or political affiliation), experimental condition (e.g., emotional versus non-emotional disclosure), mode of disclosure (writing versus talking), and other confounding factors that complicate age prediction from language.
% % \end{itemize}

\section{Related Work}
\label{sec:related_work}

% \len{Keep in mind the following distinction between Background and Related Work - The Background section should give
% an overview of the problem and the components involved: dialogue,
% language generation, dialogue generation, age modeling, etc.,
% without focusing on one or the other approach — in Related Work, you
% describe approaches that have been proposed to tackle each of these
% components, separately or jointly, and which are related or relevant to
% your own work for some reason}

\subsection{Automated Age Detection from Language}

% \len{Consider adding a small sub-section about automated age detection from text, because you often bring up the problem and other researchers' approaches to solving it in the Background section.}

% \dots

% \len{work this into this subsection. Taken from workshop paper submission}
Automated (speaker or author) age detection from (spoken or written) language is a challenging task, for which many approaches have been suggested \citep{nguyen-etal-2011-author}. The work of \citet{schler2006effects} focuses on age detection in written discourse using a corpus of blog posts. The authors learn a Multi-Class Real Winnow classifier leveraging a set of pre-determined style- and content-based features, including part-of-speech categories, function words, and the 1000 unigrams with the highest information gain in the training set. They find that content features (lexical unigrams) yield higher accuracy ($\sim$ 74\%) than style features ($\sim$72\%), while their best results are obtained with their combination ($\sim$76\%).
Previous work on age detection in dialogue has focused on speech features, which are known to systematically vary across age groups. For example,  \citet{wolters2009age} learn logistic regression age classifiers from a small dialogue dataset %of 448 dialogues 
using different acoustic cues supplemented with a small set of hand-crafted lexical features, while \citet{li2013automatic} develop SVM classifiers using acoustic and prosodic features extracted from scripted utterances spoken by participants interacting with an artificial system. 
% In contrast to this line of work, we investigate whether different age groups can be detected from textual linguistic information rather than voice-related cues. We explore whether, and to what extent, various state-of-the-art NLP models are able to capture such differences in dialogue data as a preliminary step to age-group adaptation by conversational agents.
% The work of~\citet{schler2006effects} focuses on age detection in written discourse using a corpus of blog posts. The authors learn a Multi-Class Real Winnow classifier leveraging a set of pre-determined style- and content-based features, including part-of-speech categories, function words, and the 1000 unigrams with the highest information gain in the training set. They find that content features (lexical unigrams) yield higher accuracy ($\sim$ 74\%) than style features ($\sim$72\%), while their best results are obtained with their combination ($\sim$76\%). 
% We extend this investigation in several key ways: (1) we leverage state-of-the-art NLP models that allow us to learn representations end-to-end, without the need to specify concrete features in advance; (2) we apply this approach to dialogue data, using a large-scale dataset of transcribed, spontaneous open-domain dialogues; (3) we show that text-based models can indeed detect age-related differences in both discourse and dialogue, even in the case of very sparse signal at the level of dialogue utterances; and finally (4) we carry out an in-depth analysis of the models' predictions to gain insight on which elements of language use are most informative.

More recent studies, like that of \cite{nguyen-etal-2011-author}, \cite{nguyen2014gender}, \cite{zheng2019personalized}, and \cite{abdallah2020age}, frame age prediction from text as traditional machine learning problems, like linear regression, support vector machines, or neural architectures. These modeling approaches tend to reveal that strong indicators of age lie at the syntactic or structural level of language use, as opposed to the more content-based lexical level. Furthermore, this could explain why automatic detection from text of more content-based traits, like topic or sentiment, tend to be easier problems to solve than age prediction from text. To emphasize one such complicating factor, \cite{nguyen2014gender} argue that differences in language use are often relation to the speaker's social identity, which could differ from their biological identity. 


\subsection{Controlled Text Generation}
Previous approaches to controlled text generation require fine-tuning large Transformer-based language models or training conditional generative LMs from scratch. Most notably CTRL \citep{keskarCTRL2019}, which achieves controlled generation by training a generative Transformer for a number of control codes. CTG models that require fine-tuning for control, like CTRL, can produce high quality fluent text because they are specifically trained to maximize the likelihood of generated sequences, given an attribute (denoted $p(\textbf{x} | a)$), but require training massive language models with computational costs.

Other recent examples of controlled text generation models that are not Transformer-based also exist. \cite{li-etal-2020-optimus} introduce OPTIMUS, a large pre-trained Variational Autoencoder (VAE) \citep{Kingma2014} that can be fine-tuned for specific natural language tasks, like guided sentence generation. They demonstrate OPTIMUS' ability to perform controlled text generation from latent style-embeddings, with fluency at par with GPT-2. They also show how OPTIMUS generalizes better for low-resource languages than BERT \citep{devlin-etal-2019-bert}. Nevertheless, much like the previously mentioned CTG models, OPTIMUS still incurs a significant computational cost for fine-tuning per NLP task.

% The plug-and-play language model (PPLM) \citep{dathathri2019plug} is a recent approach to leverage powerful large-scale language models and make them controllable for a wide variety of linguistic attributes, while avoiding incurring significant costs of fine-tuning these massive language models. Nevertheless avoiding these costs is anything but trivial. The plug-and-play setup of the PPLM model forms one of the main theoretical foundations of this work. It is both logical and promising for every day engineers to be able to leverage the grammatical fluency of pre-trained language models for more specific downstream tasks, e.g., specifying linguistic characteristic to enforce on an automatically written text. Their setup consists of a symbiosis of GPT-2 as their powerful large-scale language model, and a significantly smaller and therefore easier to train and fine-tune attribute model. This attribute model is often a small classifier, and can range in complexity from a simple bag of words model with a logistic classifier to a more complicated transformer encoder head. The main benefit of this setup is the extensibility it brings with it. Namely, such large-scale language models are open-source and available online and can be tailored to their specific needs using a significantly easier to train attribute model of your own liking. \cite{dathathri2019plug} demonstrate the applicability of their model on a wide variety of tasks ranging from text style transfer to language detoxification (all of which can be seen as sub-problems of controllable text generation). Other real-world applications include: being able to automatically re-write or adjust a draft text for an editorial, automatic generation of brand specific vacancy ads, or personalized chatbot assistance or even personalized education. What this work also provides is a starting point for new applications, namely controllable dialogue generation.

% \len{TODO: Where does the following sentence fit best? ``The plug-and-play setup of PPLM forms one of the main theoretical foundations of this work.''}

The Plug-and-Play language model (PPLM) \citep{dathathri2019plug} is a recent solution to the problem of high re-training costs of controlled text generation. This approach, inspired by a similar technique for style-control of generated images \citep{nguyen2017plug}, leverages the fluency of large-scale language models when controlling them for a specific linguistic attribute, while avoiding incurring significant costs of fine-tuning these massive language models. The main benefit of this setup is its low-cost extensibility. Namely, such large-scale language models are often open-source and available online, and can now be tailored to users' specific needs using a significantly easier to train attribute model. 
The original architecture proposed by \citeauthor{dathathri2019plug} uses GPT-2 as a base language model which provides grammatical fluency, combined with a significantly easier to train attribute model (i.e., a simple BoW or single-layer classifier). Using gradient updates to the activation space of the much smaller attribute model, they manage to generate language that combines (some of) the fluency of GPT-2 with the stylistic control of the attribute model, without the cost of retraining a specialised architecture. They demonstrate that PPLM achieves desirable fluency (i.e., perplexity measured with GPT(-1) \citep{radford2018improving}), as well as measurable attribute control. Their architecture's applicability is also demonstrated on tasks such as controlled story writing and language detoxification. They also show a clear trade-off between attribute control and grammatical correctness and diversity. 

% Recent examples of controllable language generation models that are not Transformer-based also exist. \cite{li-etal-2020-optimus} introduce OPTIMUS, a large pre-trained Variational Autoencoder (VAE) \citep{Kingma2014} that can be fine-tuned for specific natural language tasks, like guided sentence generation. They demonstrate OPTIMUS' ability to perform controlled text generation from latent style embeddings, with fluency at par with GPT-2. They also show how OPTIMUS generalizes better for low-resource languages than BERT \citep{devlin-etal-2019-bert}. Nevertheless, much like the previously mentioned non-plug-and-play CTG models, OPTIMUS still incurs a significant computational cost for fine-tuning per NLP task.

% Dialogue generation is not explored as an original application of PPLM, nor is their tested with more complex attribute models to hopefully allow for less deterioration of fluency as attribute control increases. 



\subsection{Text Style Transfer}
Text style transfer is the task of changing a text's stylistic properties, while retaining its style-independent properties, like content and fluency \citep{dai2019style}. Text style transfer is a closely related problem to controlled text generation. Its similarity lies in trying to modify the output distribution of a text generation model, such that stylistic characteristics of the produced text are controllable, keeping content and fluency preserved. It involves rewriting an input text with a specific style. More formally, given a text $\textbf{x}$, its corresponding style-representing vector $\textbf{s}^{(i)}$, the number of different styles $K$ over which there exists a distribution, and a desired style $\hat{\textbf{s}} \in \{\textbf{s}^{(i)}\}_{i = 1}^{K}$, the goal of text style transfer is to produce output text $\hat{\textbf{x}}$ with style $\hat{\textbf{s}}$, and the style-independent properties of $\textbf{x}$. 
% Text style transfer can also be seen as a special case of (abstractive) summarization, for which Transformers have also demonstrated applicability \citep{baan-etal-2019-abstractive}.

Previous approaches to text style transfer involve passing input text through an RNN-based encoder, yielding a style-dependent latent representation $\textbf{z}$ \citep{zhang2018styletranslation}. Typically, these approaches then attempt to ``disentangle'' $\textbf{z}$ into a style-independent content representation and a latent representation of the stylistic properties of the input text. The subsequent decoder then receives the content representation and a new latent style variable as input, to ultimately produce a style-altered output text with unchanged content. This style-disentanglement approach has a number of drawbacks: \textbf{(1)} It is difficult to evaluate the quality of disentanglement of the latent space. \textbf{(2)} It is hard to capture rich semantic information in the latent representation due to limited capacity of vector representations (especially for long texts). \textbf{(3)} To disentangle style and content in the latent representations, all previous approaches have to assume all input texts can be encoded by a fixed-size latent vector. \textbf{(4)} Since most previous approaches use RNN-based encoder-decoder frameworks, they have problems capturing long-range dependencies in the input sentences. Furthermore, disentanglement might be unnecessary, as \cite{lample2018multipleattribute} have shown a proper decoder can perform controlled text generation from an entangled latent representation by ``overwriting'' the original style.

% \begin{enumerate}
%     \item It is difficult to evaluate the quality of disentanglement of the latent space.
%     \item Disentanglement is unnecessary, as contemporary work by \cite{lample2018multipleattribute} has shown a good decoder can perform controllable text generation from an entangled latent representation by ``overwriting'' the original style.
%     \item It is hard to capture rich semantic information in the latent representation due to limited capacity of vector representations (especially for long texts).
%     \item To disentangle style and content in the latent representations, all previous approaches have to assume all input texts can be encoded by a fixed-size latent vector.
%     \item Since most previous approaches use RNN-based encoder-decoder frameworks, they have problems capturing long-range dependencies in the input sentences.
% \end{enumerate}

To address these drawbacks, \cite{dai2019style} propose Style Transformer, a Transformer-based alternative encoder-decoder framework for text style transfer. The authors' approach does not require any manipulation (i.e., disentanglement) of the latent space, eliminates the need for a fixed-size vector representation of the input, and handles long-range dependencies better due to Transformers' attention mechanism. Aside from this being the first application of Transformers for text style transfer, \cite{dai2019style} contribute a novel training algorithm for such models, that boasts significant improvements of results on two text style transfer datasets.

\subsection{Dialogue Generation}
As explained earlier in Section \ref{subsec:background_dialogue}, dialogue generation is task of automatically generating a response given a user's prompt. \cite{zhang2019dialogpt} introduce DialoGPT, a tunable large-scale language model for generation of conversational responses, trained on Reddit discussion chain data. DialoGPT therefore extends GPT-2 \citep{radford2019language} to address a more restrictive sub-category of text generation, i.e., conversational response generation. DialoGPT inherits from GPT-2 a 12-to-48 layer transformer with layer normalization, a custom initialization scheme that accounts for model depth, and byte pair encodings \citep{sennrich-etal-2016-neural} as a tokenizer. The generation task remains framed as language modeling, where a multi-turn dialogue session is modeled as a long text. 

To address the well-known problem of open-domain text generation models producing bland and uninformative samples, \cite{zhang2019dialogpt} implement a maximum mutual information (MMI) scoring function. MMI uses a pre-trained backward model to predict $p(\texttt{source} | \texttt{target})$: i.e., the source sentences (dialogue history) given the target (responses, dialogue continuation). First, top-K sampling is used to generate a set of hypotheses. Then the probability $p(\texttt{source} | \texttt{hypothesis})$ is used to re-rank all hypotheses. As frequent and repetitive hypotheses can be associated with many possible queries/sources (i.e., a hypothesis that frequently occurs is one that is apparently applicable to many queries), and maximizing backward model likelihood penalizes repetitive hypotheses, MMI yields a lower probability for highly frequent hypotheses, thereby reducing blandness and promoting diversity. 

DialoGPT is evaluated on the Dialog System Technology Challenge (DSTC) 7 track, an end-to-end conversational modeling task in which the goal is to generate conversation responses that go beyond chitchat by injecting information that is grounded in external knowledge. The model achieves state-of-the-art results on both the human and automatic evaluation results, by achieving near human-like responses that are diverse, relevant to the prompt, much like GPT-2 for open-domain text generation. They train 3 models of small (117M), medium (345M), and large (762M) parameter sizes. The medium-sized 345M model achieves the best automatic evaluation results across most metrics, and is used as one of the baselines in later experiments in this thesis. Their Hugging Face PyTorch implementation can be tested here: \url{https://huggingface.co/microsoft/DialoGPT-medium}.

% Dialogue generation is the essential precursor to this thesis' ultimate task of controlled dialogue generation.

% \len{The previous sentence feels out of the blue. Consider removing it or think of a way to create a natural flow towards it.}



\subsection{Controlled Dialogue Generation}
As mentioned previously in Section \ref{subsec:controlled_dialogue_generation}, controlled dialogue generation is the task of steering automatically generated conversational responses to possess desired attributes, like sentiment, topic, or more abstract writing style characteristics.
% Nowadays, dialogue systems like Siri, Alexa, or Google Assistant, play large roles making technology easier to use, it is of great commercial interest to be able to control (e.g., personalize) the style of their responses. Medical applications too have been found for controllable dialogue generation.
\cite{zeng-etal-2020-meddialog} explore the applications of fine-tuning large language models, like GPT, on (Mandarin and English) medical consultation data. The resulting dialogue systems succeed at generating clinically correct and human-like responses to patients' medical questions. Medical dialogue systems like these can help make healthcare services more accessible and aid medical doctors to improve patient care.

\cite{zheng2019personalized} investigate the problem of incorporating explicit personal characteristics in dialogue generation to deliver personalized conversation. They introduce a dataset \texttt{PersonalDialog}, which is a large-scale multi-turn dialogue dataset with personality trait labeling (i.e., \texttt{Age}, \texttt{Gender}, \texttt{Location}, \texttt{Interest Tags}, etc.) for a large number of speakers. \cite{zheng2019personalized} also propose persona-aware models that include a trait fusion module in the encoder-decoder framework to capture and address personality traits in dialogue generation. Persona-aware attention mechanisms and bias are used to incorporate personality information in the decoding process. All their tested classification and dialogue generation models are either variations of RNNs (such as LSTMs or gated recurrent units (GRUs)), convolutional neural networks (CNNs), or hybrids of these systems (LSTM-outputs fed into a CNN, known as recurrent convolutional neural networks (RCNNs)). The authors study the influence of age, gender, and location on dialogue classification and generation, and use both automatic (perplexity, trait accuracy, and generated response diversity measures) and human evaluation. They find dialogues to be distinguishable by gender (about 90.61\% test accuracy), then age (78.32\% test accuracy), and finally location (62.04\% test accuracy). Both automatic and human evaluation of the generated responses show that the best performing models benefit greatly from the persona-aware attention mechanism, possibly making a case to consider more attention-based architectures instead of RNNs.

Although the previously mentioned architectures are able to produce human-like conversational responses, sometimes even leveraging the fluency of large pre-trained LMs, they all suffer from the same computational drawback. They all require massive amounts of computational power to adapt their language styles, because in their cases, guided generation implies fine-tuning (or even retraining) large attribute-specific dialogue datasets. For general controlled text generation, this obstacle is overcome by \cite{dathathri2019plug}'s previously mentioned PPLM setup. The conversational analog of this idea, plug-and-play conversational model (PPCM), is proposed by \cite{madotto-etal-2020-plug}. Similar to PPLM, PPCM achieves guided dialogue generation via activation-space perturbations using easy to train attribute models. 
% In this configuration, they can achieve controllable response generation without needing dialogue data or having to fine-tune a large language model. 
Due to the computational complexity of PPLM's decoding process, PPLM is unusable as practical conversational system. PPCM solves this problem by using residual adapters \citep{bapna-firat-2019-simple} to tweak the decoding procedure such that it does not require more computational resources. 
% See Section \ref{sec:ppm} for a detailed explanation of the mechanisms behind PPLM and PPCM. 
\cite{madotto-etal-2020-plug} show, using both human and automatic evaluation, that PPCM can balance grammatical fluency and high degrees of attribute-adherence in its generated responses. PPCM uses DialoGPT as its base language model, and is tested for topical or sentimental attributes (i.e., positive, negative, sports, business, or science \& tech). 
Previous work on controlled text generation focuses on content (e.g., topical attributes, or sentiment), rather than more abstract linguistic features, which I hypothesize are more challenging to model and control. The previously mentioned work by \cite{zheng2019personalized} is a notable exception, as their approach deals with controlling dialogue systems for linguistic features, like age, gender, and geographical region. However, \cite{zheng2019personalized} still suffers from significant computational costs, because control is achieved by fine-tuning a large system for every specific set of attributes. 
% Furthermore, their proposed architectures are RNN-based, as opposed to my Transformer-based approach. My work therefore aims to extend the applicability of plug-and-play controlled generation to more abstract linguistic characteristics than those explored by \cite{dathathri2019plug} and \cite{madotto-etal-2020-plug}, and without the significant fine-tuning cost of \cite{zheng2019personalized}.

The work presented in this thesis extends the applicability of the Transformer-based Plug-and-Play controlled generation model to more abstract writing styles, namely the linguistic characteristics associated with certain age groups. Furthermore, we apply this adaptation to the task of dialogue generation. As a preliminary research objective, we aim to use text-based NLP models to detect age-related linguistic features from dialogue and discourse data. This preliminary experiment is presented in the next chapter.

% \len{TODO \begin{itemize}
%     \item Ask for Sandro's feedback on this last rephrased paragraph.
%     \item Is it worth mentioning that Zheng et al 2019 deals with Chinese Mandarin dialogue systems, and mine with English?
% \end{itemize} }