% \textbf{Things to keep in mind when writing this section:}
% \begin{itemize}
%     \item Doesn't have to be longer than 1 page.
%     \item (optional): anecdotal opener to draw attention.
%     \item Brief introduction to the topic of controllable text generation and adaptive dialogue systems.
%     \item Description of the research problem and your questions.
%     \item Placeholder for my contributions and approach.
%     \item Placeholder for overview of remainder of paper.
%     \item \textit{For consistency, maybe start it off with an introduction that you can re-use for your final version. Of course, this will be rewritten for later versions to include findings.}
%     \item The three most important papers to keep in mind for this section are: PPLM, DialoGPT, and Personalized Dialogue Generation with Diversified Traits
% \end{itemize}

\textbf{Captivating introduction to the thesis' topic by talking about recent years stuff.}
\begin{itemize}
    \item In recent years, impressive progress has been made in the development of conversational agents / dialogue systems \citep{mctear2020conversational}.
    \item However, artificial systems that can tune their language to that of a particular individual or group of users continue to pose more of a challenge. Recent examples of this line of research include adaptation at style level (Ficler and Goldberg, 2017), persona-specific traits (Zhang et al., 2018), or other traits such as sentiment (Dathathri et al., 2020).
    \item Endowing a dialogue system with personality traits to generate human-like conversation is a long-standing goal in AI \citep{edlund2008towards, scheutz2011toward}. (this one goes well with the statement about and the reference to Margot's work).
\end{itemize}

Endowing dialogue systems with the capability to emulate users' speaking styles to generate human-like conversation is a long-standing goal in artificial intelligence (AI) research \citep{edlund2008towards, scheutz2011toward}.
Despite impressive recent progress in the development of dialogue systems \citep{mctear2020conversational}, dialogue systems that can tune their language to that of a particular individual or group of users continue to pose more of a challenge.

\textbf{Motivate research}
\begin{itemize}
    \item Personalised interaction is of crucial importance to obtain systems that can be trusted by users and perceived as natural (van der Goot and Pilgrim, 2019), but most of all to be accessible to varying user profiles, rather than targeted at one particular user group (Zheng et al., 2019; Zeng et al., 2020).
\end{itemize}

\textbf{Talk about ``this work''}
\begin{itemize}
    \item more properly introduce controlled dialogue generation
    \item controlled dialogue generation can be used to adapt dialogue systems' linguistic style to that of user.
    \item controlled dialogue generation is...
    \item Research objectives
    \item Hypotheses? Or maybe not, since we discuss all of them in the experiment introductions
    \item 
\end{itemize}

\textbf{Contributions?}
\begin{itemize}
    \item ...
\end{itemize}

\textbf{Outline (and maybe briefly motivate the two-experiment) structure}
\begin{itemize}
    \item The rest of this thesis is structured as follows...
\end{itemize}

In recent years, we have witnessed promising advances in natural language processing (NLP) tasks, such as language modeling, reading comprehension, machine translation, controllable text generation, and conversational response generation \citep{radford2019language, DBLP:journals/corr/BahdanauCB14, dathathri2019plug, madotto-etal-2020-plug}. \cite{vaswani2017attention}'s Transformer architecture plays a central role in many of the state of the art (SotA) solutions to these problems. Transformer-based language models (LMs) pre-trained on massive amounts of textual data, most famously OpenAI's GPT-2 (Generative Pre-trained Transformer-2), have demonstrated their usefulness for several of the aforementioned NLP tasks \citep{radford2019language}. For instance, controllable text generation and producing dialogue responses have improved greatly because of GPT-based hybrid models. %Given the non-trivial requirements for sufficiently massive training corpora and computational resources, GPT-based solutions are worth considering for these two problems.

\len{CTG comes out of the blue in the following paragraph. Introduce it a little bit by describing what is is, and why/how it is an important task.}

\begin{itemize}
    \item Controllable text generation entails generating text samples that possess a predefined textual property, like having a positive sentiment, or being about a certain topic.
    \item Controlling more fine-grained linguistic properties, like resemblance of age-specific vernacular, still poses an important, yet unsolved/insufficiently studied (?) challenge.
    \item Personalized interaction between humans and AI systems is crucial to obtain systems that can be trusted by users and are perceived as natural.
    \item (Age-)adaptive language generation can be used to personalize AI-powered personal assistants like Siri and Alexa, improving user experience and trust.
    \item It is important for AI-power conversational agents to be accessible to varying user profiles, rather than targeted at one particular user group. 
    \item In this work, I/we focus on one aspect that may influence successful personalization of conversational agents: user age profile.
\end{itemize}

Controllable text generation (CTG) aims to enforce abstract properties, like writing style, on the passages being produced. Fine-tuning large-scale LMs for writing-style adaptation is extremely expensive, but \cite{dathathri2019plug} and \cite{li-etal-2020-optimus} propose methods that both excel at the task, while bypassing significant retraining costs. Dialogue response generation is the task of producing replies to a conversational agent's prompts, in a manner that is ideally both non-repetitive and relevant to the course of the conversation. With DialoGPT, \cite{zhang2019dialogpt} also manage to leverage GPT-2's powerful fluency for dialogue tasks, by framing them as language modeling tasks where multi-turn dialogue sessions are seen as long texts.

% CTG and dialogue response generation share the overarching objective of producing grammatically correct text that is distinct from any training instance. LJ/RF: this isn't necessarily correct. Every generated response doesn't have to be distinct from any training objective.

\len{Introduce dialogue response generation a bit more. Also emphasize its importance. And then introduce the combined task and its importance.}
A blend of CTG and dialogue response generation, i.e., controllable dialogue response generation, is an interesting and only partially explored route. It ties closely to one of Artificial Intelligence's long-standing goals of achieving human-like conversation with machines, as humans are known to adapt their language use to the characteristics of their interlocutor \citep{gallois2015communication}. Adaptive dialogue generation is difficult due to the challenge of representing traits, like age, gender, or other persona-labeled traits via language expression \citep{zheng2019personalized}.
% and the lack of persona trait labeled dialogue datasets. \cite{zheng2019personalized} explore the problem of personalized dialogue generation, and introduced \texttt{PersonalDialog} a large-scale multi-turn Chinese Mandarin dialogue dataset with personality trait labeling, and persona-aware adaptive dialogue generation models using RNNs and attention mechanisms. 

In this thesis, I investigate the problem of controllable dialogue generation, with a focus on adapting responses to users' age. As a preliminary research objective, I aim to study to what extent a classifier can detect age-related linguistic differences in natural language, and which features are most helpful in age-group detection. Do they (i.e., the linguistic or latent features exploited by the classifier) match the age-related informative features reported in previous work? 
After empirically confirming that speaker age detection is possible, I explore whether large-scale LMs, e.g. GPT-2, can be leveraged for text generation, controlled for age-groups. And what role does the used data play in the differences in output and performance between regular GPT-2 and controllable GPT-2?
Finally, my research focuses on the degree to which such a CTG model is successful in generating dialogue that is adaptive w.r.t. age, such that it has a detectable effect on the perception of the user.

\len{Fix this. }The remainder of this thesis is structured as follows: Chapter \ref{sec:background} positions the subject of controlled text generation in its theoretical background, and and \ref{sec:related_work} compares it to the most relevant related work. The methodology in Section \ref{sec:exp1_methods_exp_setup} gives detailed explanations of the most important modeling methods and techniques used for this research. \len{The code used to produce the results can be found on GitHub\footnote{\url{https://github.com/lennertjansen/msc-ai-thesis}}. (Is this the best place to mention this?)}

% The main contributions of this paper are ...

% The remainder of this work is structured as follows, ...

\begin{itemize}
    \item When introducing your own work and proposing your hypothesis, use the following argument: \textit{This idea that age prediction from text is more challenging than topic or sentiment prediction could be an indication that controlled language generation for age-differences is also a more nuanced problem than topical steered text generation.}
\end{itemize}

\textbf{Useful parts from the Clic-it paper's introduction you can work into this introduction (REVISE BEFORE USING):}

\begin{itemize}
    \item Research on developing conversational agents has experienced impressive progress, particularly in recent years \citep{mctear2020conversational}. 
    \item However, artificial systems that can tune their language to that of a particular individual or group of users continue to pose more of a challenge. Recent examples of this line of research include adaptation at style level (Ficler and Goldberg, 2017), persona-specific traits (Zhang et al., 2018), or other traits such as sentiment (Dathathri et al., 2020).
    \item Personalised interaction is of crucial importance to obtain systems that can be trusted by users and perceived as natural (van der Goot and Pilgrim, 2019), but most of all to be accessible to varying user profiles, rather than targeted at one particular user group (Zheng et al., 2019; Zeng et al., 2020).
    \item  In this work, we focus on one particular aspect that may influence conversational agent success: user age profile.
    \item We investigate whether the linguistic behaviour of conversational participants differs across age  groups using state-of-theart NLP models on purely textual data, without considering vocal cues. 
    \item We aim to detect age from characteristics of language use and adapt to this signal, rather than work from ground-truth metadata about user demographics. 
    \item \len{Important to mention} This is in the interest of preserving privacy, and from the perspective that while age and language use may have a relationship, this will not be linear (Pennebaker and Stone, 2003) and there are individual differences. 
    \item Previous work on age detection in dialogue has
    focused on speech features, which are known to systematically vary across age groups. For example, Wolters et al. (2009) learn logistic regression age classifiers from a small dialogue dataset using different acoustic cues supplemented with a small set of hand-crafted lexical features, while Li et al. (2013) develop SVM classifiers using acoustic and prosodic features extracted from scripted utterances spoken by participants interacting with an artificial system.
    \item In contrast to this line of work, we investigate whether different age groups can be detected from textual linguistic information rather than voice-related cues. We explore whether, and to what extent, various state-of-the-art NLP models are able to capture such differences in dialogue data as a preliminary step to age-group adaptation by conversational agents. \len{This could be a good sentence to bridge the aims of the two parts}
    \item We build on the work of Schler et al. (2006), who focus on age detection in written discourse using a   corpus of blog posts. The authors learn a Multi-Class Real Winnow classifier leveraging a set of pre-determined style- and content-based features, including part-of-speech categories, function words, and the 1000 unigrams with the highest information gain in the training set. They find that content features (lexical unigrams) yield higher accuracy (74\%) than style features (72\%), while their best results (76.2\%) are obtained with their combination. \len{Be mindful that this could also be used in CHapter 2}
    \item We extend this investigation in several key ways: (1) we leverage state-of-the-art NLP models that allow us to learn representations end-to-end, without the need to specify concrete features in advance; (2) we apply this approach to dialogue data, using a large-scale dataset of transcribed, spontaneous open-domain dialogues, and also use this approach to replicate the experiments of Schler et al. (2006) on disccourse; (3) we show that text-based models can indeed detect age-related differences, even in the case of very sparse signal at the level of dialogue utterances; and finally (4) we carry out an in-depth analysis of the models’ predictions to gain insight on which elements of language use are most informative. 
    \item Our work can be considered a first step toward the modeling of age-related linguistic adaptation by AI conversational systems. In particular, our results can inform future work on controlled text generation for dialogue agents (Dathathri et al., 2020; Madotto et al., 2020).
\end{itemize}

Oher phrases

\begin{itemize}
    \item Endowing a dialogue system with personality traits to generate human-like conversation is a long-standing goal in AI \citep{edlund2008towards, scheutz2011toward}. (this one goes well with the statement about and the reference to Margot's work).
\end{itemize}