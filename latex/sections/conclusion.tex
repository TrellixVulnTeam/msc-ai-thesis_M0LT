% \len{Revise this.}

In this thesis, I first investigate the extent to which text-based NLP-models can detect age-related linguistic features in dialogue data, and which features drive their predictions. Then, I study the extent to which age-adaptive dialogue generation is possible using Plug-and-Play language models (PPLM) \citep{dathathri2019plug}.

The results of the age detection experiments show that a fine-tuned BERT model is capable of detecting age-related linguistic features in dialogue utterances with reasonable accuracy, especially when the dialogue fragment is long enough to contain discriminative signal. However, simpler $n$-gram-based models achieve comparable performance, suggesting that, in dialogue, ‘local’ features can be indicative of the language of speakers from different age groups. This is shown to be the case, with both lexical and stylistic cues being informative to these models in this task. Furthermore, the age detection results informed the subsequent experiments about controlled dialogue generation using PPLM.

The controlled dialogue generation results show that it is possible to use PPLM to generate dialogue responses that possess detectable linguistic features associated with specific age groups. Discriminator-based PPLM-setups typically achieve higher levels of detectable control 
% (i.e., statistical resemblance to a specific writing style) 
than bag-of-words (BoW) based setups, but generate significantly more perplexing and repetitive responses. This could be attributable to the fact that BoW-based control is more local (i.e., at the token-level) and less invasive than discriminator-based control, which can operate at the structural level. 

Overall, I believe this thesis is a promising step towards the development of age-adaptive conversational systems.