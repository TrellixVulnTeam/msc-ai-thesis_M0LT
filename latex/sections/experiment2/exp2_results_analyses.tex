\newpage
\section{Controlled Text Generation Performance}
\label{sec:exp2_results}

% \len{Old text for the unprompted results. FROM HERE....}

% Table~\ref{tab:ctg_results_ws} reports the automated evaluation results of our controllable text generation models. It can be seen that uncontrolled GPT-2 baseline has a slight bias towards generating "young-sounding" language (57.5\% accuracy). Furthermore, it appears that perturbing GPT-2's output distribution with the 100 most common words across all ages results in a slight de-biasing of the generated text (54.1\% accuracy). Achieving detectable control seems possible, because all GPT-2-based models surpass both baselines in terms of accuracy, with the exception of both BoW-setups using the 100 most informative unigrams.

% Frequency-based BoW-models outperform those using the most informative unigrams, as illustrated by their higher average accuracy (66.75\% versus. 53.1\%), and lower average perplexity (27.48 versus 27.90). 
% % \len{Offer an explanation.} 
% Discriminator-based models achieve noticeably better accuracies, with an average improvement of 8.45\% over the best performing BoW-based models. However, discriminator-based models do show more signs of disfluency and repetitiveness compared to the BoW-models, as depicted by the worse perplexities and Dist-$n |_{n = 1,2,3}$ scores.

% % The accuracies of our uncontrolled DialoGPT baseline (78.1\%) and the 100MCW baseline (80.7\%), suggest that DialoGPT is heavily biased towards producing young-sounding language. This can be attributable to DialoGPT having been fine-tuned on Reddit threads, as the majority of Reddit users are between the ages 20 and 29~\footnote{\url{https://www.statista.com/statistics/1125159/reddit-us-app-users-age/}}
% % \len{Find a reference for this statement} 
% \citep{zhang2019dialogpt}. DialoGPT's strong propensity for generating younger sounding language makes it a less desirable choice for our human evaluation experiments, because it requires non-standard parameter settings to produce detectably older sounding text.

% Overall, the results show that, for most models, a plug-and-play approach to controlling generated dialogue responses to possess detectable age-specific linguistic features is achievable. The most promising models being either discriminator-based, or frequency-based bag-of-words models. Discriminator-based models achieve more detectable levels of control than their BoW-based counterparts, at the cost of perplexity and repetitiveness. This could be attributable to the more complex activation-space updates that are used by discriminator-models. Furthermore, GPT-2's preference to generate young-sounding language is severely less pronounced than that of DialoGPT, making it easier to control, given equal parameter settings.

% \len{...TO HERE}

The quantitative results of generating younger (19 to 29) and older (50 and over) sounding responses to neutral prompts are reported in Tables \ref{tab:ctg_results_ws_neutral_prompt_young_models} and \ref{tab:ctg_results_ws_neutral_prompt_old_model}, respectively. In these tables, the underlying language model being used in a setup (i.e., a row in a table) is indicated by the prefixes G- for GPT-2 and D- for DialoGPT. Furthermore, both tables report the results of the unperturbed GPT-2 and DialoGPT baselines (labeled G-baseline and D-baseline, respectively), and those of the 100 most common age-independent bag-of-words setups for both GPT-2 and DialoGPT (labeled G-100MCW and D-100MCW, respectively). The accuracies for these two setups (i.e., baseline and 100 most common words) are omitted because they do not aim to generate responses that resemble any target age group. Moreover, two bag-of-words (BoW) setups are reported per underlying language model (GPT-2 or DialoGPT): the frequency-based BoW setup (indicated by the suffix, -BoW$_{FB}$), and the 100 most informative unigram setup (indicated by the suffix, -BoW$_{100MIU}$). Detailed descriptions of how and why these aforementioned wordlists are constructed are provided in Section \ref{subsec:att_model_dev}. Finally, the discriminator-based setups are indicated by the suffix, -Discrim. The aforementioned reporting conventions also hold for the tables containing the results of response generation to younger and older sounding prompts (i.e., Tables \ref{tab:ctg_results_ws_young_prompt_young_model}, \ref{tab:ctg_results_ws_young_prompt_old_model}, \ref{tab:ctg_results_ws_old_prompt_young_model}, and \ref{tab:ctg_results_ws_old_prompt_old_model}). The results of those experiments are discussed in Section \ref{subsec:ctg_anal_prompt_class}.

As one would expect, Tables \ref{tab:ctg_results_ws_neutral_prompt_young_models} and \ref{tab:ctg_results_ws_neutral_prompt_old_model} show that the GPT-2 baseline consistently scores among the best on perplexity (best perplexity compared to young generation models, and second best compared to old-generation models) and diversity of generation. Similarly, the unperturbed DialoGPT baseline also scores best in terms of perplexity, when compared to other DialoGPT-based setups. This means that the responses generated by GPT-2 and DialoGPT are found to be among the least perplexing to GPT-1. This is unsurprising, as GPT-2, and thereby also DialoGPT, is pre-trained in similar fashion to GPT-1 \citep{radford2018improving, radford2019language, zhang2019dialogpt}. Additionally, the target probabilities ($\bar{P}_Y = 0.62$ in Table~\ref{tab:ctg_results_ws_neutral_prompt_young_models}, and $\bar{P}_O = 0.38$ in Table~\ref{tab:ctg_results_ws_neutral_prompt_old_model}) indicate that the GPT-2 baseline is biased towards generating young language. I.e., GPT-2 is inclined to produce responses, given a neutral prompt, that are likely to contain features learned to be young by BERT$_{FT}$. Moreover, DialoGPT has very strong bias towards generating younger sounding responses, given a neutral prompt (0.76 average probability to contain detectable young features). This is most likely due to DialoGPT having been fine-tuned on Reddit threads, as the majority of Reddit users are between the ages 20 and 29~\footnote{\url{https://www.statista.com/statistics/1125159/reddit-us-app-users-age/}}
\citep{zhang2019dialogpt}.

The G-BoW$_{100MCW}$ setup performs on par with baseline w.r.t. perplexity and diversity (second best perplexity, second best Dist-2, best Dist-3), when compared to the young generation models. A similar pattern can be seen for old models, where G-100MCW has the second best Dist-2, and best Dist-3 scores. Additionally, the target probabilities seem virtually unaffected by the 100MCW setups, suggesting that perturbing GPT-2's output with an age-agnostic bag-of-words of the most frequently used words in the dialogue dataset does not noticeably shift the writing style towards that of the younger or older age group. This is to be expected, as such a wordlist should be an unbiased representation of the dataset's language style, given similar sample sizes per class.

BoW-based models seem to generate responses that are slightly more likely to contain features of the target age (young GPT2-BoW$_{FB}$ models result in 0.06 target probability improvement over the baseline, and old GPT2-BoW$_{FB}$ model in 0.04 target probability improvement over baseline). However, these differences are could also be due to randomness. For the 50-plus style GPT-2-based response models, the BoW$_{100MIU}$ setup does not manage to generate older sounding language than the baseline. Furthermore, BoW-based models seem to barely impact the syntactical structure of generated responses, because changes are made at the token-level \cite{dathathri2019plug}. This is confirmed by the barely altered perplexity and Dist-scores. \len{But this will be studied in more detail in the qualitative analyses.} 

The GPT-2 discriminator-based old-style model manages to generate responses that more convincingly resemble the style of the target group (0.38 $\bar{P}_O$ improvement over the GPT-2 baseline). However, this comes at the cost of perplexity ($+19.65$ compared to baseline) and diversity (much lower dist-scores and higher corresponding standard deviations). By contrast, the GPT-2 discriminator-based young setup does not generate convincingly more young-sounding responses (only 0.04 average target probability improvement over baseline), despite having noticeably worse and less precise perplexity ($4.59$ increase over baseline) and diversity.

The unperturbed DialoGPT baseline produces more perplexing and less diverse text than GPT-2 according to GPT-1 perplexity and the Dist-$n |_{n = 1,2,3}$ scores. The higher perplexity is to be expected, as DialoGPT pre-training and fine-tuning method deviates more from GPT-1's than GPT-2, making it likely to produce more unexpected sentences \cite{zhang2019dialogpt}. When using DialoGPT as an underlying language model, the BoW-based models (including 100MCW) seem to reinforce young-bias for DialoGPT, regardless of age (i.e., for all young-targeted BoW-based models $\bar{P}_Y$ goes up, and $\bar{P}_O$ goes down for all old-targeted BoW-based models). And the discriminator-based DialoGPT models, are superior w.r.t. target probability (+0.10 $\bar{P}_Y$ difference compared to DialoGPT baseline for young-models, and +0.34 $\bar{P}_O$ compared to baseline for old-models). However, this again comes at the cost of much higher and more volatile perplexity.

Overall, according to these results it seems to be possible to control dialogue responses for a certain age group. The used underlying language models are biased (in varying degrees) towards generating younger-sounding language. In these tested PPLM-setups, there seems to be a tradeoff between increased control and decreasing perplexity and diversity of generated language. Furthermore, the BoW-based models achieve less detectable levels of control, but preserve the fluency and diversity of generated text. In other words, the discriminator-based models make more invasive changes to the unperturbed sentences, which can result in less fluent and more repetitive text. However, they do produce more detectably age-appropriate passages.

\textbf{Initial observations and interpretations neutrally prompted ctg results (Tables \ref{tab:ctg_results_ws_neutral_prompt_young_models} and \ref{tab:ctg_results_ws_neutral_prompt_old_model})}
\begin{itemize}
    \item Style of prompt heavily influences control of response. Also confirmed by Tables \ref{tab:ctg_results_ws_young_prompt_young_model}, \ref{tab:ctg_results_ws_young_prompt_old_model}, \ref{tab:ctg_results_ws_old_prompt_young_model}, and \ref{tab:ctg_results_ws_old_prompt_old_model}. Remind reader of ctg formula $p(\textbf{x} | a, \texttt{prompt})$.
    % \item GPT-2 baseline scores best w.r.t. fluency (lowest perplexity) and diversity of generation (highest Dist-2, second highest Dist-3).
    % \item GPT-2 + BoW$_{100MCW}$ on par with baseline w.r.t. fluency and diversity (second best perplexity, second best Dist-2, best Dist-3).
    % \item Very similar pattern for old models: baseline second best perplexity and Dist-3, best Dist-1 and Dist-2; 100MCW second best Dist-2, and best Dist-3.
    % \item Baseline is moderately biased towards generating young language. I.e., GPT-2 is inclined to produce responses, given a neutral prompt, that are likely to contain features learned to be young by BERT$_{FT}$.
    % \item BoW-based models seem to result in language that is slightly more likely to contain features of target age (Young bow-models result in 0.06 probability increase wrt baseline, and old-bow-fb model in 0.04 increase wrt baseline). Differences are also possibly due to randomness.
    % \item BoW-based models barely impact the syntactical structure of generated sequences, i.e., changes made at lexical-level. This is shown by the barely altered perplexity (sometimes improved , G-B$_{100MIU,O}$ 0.25 lower average perplexity than baseline), and Dist-scores. \len{But this will be studied in more detail in the qualitative analyses.} 
    % \item BoW-fb slightly superior to BoW-100MIU -> consistently higher accuracy for BERT$_{FT}$.
    % \item For Old-models, BoW still doesn't fully overcome young-bias to result in convincingly old language.
    % \item Discriminator-based old model manages to generate language that is more convincingly similar to target age (0.38 old prob improvement). This comes at the cost of fluency and diversity (much higher perplexity and std wrt baseline), noticeable lower dist-scores and higher std's.
    % \item GPT2-disc young not convincingly more young sounding response. Noticeably worse and less precise fluency and diversity though. Only 0.04 average probability improvement.
    % \item DialoGPT has very strong young-bias, given a neutral prompt (0.76 average probability to contain detectable young features). --> Most likely due to DialoGPT being GPT-2, fine-tuned on Reddit Thread data \citep{zhang2019dialogpt} and include reddit age dist reference.
    % \item DialoGPT baseline produces less fluent and less diverse text than GPT-2 according to GPT-1 perplexity.
    % \item BoW-based models (including 100MCW) seem to reinforce young-bias for DialoGPT, regardless of age (young prob goes up for both BoW, and old prob goes down for both BoW-models).
    % \item Discriminator based models, again, outperform significantly w.r.t. target probability (0.10 prob difference wrt baseline for young, and 0.34 prob difference wrt baseline for old). Again, at the cost of on average worse and more volatile perplexity.
    \item Janie's suggestion: it could be that there are some detectable young-sounding tokens that make BoW-based young control easier, and that old-sounding features are more salient at the structural/syntactical level and harder to control for.
    \item Overall, it seems to be possible to control dialogue responses for a certain age group. The used base language models are biased towards generating young-sounding language. In the current PPLM-setup, there seems to be a tradeoff between increased control and decreasing fluency and diversity. BoW-based models achieve less detectable levels of control, but preserve the fluency and diversity of generated text. Discriminator based models make more invasive changes to the unperturbed sentences, which can result in less fluent and more repetitive text. However, they do produce more detectably age-appropriate passages.
    \item \len{TODO - Examine the nonsensical generated sequences that are correctly labeled as old or young. What patterns do you see? It could be that BERT$_{FT}$ is picking up non-language patterns that give away age.}
\end{itemize}

\begin{table*}[h]
    \centering
    \begin{tabular}{l | c c c c | c c}
    \toprule
    \textbf{Model} & \textbf{ppl.} & \textbf{Dist-1} & \textbf{Dist-2} & \textbf{Dist-3} & $\boldsymbol{\bar{P}_Y}$ & \textbf{Acc.}\\
    % -plus)}$\\
     & $\downarrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better\\
    \midrule
    \midrule
    G-baseline & \textbf{27.50} (6.58) & 0.87 (0.09) & \textbf{0.94} (0.04) & \textcolor{blue}{0.90} (0.06) & 0.62 (0.42) & -\\
    G-100MCW & \textcolor{blue}{27.56} (6.60) & 0.86 (0.10) & \textcolor{blue}{0.93} (0.04) & \textbf{0.90} (0.05) & 0.63 (0.42) & -\\
    \midrule
    G-BoW$_{FB}$ & 27.91 (7.18) & 0.87 (0.10) & 0.93 (0.05) & \textcolor{blue}{0.90} (0.06) & 0.69 (0.41) & 70.4\%\\
    G-BoW$_{100MIU}$ & 28.37 (7.31) & 0.87 (0.09) & \textcolor{blue}{0.93} (0.04) & \textcolor{blue}{0.90} (0.06) & 0.67 (0.41) & 67.4\%\\
    \midrule
    G-Discrim & 32.09 (18.98) & 0.77 (0.20) & 0.86 (0.13) & 0.84 (0.15) & 0.66 (0.43) & 67.8\%\\
    \midrule
    \midrule
    D-baseline & 37.52 (12.06) & 0.86 (0.13) & 0.90 (0.08) & 0.85 (0.10) & 0.76 (0.37) & -\\
    D-100MCW & 37.80 (10.89) & 0.85 (0.14) & 0.89 (0.10) & 0.85 (0.10) & 0.82 (0.33) & -\\
    \midrule
    D-BoW$_{FB}$ & 38.53 (12.64) & 0.87 (0.12) & 0.90 (0.08) & 0.86 (0.10) & 0.82 (0.33) & 83.0\%\\
    D-BoW$_{100MIU}$ & 38.67 (11.70) & \textcolor{blue}{0.88} (0.11) & 0.91 (0.07) & 0.86 (0.10) & \textbf{0.87} (0.28) & \textcolor{blue}{88.5\%}\\
    \midrule
    D-Discrim & 42.01 (16.94) & \textbf{0.90} (0.12) & 0.86 (0.14) & 0.77 (0.22) & \textcolor{blue}{0.86} (0.29) & \textbf{85.9\%}\\
    \bottomrule
    \end{tabular}
    \caption{\len{Neutral prompt - Young model} Results of age-controlled language generation. ppl. is perplexity w.r.t. GPT-1. Dist-n is number of distinct n-grams normalized by text length, as a measure of diversity. $\bar{P}(Young)$ is the sample's average probability to contain features learned to be young by BERT$_{FT}$. Acc. is BERT$_{FT}$'s accuracy when classifying the row's samples.}
    \label{tab:ctg_results_ws_neutral_prompt_young_models}
\end{table*}

\begin{table*}[h]
    \centering
    \begin{tabular}{l | c c c c | c c }
    \toprule
    \textbf{Model} & \textbf{ppl.} & \textbf{Dist-1} & \textbf{Dist-2} & \textbf{Dist-3} & $\boldsymbol{\bar{P}_O}$ & \textbf{Acc.}\\
    % -plus)}$\\
     & $\downarrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better\\
    \midrule
    \midrule
    G-baseline & \textcolor{blue}{27.50} ($\pm$6.58) & \textbf{0.87} ($\pm$0.09) & \textbf{0.94} ($\pm$0.04) & \textcolor{blue}{0.90} ($\pm$0.06) & 0.38 ($\pm$0.42) & -\\
    G-100MCW & 27.56 ($\pm$6.60) & 0.86 ($\pm$0.10) & \textcolor{blue}{0.93} ($\pm$0.04) & \textbf{0.90} ($\pm$0.05) & 0.37 ($\pm$0.42) & -\\
    \midrule
    G-BoW$_{FB}$ & 27.58 ($\pm$7.07) & 0.86 ($\pm$0.10) & \textcolor{blue}{0.93} ($\pm$0.04) & \textcolor{blue}{0.90} ($\pm$0.06) & 0.42 ($\pm$0.42) & 43.0\%\\
    G-BoW$_{100MIU}$ & \textbf{27.25} ($\pm$6.15) & \textbf{0.87} ($\pm$0.09) & \textcolor{blue}{0.93} ($\pm$0.04) & \textcolor{blue}{0.90} ($\pm$0.06) & 0.38 ($\pm$0.42) & 37.4\%\\
    \midrule
    G-Discrim & 47.15 ($\pm$47.56) & 0.73 ($\pm$0.24) & 0.75 ($\pm$0.28) & 0.75 ($\pm$0.27) & \textbf{0.76} ($\pm$0.36) & \textbf{74.3\%}\\
    \midrule
    \midrule
    D-baseline & 37.52 ($\pm$12.06) & 0.86 ($\pm$0.13) & 0.90 ($\pm$0.08) & 0.85 ($\pm$0.10) & 0.24 ($\pm$0.37) & -\\
    D-100MCW & 37.80 ($\pm$10.89) & 0.85 ($\pm$0.14) & 0.89 ($\pm$0.10) & 0.85 ($\pm$0.10) & 0.18 ($\pm$0.33) & -\\
    \midrule
    D-BoW$_{FB}$ & 37.85 ($\pm$11.17) & 0.87 ($\pm$0.12) & 0.90 ($\pm$0.08) & 0.86 ($\pm$0.09) & 0.22 ($\pm$0.35) & 21.5\%\\
    D-BoW$_{100MIU}$ & 37.91 ($\pm$12.27) & \textcolor{blue}{0.87} ($\pm$0.11) & 0.90 ($\pm$0.07) & 0.85 ($\pm$0.10) & 0.22 ($\pm$0.34) & 21.9\%\\
    \midrule
    D-Discrim & 41.17 ($\pm$20.72) & 0.87 ($\pm$0.12) & 0.89 ($\pm$0.13) & 0.83 ($\pm$0.16) & \textcolor{blue}{0.57} ($\pm$0.41) & \textcolor{blue}{56.7\%}\\
    \bottomrule
    \end{tabular}
    \caption{\len{Neutral prompt - Old model} Results of age-controlled language generation. Perplexity is perplexity w.r.t. GPT-1. Dist-n is number of distinct n-grams normalized by text length, as a measure of diversity. $\boldsymbol{\bar{P}_Y}$ and $\boldsymbol{\bar{P}_O}$ are the respective average young and old probabilities assigned by the best BERT$_{FT}$. Acc. is the best BERT model's accuracy when classifying the row's samples.}
    \label{tab:ctg_results_ws_neutral_prompt_old_model}
\end{table*}


% TABLE 5.6 WITH YOUNG AND OLD PROB. JUST IN CASE %
% \begin{table*}[h]
%     \centering
%     \begin{tabular}{l c c c c c c c}
%     \toprule
%     \textbf{Model} & \textbf{ppl.} & \textbf{Dist-1} & \textbf{Dist-2} & \textbf{Dist-3} & \textbf{Young prob.} & \textbf{Old prob.} & \textbf{Acc.}\\
%     % -plus)}$\\
%      & $\downarrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & - & - & $\uparrow$ better\\
%     \midrule
%     \midrule
%     Baseline & 27.45 ($\pm$7.27) & 0.90 ($\pm$0.10) & 0.92 ($\pm$0.05) & 0.86 ($\pm$0.09) & 0.52 ($\pm$0.32) & 0.48 ($\pm$0.32) & 57.5\%\\
%     \midrule
%     B$_{100MCW}$ & 26.68 ($\pm$8.77) & 0.89 ($\pm$0.10) & 0.92 ($\pm$0.05) & 0.86 ($\pm$0.09) & 0.50 ($\pm$0.29) & 0.50 ($\pm$0.29) & 51.7\%\\
%     B$_{Y, FB}$ & 27.11 ($\pm$7.45) & \textbf{0.91} ($\pm$0.09) & \textbf{0.92} ($\pm$0.04) & \textbf{0.87} ($\pm$0.09) & 0.60 ($\pm$0.29) & 0.40 ($\pm$0.29) & 68.3\%\\
%     B$_{O, FB}$ & 25.99 ($\pm$6.41) & 0.88 ($\pm$0.11) & 0.92 ($\pm$0.05) & 0.86 ($\pm$0.09) & 0.35 ($\pm$0.31) & 0.65 ($\pm$0.31) & 62.5\%\\
%     B$_{Y, 100MIU}$ & 28.48 ($\pm$11.96) & 0.88 ($\pm$0.12) & 0.91 ($\pm$0.06) & 0.86 ($\pm$0.10) & 0.62 ($\pm$0.31) & 0.38 ($\pm$0.31) &69.2\%\\
%     B$_{O, 100MIU}$ & \textbf{25.57} ($\pm$7.44) & 0.88 ($\pm$0.11) & 0.92 ($\pm$0.05) & \textbf{0.87} ($\pm$0.09) & 0.38 ($\pm$0.31) & 0.62 ($\pm$0.31) & 58.3\%\\
%     \midrule
%     D$_{Y, GPT2}$ & 33.02 ($\pm$12.24) & 0.85 ($\pm$0.16) & 0.89 ($\pm$0.07) & 0.83 ($\pm$0.12) & 0.70 ($\pm$0.31) & 0.30 ($\pm$0.31) & 73.9\%\\
%     D$_{O, GPT2}$ & 32.86 ($\pm$18.08) & 0.80 ($\pm$0.21) & 0.84 ($\pm$0.13) & 0.79 ($\pm$0.19) & 0.37 ($\pm$0.29) & 0.63 ($\pm$0.29) & 63.3\%\\
%     D$_{Y, GPT2*}$ & 30.98 ($\pm$13.95) & 0.86 ($\pm$0.15) & 0.90 ($\pm$0.06) & 0.84 ($\pm$0.11) & \textcolor{blue}{0.76} ($\pm$0.29) & 0.29 ($\pm$0.29) & 80.0\%\\
%     D$_{O, GPT2*}$ & 34.81 ($\pm$26.76) & 0.84 ($\pm$0.17) & 0.85 ($\pm$0.13) & 0.77 ($\pm$0.23) & 0.31 ($\pm$0.25) & \textcolor{red}{0.69} ($\pm$0.25) & 75.8\%\\
%     \bottomrule
%     \end{tabular}
%     \caption{Results of age-controlled language generation. Perplexity is perplexity w.r.t. GPT-1. Dist-n is number of distinct n-grams normalized by text length, as a measure of diversity. Young and old accuracy are the assigned probabilities of belonging to the young or old age categories.}
%     \label{tab:ctg_results}
% \end{table*}


%%% THIS ISN'T RELEVANT ANYMORE --CONSIDER DELETING IT %%%%%%%%%%%%%%%%%%%%%%%%%
% \paragraph{Notes on Table \ref{tab:ctg_results}}
% \begin{itemize}
%     \item These are initial results.
%     \item All metrics are averaged over 120 samples: 30 samples per group of sequence lengths 8, 16, 32, and 64.
%     \item Young and old accuracy (last two columns) denote the probability of belonging to the young or old age-groups assigned by the best performing BERT-based classifier.
%     \item I use the same parameter settings as Table 6 of \cite{dathathri2019plug} to make the results comparable, i.e.:
%     \begin{itemize}
%         \item Step-size 0.02. Step-size is $\alpha$ in Equation \ref{eq:H_update_rule}.
%         \item Temperature 1.0.
%         \item Number of update iterations: 3.
%         \item $\gamma$ 1.5.
%         \item GM-scale 0.9.
%         \item KL-scale 0.01.
%     \end{itemize}
%     \item The current baseline is uncontrolled/unperturbed GPT-2.
%     \item There are four settings for BoW-based control:
%     \begin{itemize}
%         \item Young frequency-based wordlist.
%         \item Old frequency-based wordlist.
%         \item Young + most informative unigrams as wordlist.
%         \item Old + most informative unigrams as wordlist.
%     \end{itemize}
%     \item Initial observations:
%     \begin{itemize}
%         \item Fractions of distinct uni-,bi, and trigrams do not change.
%         \item Perplexity seems to improve when controlling generation for each age-group, which isn't necessarily what one would expect.
%         \item The baseline starts off with a higher average probability of belonging to the young age group
%         \item Controlling for young-language does result in a slightly greater assigned probability of belonging to young age-bracket.
%         \item Controlling for old-language results in a doubling of the assigned probability of belonging to the old age-bracket.
%     \end{itemize}
% \end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{itemize}
    \item \len{Include examples of same original sequence being perturbed differently at the unigram-level between corresponding young and old BoW-based CTG. E.g., \textit{I think you're a nice person (old)} vs. \textit{I think you're a nice guy (young)}}
\end{itemize}

% \subsubsection{Frequency-based wordlist generation}

% Steps taken to create age-specific wordlists (full imbalanced BNC used):
% \begin{itemize}
%     \item Remove all stopwords. List of stopwords from NLTK's English stopword list. \textbf{TODO: does this make sense? What if differences in use of stopwords are strong indicators of an age-group's speech?}
%     \item Order all unique words by frequency per age-group.
%     \item For both lists, keep the words that account for at least 80\% of the respective cumulative probability densities.
%     \item From both sets of words, remove the words that are in the \textit{union} (i.e., the overlapping set) of the young and old sets.
%     \item For both sets, order the words by frequency.
%     \item For both remaining lists, keep the words that account for at least 80\% of the respective cumulative probability densities.
%     \item \textbf{TODO:} remove curse-words?
%     \item Resulting wordlist lengths:
%         \begin{itemize}
%             \item Young (19-29): 90 words
%             \item Old (50 plus): 225 words
%         \end{itemize}
% \end{itemize}

% \subsubsection{Most informative unigrams as wordlists}

% \subsection{Discriminator-based control}




% \textbf{Notes on the experimental details of Table \ref{tab:ctg_results_ws}:}

% \begin{itemize}
%     \item All sequences are generated unconditionally. I.e., from $\texttt{|<endoftext>|}$ token.
%     \item All results are averaged over 240 samples.
%     \item 
% \end{itemize}


\section{Controlled Text Generation Analyses}
\label{sec:exp2_analyses}

\textit{By means of quantitative and qualitative analyses, we seek to study which relationships drive the grammatical quality and attribute relevance of generated output. We study the relationship between fluency and control, the effects of sequence length, and visualize attention mechanisms. Finally, we provide qualitative inspections of various cases, i.e., high versus low perplexity or assigned BERT$_{FT}$ probability, and a human evaluation of linguistic quality.}

% \len{Introduce the ctg analyses, like we do for the classification results. Talk about which models we're comparing, and why (probably the best performing ones from each class, i.e., best-bow, best-discrim, and best DGPT?... \textit{By means of quantitative and qualitative analyses, we seek to study which relationships drive the quality and control of generated output...  We start by studying the relationship between fluency and control (quant.), ... the effects of sequence length (quant.), ..., visualize attention mechanisms (quant.}. Then we ... summary stats. and qualitative inspection of various cases, i.e., high/low ppl., high/low prob. (qual)., ...and human eval (qual). }

\section{Controlled Dialogue Generation Analyses}

\len{TODO - Add examples of generated sequences along with their model's configurations, age-group, etc. Similar to dialogue snippets earlier.}

\subsection{The Relationship between Perplexity and Target Probability \len{Think of better title}}

Figure~\ref{fig:ctg_lineplot_fluency_vs_control} attempts to depict the relationship between fluency and control, as measured by perplexity and BERT's classification accuracy, respectively. On the y-axis, ``mean accuracy'' refers to the average fraction of generated sequences, controlled for young or old language, that are correctly labeled as such by Experiment 1's best BERT classifier. The bars around the averages in Figure~\ref{fig:ctg_lineplot_fluency_vs_control} are 90\% confidence intervals.
% It can be seen as a proxy for control, because it indicates how resemblant of an age group's vernacular a generated text is deemed to be. 
% Perplexity, measured by a different language model (GPT-1 \citep{radford2018improving}), is a measure of a language model's uncertainty when posed with the task of predicting a succession of words. Assuming a language model to be a reliable representation of relationships within an actual language, low perplexity can serve as a rough proxy for fluency of a text. However, a major caveat of perplexity is that it only measures uncertainty w.r.t. one language model, making it less generalizable. To slightly reduce this effect, we choose to evaluate perplexity with respect to a different language model than the one used for generation.
% \len{Disclose the confidence interval level}
It appears that increasing perplexity is slightly negatively correlated with accuracy. It is also clear from Figure~\ref{fig:ctg_lineplot_fluency_vs_control} that uncertainty about prediction strongly increases for greater perplexity. These two observations indicate that sentences deemed less coherent by GPT-1 tend to be harder to classify by BERT$_{FT}$ with certainty. BERT$_{FT}$ is pre-trained and fine-tuned to pick up syntactic features from dialogue that can indicate a speaker's age. It is therefore plausible that structural deviations from proper syntax (i.e., high perplexity) can obfuscate the age-related linguistic signal BERT$_{FT}$ leverages. Finally, it seems that, on average, the discriminator-based models are more capable of producing correctly classifiable high-perplexity sentences. \len{Why would that be?} However, none of the differences between the average accuracies are statistically significant at the 10\% level, so this conclusion should be taken tentatively.

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_gpt2_disc_np_y.png}
        \caption{}
        \label{subfig:barplot_ppl_target_prob_np_gpt2_disc_young}
     \end{subfigure}
    %  \hfill
     \quad
     \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_gpt2_disc_np_o.png}
        \caption{}
        \label{subfig:barplot_ppl_target_prob_np_gpt2_disc_old}
     \end{subfigure}
    \medskip
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_gpt2_bow_fb_np_y.png}
        \caption{}
        \label{subfig:barplot_ppl_target_prob_np_gpt2_bow_young}
     \end{subfigure}
    %  \hfill
    \quad
     \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_gpt2_bow_fb_np_o.png}
        \caption{}
        \label{subfig:barplot_ppl_target_prob_np_gpt2_bow_old}
     \end{subfigure}
    \caption{Mean target probability ($x$-axes) assigned to GPT-2-based models' samples by BERT$_{FT}$ for increasing ranges of GPT-1 perplexity ($y$-axes). Error bars are 95\% confidence intervals.}
    \label{fig:barplot_ppl_target_prob_np_gpt2}
\end{figure}

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_dgpt_disc_np_y.png}
        \caption{}
        \label{subfig:barplot_ppl_target_prob_np_dgpt_disc_young}
     \end{subfigure}
    %  \hfill
     \quad
     \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_dgpt_disc_np_o.png}
        \caption{}
        \label{subfig:barplot_ppl_target_prob_np_dgpt_disc_old}
     \end{subfigure}
    \medskip
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_dgpt_bow_miu_np_y.png}
        \caption{}
        \label{subfig:barplot_ppl_target_prob_np_dgpt_bow_young}
     \end{subfigure}
    %  \hfill
    \quad
     \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_dgpt_bow_miu_np_o.png}
        \caption{}
        \label{subfig:barplot_ppl_target_prob_np_dgpt_bow_old}
     \end{subfigure}
    \caption{Mean target probability ($y$-axes) assigned to DialoGPT-based models' samples by BERT$_{FT}$ for increasing ranges of GPT-1 perplexity ($x$-axes). Error bars are 95\% confidence intervals.}
    \label{fig:barplot_ppl_target_prob_np_dgpt}
\end{figure}

\len{\textbf{Observed patterns in perplexity target-prob plots}}:

\begin{itemize}
    \item For GPT2-based Old models (both discrim (Figure~\ref{subfig:barplot_ppl_target_prob_np_gpt2_disc_old}) and bow (Figure~\ref{subfig:barplot_ppl_target_prob_np_gpt2_bow_old})), there is a very clear pattern of increasing perplexity coinciding with higher assigned target probabilities. Responses with relatively high perplexities (50+) are significantly more likely to contain features learned to be old by BERT$_{FT}$. This suggests there could be a tradeoff between increased levels of attribute relevance (i.e., control) and fluency (i.e., lower perplexity). High-perplexity responses are of the GPT2-old models are also assigned probabilities with more precision (i.e., smaller confidence region).
    \item For the GPT-2 Young models' responses we observe a pattern of slight increase of average assigned target probability between low (0-25) and medium (25-50) perplexity, followed by a extreme decrease of assigned target probability and associated precision for high-perplexity responses.
    \item DialoGPT's young-bias is noticeable in Figures~\ref{subfig:barplot_ppl_target_prob_np_dgpt_disc_young} and \ref{subfig:barplot_ppl_target_prob_np_dgpt_bow_young}: all high average target probabilities with relatively high certainty.
    \item No clear pattern of tradeoff between perplexity and target probability in DialoGPT-based models.
    \item BERT$_{FT}$ seems to have least certainty (i.e., low precision aka high variance) about low-perplexity responses in every case, except DialoGPT-BoW Young (Figure~\ref{subfig:barplot_ppl_target_prob_np_dgpt_bow_young}).
    \item \len{Using the term fluency as a generalization of perplexity can be misleading. Think of another word, just use perplexity, or provide a disclaimer.}
\end{itemize}


\subsection{The Effects of Generated Response Length \len{Think of better title}}

\begin{itemize}
    \item \textit{Main question: how is generated sequence length related to fluency and control?}
    
    \item \textit{Study the relationship between generated sequence length (measured in number of tokens) and automated evaluation metrics (i.e., perplexity, dist-n, and accuracy).}
    
    \item \textit{For every metric and for (all?) models, plot sequence length on the x-axis, and the average metric with confidence intervals on the y-axis.}
    
    \item \textit{Which patterns do you observe?} 
\end{itemize}

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.49\textwidth}
        \centering
\includegraphics[width=1\columnwidth]{figures/exp2/sequence_length/lineplot_len_acc_best_gpt2_disc_bow_neutral_prompt_ci_95_errstyle_band.png}
        \caption{}
        \label{subfig:lineplot_length_acc_np_gpt2}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/sequence_length/lineplot_len_acc_best_dgpt_disc_bow_neutral_prompt_ci_95_errstyle_band.png}
        \caption{}
        \label{subfig:lineplot_length_acc_np_dgpt}
     \end{subfigure}
        \caption{Mean BERT$_{FT}$ accuracy. GPT-2-based models (left), DialoGPT-based models (right). Translucent error bands represent 95\% confidence intervals. Plots best viewed in color.}
        \label{fig:lineplots_length_acc_np_gpt2_dgpt}
\end{figure}

\len{\textbf{Patterns in Figure~\ref{fig:lineplots_length_acc_np_gpt2_dgpt}}}:
\begin{itemize}
    \item No clear trends.
    \item BoW-based Old (GPT-2 and DialoGPT) has significantly lower accuracy at almost every length bracket.
    \item Shortest responses generated by GPT-2-based models appear to be most challenging to classify for BERT$_{FT}$.
\end{itemize}

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.49\textwidth}
        \centering
\includegraphics[width=1\columnwidth]{figures/exp2/sequence_length/lineplot_len_ppl_best_gpt2_disc_bow_neutral_prompt_ci_95_errstyle_band.png}
        \caption{}
        \label{subfig:lineplot_length_ppl_np_gpt2}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/sequence_length/lineplot_len_ppl_best_dgpt_disc_bow_neutral_prompt_ci_95_errstyle_band.png}
        \caption{}
        \label{subfig:lineplot_length_ppl_np_dgpt}
     \end{subfigure}
        \caption{Perplexity. GPT-2-based models (left), DialoGPT-based models (right). Translucent error bands represent 95\% confidence intervals. Plots best viewed in color.}
        \label{fig:lineplots_length_ppl_np_gpt2_dgpt}
\end{figure}

\len{\textbf{Patterns in Figure~\ref{fig:lineplots_length_ppl_np_gpt2_dgpt}}:}
\begin{itemize}
    \item Perplexity decreases for increasing response length. Longer responses are deemed more plausible by GPT-1.
    \item GPT2-Discrim Old significantly worse perplexity at 5\% level for medium length responses. (is also best model setup w.r.t. target-prob improvement over baseline if i'm not mistaken).
    
\end{itemize}

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.49\textwidth}
        \centering
\includegraphics[width=1\columnwidth]{figures/exp2/sequence_length/lineplot_len_dist1_best_gpt2_disc_bow__neutral_prompt_ci_95_errstyle_band.png}
        \caption{}
        \label{subfig:lineplot_length_dist1_np_gpt2}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/sequence_length/lineplot_len_dist1_best_dgpt_disc_bow__neutral_prompt_ci_95_errstyle_band.png}
        \caption{}
        \label{subfig:lineplot_length_dist1_np_dgpt}
     \end{subfigure}
        \caption{Dist-1. GPT-2-based models (left), DialoGPT-based models (right). Translucent error bands represent 95\% confidence intervals. Plots best viewed in color.}
        \label{fig:lineplots_length_dist1_np_gpt2_dgpt}
\end{figure}

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.49\textwidth}
        \centering
\includegraphics[width=1\columnwidth]{figures/exp2/sequence_length/lineplot_len_dist2_best_gpt2_disc_bow_neutral_prompt_ci_95_errstyle_band.png}
        \caption{}
        \label{subfig:lineplot_length_dist2_np_gpt2}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/sequence_length/lineplot_len_dist2_best_dgpt_disc_bow_neutral_prompt_ci_95_errstyle_band.png}
        \caption{}
        \label{subfig:lineplot_length_dist2_np_dgpt}
     \end{subfigure}
        \caption{Dist-2. GPT-2-based models (left), DialoGPT-based models (right). Translucent error bands represent 95\% confidence intervals. Plots best viewed in color.}
        \label{fig:lineplots_length_dist2_np_gpt2_dgpt}
\end{figure}

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.49\textwidth}
        \centering
\includegraphics[width=1\columnwidth]{figures/exp2/sequence_length/lineplot_len_dist3_best_gpt2_disc_bow__neutral_prompt_ci_95_errstyle_band.png}
        \caption{}
        \label{subfig:lineplot_length_dist3_np_gpt2}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/sequence_length/lineplot_len_dist3_best_dgpt_disc_bow__neutral_prompt_ci_95_errstyle_band.png}
        \caption{}
        \label{subfig:lineplot_length_dist3_np_dgpt}
     \end{subfigure}
        \caption{Dist-3. GPT-2-based models (left), DialoGPT-based models (right). Translucent error bands represent 95\% confidence intervals. Plots best viewed in color.}
        \label{fig:lineplots_length_dist3_np_gpt2_dgpt}
\end{figure}

\len{\textbf{Patterns in Figures~\ref{fig:lineplots_length_dist1_np_gpt2_dgpt}, \ref{fig:lineplots_length_dist2_np_gpt2_dgpt}, and \ref{fig:lineplots_length_dist3_np_gpt2_dgpt}}:}

\begin{itemize}
    \item Figure~\ref{fig:lineplots_length_dist1_np_gpt2_dgpt} shows that diversity w.r.t. unigrams increases for longer responses. This is most likely just due to the fact that longer sentences have an \textit{a priori} higher probability of repeating words. E.g., stopwords like "the" and "of" are likely to appear multiple times in longer sentences. \len{Is this a valid suggestion?}
    \item The same figure shows an interesting difference: GPT-2-BoW models generate significantly more diverse responses w.r.t. unigrams for almost every bracket of response length. This could be attributable to BoW-based control altering base-GPT2's generated sentences at the token-level, thus being more likely to preserve the unigram diversity of the unperturbed baseline (G-Baseline's Dist-1 is always in the upper register when looking at the columns in Tables \ref{tab:ctg_results_ws_neutral_prompt_young_models} and \ref{tab:ctg_results_ws_neutral_prompt_old_model}.
    \item Figure~\ref{fig:lineplots_length_dist2_np_gpt2_dgpt} and shows that variety w.r.t. bigrams makes an initial upward jump between response length of 1-10 and 10-20. Dist-2 then follows a mild downward trend for both GPT2- and DialoGPT-based models. The GPT2-based models' trend is more pronounced and less volatile than DialoGPT's.
    \item Figure \ref{subfig:lineplot_length_dist2_np_gpt2} shows the BoW-based GPT-2 models also produce significantly more diverse language w.r.t. bigrams for most response lengths.
    \item Figure~\ref{fig:lineplots_length_dist3_np_gpt2_dgpt} shows similar patterns: initial upward jump in trigram diversity between shortest and second-to-shortest length brackets. GPT-2 models then show a slight downward trend from the 20-30 lengths onward. However, DialoGPT actually show a decreasing increase in trigram diversity for all models.
\end{itemize}

\textbf{Patterns in (obsolete) unprompted results \len{DELETE OR MOVE TO APPENDIX}:}
\begin{itemize}
    \item \len{NB: These are all patterns observed in the unprompted results. Once prompted results are in, we can interpret them as if length of dialogue response.}
    \item Increasing sequence length is correlated with decreasing perplexity. Longer sentences are deemed more coherent by GPT-2
    \item Increasing length seems very slighty positively correlated with average accuracy (and more uncertainty). I.e., longer sequences are, on average, easier to classify, though less precision.
    \item BoW-based models significantly more distinct  w.r.t. unigrams than dirscrim-based.
    \item Overall, repetitiveness seems to increase as generated sequences become longer.
    \item The differences between young and old perplexity are smaller for BoW-based models than for Discrim-based. Same pattern holds for repetitiveness.
\end{itemize}

\len{NB: These are all patterns observed in the unprompted results. Once prompted results are in, we can interpret them as if length of dialogue response.}

The number of tokens being generated in an utterance seems to coincide with noticeable differences in our automated evaluation metrics. It is therefore important to get a clearer picture of how the various measures for fluency and control change for varying sequence lengths. Properly understanding this relationship can inform developers of adaptive dialogue systems about preserving output quality for responses of arbitrary lengths.

Figure~\ref{fig:ctg_lineplots_len_vs_metrics} presents plots of the relationships between generated sequence length (on the x-axes) and average perplexity (Figure~\ref{fig:ctg_lineplot_len_vs_ppl}), average BERT$_{FT}$ accuracy (Figure~\ref{fig:ctg_lineplot_len_vs_acc}), and average normalized number of distinct unigrams (Figure~\ref{fig:ctg_lineplot_len_vs_dist1}), bigrams (Figure~\ref{fig:ctg_lineplot_len_vs_dist2}), and trigrams (Figure~\ref{fig:ctg_lineplot_len_vs_dist3}).


Starting with Figure~\ref{fig:ctg_lineplot_len_vs_ppl}, it appears that, for all models, increases in generated utterance length coincide with decreases in perplexity. This is most likely attributable to the nature of calculating perplexity than generation properties of the models. Namely, perplexity essentially averages the sum of the negative exponentiated probabilities $p(\texttt{word} | \texttt{context})$, for every word in a sentence. Because the context increases with every successive word, and larger contexts typically result in less uncertainty, shorter sequences are often given unfairly high perplexities.

In Figure~\ref{fig:ctg_lineplot_len_vs_acc}, we can see that increasing length seems very slightly positively correlated with average accuracy (and more uncertainty). That is, longer sequences are, on average, slightly easier to classify, though with less precision. This is probably due to the fact that longer sentences contains more information to base predictions on.

Focusing on repetitive use of unigrams, it appears that BoW-based models generate significantly more diverse utterances than discriminator-based models. 

Repetitiveness w.r.t. bigrams and trigrams seems to increase as generated sequences become longer.

Overall, the differences between young and old perplexity are smaller for BoW-based models than for Discriminator-based. Same pattern holds for repetitiveness.


% \begin{figure}[H]
%      \centering
%      \begin{subfigure}[b]{0.49\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{figures/exp2/lineplot_len_dist1_best_gpt2_disc_bow_ci_90_errstyle_bars_nolegend.png}
%         \caption{...}
%         \label{fig:ctg_lineplot_len_vs_dist1}
%      \end{subfigure}
%     %  \hfill
%      \begin{subfigure}[b]{0.49\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{figures/exp2/lineplot_len_dist2_best_gpt2_disc_bow_ci_90_errstyle_bars_nolegend.png}
%         \caption{...}
%         \label{fig:ctg_lineplot_len_vs_dist2}
%      \end{subfigure}
%         \caption{}
%         \label{}
%     % \hfill
%      \begin{subfigure}[b]{0.49\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{figures/exp2/lineplot_len_dist3_best_gpt2_disc_bow_ci_90_errstyle_bars_nolegend.png}
%         \caption{...}
%         \label{fig:ctg_lineplot_len_vs_dist3}
%      \end{subfigure}
%         \caption{}
%         \label{}
% \end{figure}

% \begin{figure}[H]
% \centering
% \includegraphics[width=.4\textwidth]{figures/exp2/lineplot_len_ppl_best_gpt2_disc_bow_ci_90_errstyle_bars.png}\quad
% \includegraphics[width=.4\textwidth]{figures/exp2/lineplot_len_acc_best_gpt2_disc_bow_ci_90_errstyle_bars_nolegend.png}
% % \includegraphics[width=.3\textwidth]{figures/exp2/lineplot_len_dist1_best_gpt2_disc_bow_ci_90_errstyle_bars_nolegend.png}

% \medskip
% \includegraphics[width=.4\textwidth]{figures/exp2/lineplot_len_dist1_best_gpt2_disc_bow_ci_90_errstyle_bars_nolegend.png}\quad
% \includegraphics[width=.4\textwidth]{figures/exp2/lineplot_len_dist2_best_gpt2_disc_bow_ci_90_errstyle_bars_nolegend.png}\quad
% \includegraphics[width=.4\textwidth]{figures/exp2/lineplot_len_dist3_best_gpt2_disc_bow_ci_90_errstyle_bars_nolegend.png}

% \caption{Generated sequence length against various automated metrics.}
% \label{fig:seq_len_vs_auto_metrics}
% \end{figure}

\subsection{The Effects of Prompt Class \len{Think of better title}}
\label{subsec:ctg_anal_prompt_class}

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/prompt_class/catplot_prompt_class_target_prob_gpt2_young_models.png}
        \caption{}
        \label{subfig:catplot_prompt_class_target_prob_gpt2_young}
     \end{subfigure}
    %  \hfill
     \quad
     \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/prompt_class/catplot_prompt_class_target_prob_gpt2_old_models.png}
        \caption{}
        \label{subfig:catplot_prompt_class_target_prob_gpt2_old}
     \end{subfigure}
    \medskip
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/prompt_class/catplot_prompt_class_target_prob_dgpt_young_models.png}
        \caption{}
        \label{subfig:catplot_prompt_class_target_prob_dgpt_young}
     \end{subfigure}
    %  \hfill
    \quad
     \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/prompt_class/catplot_prompt_class_target_prob_dgpt_old_models.png}
        \caption{}
        \label{subfig:catplot_prompt_class_target_prob_dgpt_old}
     \end{subfigure}
    \caption{Target probability. The plots are best viewed in color. \len{TODO: (1) Change Target probability labels to Young or Old probability. The term target probability doesn't hold for baseline models. (2) Make very clear what the bars represent, i.e., averages over how many samples? how many models? See Slack thread with Sandro.}}
    \label{fig:catplot_prompt_class_target_prob}
\end{figure}

\len{\textbf{Patterns in Figure \ref{fig:catplot_prompt_class_target_prob}}:}
\begin{itemize}
    \item The style of the prompt clearly nudges the assigned probability in the direction of the prompt's class.
    \item The discrim. old models (GPT-2 and DialoGPT) always yield the highest relative improvements over the baselines.
    \item Ideally, you would want (1) the neutrally prompted baseline to be around 0.50. (2) A young or old prompt should shift the target probability in the direction of the prompt class; i.e., a young prompt should shift a young-model's target prob upwards, and an old-model's target prob downwards. (3) ...
    \item The models target probabilities (baseline, bow, and discrim) move accordingly with the prompt's class: young prompted young-model has highest young target prob, then neutral prompted, and then old prompted. Same pattern goes the other way around: an old prompted old-model has the highest (old) target prob, then neutral prompted, and then young prompted.
    \item So the class of the prompt strongly influences the style of the generated response.
    \item \len{Make sure to emphasize that this is also something that hasn't been studied by \cite{dathathri2019plug} or \cite{madotto-etal-2020-plug}; i.e., they never study the effect of their prompt style or sentiment on the style/attribute relevance of generation. This is actually a non-negligible fault in their research, because you can bias the style of generation by giving it a biased prompt. Furthermore, not quantitatively taking into account the prompt style or effect obfuscates the degree to which one can conclude whether attribute relevance is the result of controlled generation or prompt-bias.}
\end{itemize}

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/prompt_class/catplot_prompt_class_ppl_gpt2_young_models.png}
        \caption{}
        \label{subfig:catplot_prompt_class_ppl_gpt2_young}
     \end{subfigure}
    %  \hfill
     \quad
     \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/prompt_class/catplot_prompt_class_ppl_gpt2_old_models.png}
        \caption{}
        \label{subfig:catplot_prompt_class_ppl_gpt2_old}
     \end{subfigure}
    \medskip
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/prompt_class/catplot_prompt_class_ppl_dgpt_young_models.png}
        \caption{}
        \label{subfig:catplot_prompt_class_ppl_dgpt_young}
     \end{subfigure}
    %  \hfill
    \quad
     \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/prompt_class/catplot_prompt_class_ppl_dgpt_old_models.png}
        \caption{}
        \label{subfig:catplot_prompt_class_ppl_dgpt_old}
     \end{subfigure}
    \caption{Perplexity. Mind the differences in scale between the $y$-axes. The plots are best viewed in color.}
    \label{fig:catplot_prompt_class_ppl}
\end{figure}



Initial observations and interpretations of Tables \ref{tab:ctg_results_ws_young_prompt_young_model}, \ref{tab:ctg_results_ws_young_prompt_old_model}, \ref{tab:ctg_results_ws_old_prompt_young_model}, \ref{tab:ctg_results_ws_old_prompt_old_model}.

\begin{itemize}
    \item Using strongly young-prompt results in heavily reinforced young-bias for GPT2 and DialoGPT.
    \item Similarly, old-prompt results in slightly neutralized young-bias for both language models.
    \item Neutrally prompted patterns persist...
    \begin{itemize}
        \item Trade-off between control and fluency + diversity.
        \item BoW achieves smaller increases in control, but leaves fluency and dist intact.
        \item Discrim higher levels of control increase wrt baseline, worse quality of text wrt fluency and diversity.
    \end{itemize}
    \item Overall, stylistic aspects of prompts heavily influence controllability of response.
\end{itemize}

\paragraph{Young Prompts}

\begin{table*}[h]
    \centering
    \begin{tabular}{l | c c c c | c c}
    \toprule
    \textbf{Model} & \textbf{ppl.} & \textbf{Dist-1} & \textbf{Dist-2} & \textbf{Dist-3} & $\boldsymbol{\bar{P}_Y}$ & \textbf{Acc.}\\
    % -plus)}$\\
     & $\downarrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better\\
    \midrule
    \midrule
    G-baseline & \textcolor{blue}{28.05} ($\pm$6.12) & 0.85 ($\pm$0.13) & 0.91 ($\pm$0.08) & 0.88 ($\pm$0.08) & 0.80 ($\pm$0.33) & -\\
    G-100MCW & \textbf{27.71} ($\pm$6.20) & 0.85 ($\pm$0.12) & 0.91 ($\pm$0.09) & 0.88 ($\pm$0.09) & 0.75 ($\pm$0.37) & -\\
    \midrule
    G-B$_{FB, Y}$ & 28.81 ($\pm$7.09) & 0.86 ($\pm$0.12) & \textbf{0.92} ($\pm$0.08) & \textbf{0.89} ($\pm$0.08) & 0.82 ($\pm$0.32) & 83.3\%\\
    G-B$_{100MIU, Y}$ & 28.49 ($\pm$6.49) & 0.86 ($\pm$0.12) & 0.91 ($\pm$0.08) & 0.88 ($\pm$0.08) & 0.83 ($\pm$0.32) & 83.0\%\\
    \midrule
    G-D$_{Y}$ & 39.32 ($\pm$37.49) & 0.84 ($\pm$0.21) & 0.61 ($\pm$0.40) & 0.57 ($\pm$0.40) & 0.70 ($\pm$0.40) & 70.7\%\\
    \midrule
    \midrule
    D-baseline & 36.69 ($\pm$9.11) & 0.87 ($\pm$0.10) & \textcolor{blue}{0.91} ($\pm$0.06) & 0.87 ($\pm$0.08) & \textcolor{blue}{0.90} ($\pm$0.24) & -\\
    D-100MCW & 36.93 ($\pm$9.18) & 0.86 ($\pm$0.11) & \textcolor{blue}{0.91} ($\pm$0.06) & \textcolor{blue}{0.88} ($\pm$0.07) & 0.90 ($\pm$0.25) & -\\
    \midrule
    D-B$_{FB, Y}$ & 37.35 ($\pm$8.60) & \textcolor{blue}{0.88} ($\pm$0.10) & \textcolor{blue}{0.91} ($\pm$0.06) & 0.87 ($\pm$0.08) & 0.90 ($\pm$0.26) & \textcolor{blue}{90.0\%}\\
    D-B$_{100MIU, Y}$ & 37.87 ($\pm$8.32) & \textcolor{blue}{0.88} ($\pm$0.10) & 0.91 ($\pm$0.07) & 0.87 ($\pm$0.09) & \textbf{0.91} ($\pm$0.24) & \textbf{92.6\%}\\
    \midrule
    D-D$_{Y}$ & 39.22 ($\pm$14.96) & \textbf{0.89} ($\pm$0.12) & 0.86 ($\pm$0.19) & 0.79 ($\pm$0.23) & 0.89 ($\pm$0.25) & 91.1\%\\
    \bottomrule
    \end{tabular}
    \caption{\len{Young prompt - Young models} Results of age-controlled language generation. Perplexity is perplexity w.r.t. GPT-1. Dist-n is number of distinct n-grams normalized by text length, as a measure of diversity. Acc. is the best BERT model's accuracy when classifying the row's samples.}
    \label{tab:ctg_results_ws_young_prompt_young_model}
\end{table*}

\begin{table*}[h]
    \centering
    \begin{tabular}{l | c c c c | c c}
    \toprule
    \textbf{Model} & \textbf{ppl.} & \textbf{Dist-1} & \textbf{Dist-2} & \textbf{Dist-3} & $\boldsymbol{\bar{P}_O}$ & \textbf{Acc.}\\
    % -plus)}$\\
     & $\downarrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better\\
    \midrule
    \midrule
    G-baseline & \textcolor{blue}{28.05} ($\pm$6.12) & 0.85 ($\pm$0.13) & 0.91 ($\pm$0.08) & 0.88 ($\pm$0.08) & 0.20 ($\pm$0.33) & -\\
    G-100MCW & \textbf{27.71} ($\pm$6.20) & 0.85 ($\pm$0.12) & 0.91 ($\pm$0.09) & 0.88 ($\pm$0.09) & 0.25 ($\pm$0.37) & -\\
    \midrule
    G-B$_{FB, O}$ & 28.54 ($\pm$6.45) & 0.86 ($\pm$0.12) & \textbf{0.92} ($\pm$0.08) & \textbf{0.89} ($\pm$0.08) & 0.23 ($\pm$0.36) & 22.6\%\\
    G-B$_{100MIU, O}$ & 28.18 ($\pm$5.70) & 0.87 ($\pm$0.11) & \textbf{0.92} ($\pm$0.08) & \textcolor{blue}{0.89} ($\pm$0.09) & 0.21 ($\pm$0.34) & 21.5\%\\
    \midrule
    G-D$_{O}$ & 85.40 ($\pm$150.28) & 0.67 ($\pm$0.30) & 0.62 ($\pm$0.31) & 0.62 ($\pm$0.32) & \textbf{0.71} ($\pm$0.40) & \textbf{70.5\%}\\
    \midrule
    \midrule
    D-baseline & 36.69 ($\pm$9.11) & \textcolor{blue}{0.87} ($\pm$0.10) & 0.91 ($\pm$0.06) & 0.87 ($\pm$0.08) & 0.10 ($\pm$0.24) & -\\
    D-100MCW & 36.93 ($\pm$9.18) & 0.86 ($\pm$0.11) & 0.91 ($\pm$0.06) & 0.88 ($\pm$0.07) & 0.10 ($\pm$0.25) & -\\
    \midrule
    D-B$_{FB, O}$ & 37.25 ($\pm$9.45) & 0.87 ($\pm$0.11) & 0.91 ($\pm$0.06) & 0.87 ($\pm$0.08) & 0.12 ($\pm$0.29) & 11.1\%\\
    D-B$_{100MIU, O}$ & 37.04 ($\pm$8.78) & \textbf{0.88} ($\pm$0.10) & \textcolor{blue}{0.91} ($\pm$0.05) & 0.88 ($\pm$0.07) & 0.15 ($\pm$0.32) & 15.2\%\\
    \midrule
    D-D$_{O}$ & 38.46 ($\pm$14.91) & 0.82 ($\pm$0.15) & 0.87 ($\pm$0.15) & 0.83 ($\pm$0.17) & \textcolor{blue}{0.48} ($\pm$0.44) & \textcolor{blue}{47.4\%}\\
    \bottomrule
    \end{tabular}
    \caption{\len{Young prompt - Old models} Results of age-controlled language generation. Perplexity is perplexity w.r.t. GPT-1. Dist-n is number of distinct n-grams normalized by text length, as a measure of diversity. Acc. is the best BERT model's accuracy when classifying the row's samples.}
    \label{tab:ctg_results_ws_young_prompt_old_model}
\end{table*}

\paragraph{Old Prompts}

\begin{table*}[h]
    \centering
    \begin{tabular}{l | c c c c | c c}
    \toprule
    \textbf{Model} & \textbf{ppl.} & \textbf{Dist-1} & \textbf{Dist-2} & \textbf{Dist-3} & $\boldsymbol{\bar{P}_Y}$ & \textbf{Acc.}\\
    % -plus)}$\\
     & $\downarrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better\\
    \midrule
    \midrule
    G-baseline & \textcolor{blue}{29.34} ($\pm$10.30) & 0.86 ($\pm$0.09) & \textbf{0.94} ($\pm$0.04) & \textcolor{blue}{0.90} ($\pm$0.06) & 0.60 ($\pm$0.43) & -\\
    G-100MCW & \textbf{29.14} ($\pm$10.11) & 0.86 ($\pm$0.10) & \textcolor{blue}{0.93} ($\pm$0.04) & \textcolor{blue}{0.90} ($\pm$0.06) & 0.60 ($\pm$0.44) & -\\
    \midrule
    G-B$_{Y, FB}$ & 29.61 ($\pm$10.28) & 0.86 ($\pm$0.10) & 0.93 ($\pm$0.04) & \textbf{0.91} ($\pm$0.06) & 0.62 ($\pm$0.43) & 61.1\%\\
    G-B$_{Y, 100MIU}$ & 29.51 ($\pm$0.09) & \textcolor{blue}{0.87} ($\pm$0.09) & 0.93 ($\pm$0.05) & \textcolor{blue}{0.90} ($\pm$0.06) & 0.68 ($\pm$0.42) & 68.5\%\\
    \midrule
    G-D$_{Y}$ & 32.34 ($\pm$19.88) & 0.77 ($\pm$0.20) & 0.84 ($\pm$0.19) & 0.80 ($\pm$0.23) & 0.65 ($\pm$0.43) & 65.4\%\\
    \midrule
    \midrule
    D-baseline & 38.18 ($\pm$12.03) & 0.86 ($\pm$0.12) & 0.90 ($\pm$0.08) & 0.86 ($\pm$0.09) & 0.72 ($\pm$0.38) & -\\
    D-100MCW & 37.73 ($\pm$11.88) & 0.85 ($\pm$0.13) & 0.90 ($\pm$0.08) & 0.86 ($\pm$0.09) & 0.73 ($\pm$0.39) & -\\
    \midrule
    D-B$_{Y, FB}$ & 38.24 ($\pm$11.53) & 0.86 ($\pm$0.12) & 0.90 ($\pm$0.08) & 0.86 ($\pm$0.10) & 0.81 ($\pm$0.34) & \textcolor{blue}{82.6\%}\\
    D-B$_{Y, 100MIU}$ & 38.66 ($\pm$11.57) & 0.85 ($\pm$0.12) & 0.90 ($\pm$0.07) & 0.86 ($\pm$0.09) & \textcolor{blue}{0.81} ($\pm$0.33) & 80.7\%\\
    \midrule
    D-D$_{Y}$ & 42.93 ($\pm$20.18) & \textbf{0.90} ($\pm$0.14) & 0.79 ($\pm$0.22) & 0.68 ($\pm$0.28) & \textbf{0.84} ($\pm$0.30) & \textbf{85.2\%}\\
    \bottomrule
    \end{tabular}
    \caption{\len{Old prompt - Young model} Results of age-controlled language generation. Perplexity is perplexity w.r.t. GPT-1. Dist-n is number of distinct n-grams normalized by text length, as a measure of diversity. Acc. is the best BERT model's accuracy when classifying the row's samples.}
    \label{tab:ctg_results_ws_old_prompt_young_model}
\end{table*}

\begin{table*}[h]
    \centering
    \begin{tabular}{l | c c c c | c c}
    \toprule
    \textbf{Model} & \textbf{ppl.} & \textbf{Dist-1} & \textbf{Dist-2} & \textbf{Dist-3} & $\boldsymbol{\bar{P}_O}$ & \textbf{Acc.}\\
    % -plus)}$\\
     & $\downarrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better\\
    \midrule
    \midrule
    G-baseline & 29.34 ($\pm$10.30) & \textcolor{blue}{0.86} ($\pm$0.09) & \textbf{0.94} ($\pm$0.04) & \textbf{0.90} ($\pm$0.06) & 0.40 ($\pm$0.43) & -\\
    G-100MCW & 29.14 ($\pm$10.11) & 0.86 ($\pm$0.10) & \textcolor{blue}{0.93} ($\pm$0.04) & \textbf{0.90} ($\pm$0.06) & 0.40 ($\pm$0.44) & -\\
    \midrule
    G-B$_{O, FB}$ & \textbf{28.81} ($\pm$10.10) & 0.86 ($\pm$0.10) & 0.93 ($\pm$0.05) & \textbf{0.90} ($\pm$0.06) & 0.41 ($\pm$0.43) & 41.1\%\\
    G-B$_{O, 100MIU}$ & 29.05 ($\pm$9.80) & \textcolor{blue}{0.86} ($\pm$0.09) & \textcolor{blue}{0.93} ($\pm$0.04) & \textbf{0.90} ($\pm$0.06) & 0.40 ($\pm$0.43) & 39.6\%\\
    \midrule
    G-D$_{O}$ & 95.21 ($\pm$174.42) & 0.65 ($\pm$0.27) & 0.78 ($\pm$0.18) & 0.78 ($\pm$0.18) & \textbf{0.90} ($\pm$0.25) & \textbf{90.3\%}\\
    \midrule
    \midrule
    D-baseline & 38.18 ($\pm$12.03) & 0.86 ($\pm$0.12) & 0.90 ($\pm$0.08) & 0.86 ($\pm$0.09) & 0.28 ($\pm$0.38) & -\\
    D-100MCW & 37.73 ($\pm$11.88) & 0.85 ($\pm$0.13) & 0.90 ($\pm$0.08) & 0.86 ($\pm$0.09) & 0.27 ($\pm$0.39) & -\\
    \midrule
    D-B$_{O, FB}$ & 37.80 ($\pm$11.74) & 0.86 ($\pm$0.12) & 0.90 ($\pm$0.07) & \textcolor{blue}{0.87} ($\pm$0.08) & 0.28 ($\pm$0.39) & 29.3\%\\
    D-B$_{O, 100MIU}$ & 36.93 ($\pm$11.68) & \textbf{0.87} ($\pm$0.12) & 0.90 ($\pm$0.09) & 0.86 ($\pm$0.09) & 0.31 ($\pm$0.41) & 29.6\%\\
    \midrule
    D-D$_{O}$ & 40.08 ($\pm$16.77) & 0.85 ($\pm$0.14) & 0.88 ($\pm$0.10) & 0.83 ($\pm$0.14) & \textcolor{blue}{0.61} ($\pm$0.42) & \textcolor{blue}{61.1\%}\\
    \bottomrule
    \end{tabular}
    \caption{\len{Old prompt - Old models} Results of age-controlled language generation. Perplexity is perplexity w.r.t. GPT-1. Dist-n is number of distinct n-grams normalized by text length, as a measure of diversity. Acc. is the best BERT model's accuracy when classifying the row's samples.}
    \label{tab:ctg_results_ws_old_prompt_old_model}
\end{table*}


% \subsubsection{Quantitative 3: The Effects of PPLM-Parameters on Fluency and Control}

% \begin{itemize}
%     \item \textit{Plot and examine the relationship between fluency and control, and various PPLM-parameters (step-size, number of iterations, temperature, top $k$, gamma, KL-scale).}
%     \item \textit{Which patterns do you observe?}
%     \item \len{How much sense does it make to study this, though? Is that the purpose of my thesis? Hasn't this been studied enough in the PPLM-paper? Which parameters do I choose?}
% \end{itemize}

\subsection{BERT-Classifier Visualizations. Or (Dialo)GPT Visualizations.}

\begin{itemize}
    \item \textit{\textbf{NB:} This is more relevant to the classification experiments, than to the controlled generation experiments.}
    
    \item \textit{Use BertViz \citep{vig-2019-multiscale} to visualize what parts of sequences BERT's transformer heads and neurons are focusing on.}
    
    \item \url{https://github.com/jessevig/bertviz}
    
    \item \url{https://towardsdatascience.com/openai-gpt-2-understanding-language-generation-through-visualization-8252f683b2f8}
    
    \item Discussion about interpretability of attention. See Attention is not explanation, Attention is not not explanation, and The Elephant in the Interpretability Room.
\end{itemize}




\subsection{Qualitative Analyses}

\subsubsection{Qualitative 1: Summary Statistics and Qualitative Inspection of Various Cases}

\begin{itemize}
    \item \textit{Similar to (error)case analyses of Experiment 1.}
    
    \item \textit{Provide summary statistics and (\textbf{qualitative}) inspection of generated sequences per case.}
    
    \item \textit{Cases could be: (1) sequences with low, average, high, or very-high perplexity. (2) (in)correctly classified generated sequences.}
    
    \item \textit{What patterns do you observe among, e.g., misclassified sequences with low perplexity?}
    
    \item \textit{Provide table of examples per case and age-group. Similar to table \ref{tab:qualexamples}}
\end{itemize}


% \subsubsection{Qualitative 2: Human evaluation of fluency, grammaticality, and relevancy}

% \begin{itemize}
%     \item \textit{Generate and sample text passages for a variety of model-configurations and age-groups.}
%     \item \textit{Have a group of human participants rate these sequences on a scale from 1 to 5 for their (1) fluency, (2) grammaticality, (3) relevance to the prompt (if there is one)}
%     \item \textit{Average the ratings, and compare the human evaluation metrics to the automated evaluation metrics reported in Table \ref{tab:ctg_results_ws}}
% \end{itemize}



