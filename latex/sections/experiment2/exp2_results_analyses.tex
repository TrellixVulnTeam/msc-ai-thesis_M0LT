\newpage
\section{Controlled Dialogue Generation Results}
\label{sec:exp2_results}
% \len{NB - If you choose to use confidence intervals instead of std's, be sure to revise this section so it still makes sense.}
% \len{Old text for the unprompted results. FROM HERE....}

% Table~\ref{tab:ctg_results_ws} reports the automated evaluation results of my controllable text generation models. It can be seen that uncontrolled GPT-2 baseline has a slight bias towards generating "young-sounding" language (57.5\% accuracy). Furthermore, it appears that perturbing GPT-2's output distribution with the 100 most common words across all ages results in a slight de-biasing of the generated text (54.1\% accuracy). Achieving detectable control seems possible, because all GPT-2-based models surpass both baselines in terms of accuracy, with the exception of both BoW-setups using the 100 most informative unigrams.

% Frequency-based BoW-models outperform those using the most informative unigrams, as illustrated by their higher average accuracy (66.75\% versus. 53.1\%), and lower average perplexity (27.48 versus 27.90). 
% % \len{Offer an explanation.} 
% Discriminator-based models achieve noticeably better accuracies, with an average improvement of 8.45\% over the best performing BoW-based models. However, discriminator-based models do show more signs of disfluency and repetitiveness compared to the BoW-models, as depicted by the worse perplexities and Dist-$n |_{n = 1,2,3}$ scores.

% % The accuracies of my uncontrolled DialoGPT baseline (78.1\%) and the 100MCW baseline (80.7\%), suggest that DialoGPT is heavily biased towards producing young-sounding language. This can be attributable to DialoGPT having been fine-tuned on Reddit threads, as the majority of Reddit users are between the ages 20 and 29~\footnote{\url{https://www.statista.com/statistics/1125159/reddit-us-app-users-age/}}
% % \len{Find a reference for this statement} 
% \citep{zhang2019dialogpt}. DialoGPT's strong propensity for generating younger sounding language makes it a less desirable choice for my human evaluation experiments, because it requires non-standard parameter settings to produce detectably older sounding text.

% Overall, the results show that, for most models, a plug-and-play approach to controlling generated dialogue responses to possess detectable age-specific linguistic features is achievable. The most promising models being either discriminator-based, or frequency-based bag-of-words models. Discriminator-based models achieve more detectable levels of control than their BoW-based counterparts, at the cost of perplexity and repetitiveness. This could be attributable to the more complex activation-space updates that are used by discriminator-models. Furthermore, GPT-2's preference to generate young-sounding language is severely less pronounced than that of DialoGPT, making it easier to control, given equal parameter settings.

% \len{...TO HERE}

The quantitative results of generating younger (ages 19 through 29) and older (ages 50 and over) sounding responses to \textit{neutral} prompts are reported in Tables \ref{tab:ctg_results_ws_neutral_prompt_young_models} and \ref{tab:ctg_results_ws_neutral_prompt_old_model}, respectively. The metrics per row are averaged over $N = 30 \cdot 9 = 270$ samples (see Section \ref{subsec:experimental_details_generation}). In these tables, the underlying language model being used in a setup (i.e., a row in a table) is indicated by the prefixes G- for GPT-2 and D- for DialoGPT. Additionally, both tables report the results of the uncontrolled GPT-2 and DialoGPT baselines (labeled G-baseline and D-baseline, respectively), and those of the 100 most common age-independent bag-of-words setups for both GPT-2 and DialoGPT (labeled G-100MCW and D-100MCW, respectively). The accuracies for these two setups (i.e., baseline and 100 most common words) are omitted because they do not aim to generate responses that resemble any target age group. Moreover, two bag-of-words (BoW) setups are reported per underlying language model (GPT-2 or DialoGPT): the frequency-based BoW setup (indicated by the suffix, -BoW$_{FB}$), and the 100 most informative unigram-based setup (indicated by the suffix, -BoW$_{100MIU}$). Detailed descriptions of how and why these aforementioned wordlists are constructed are provided in Section \ref{subsec:att_model_dev}. Finally, the discriminator-based setups are indicated by the suffix, -Discrim. The aforementioned reporting conventions also hold for the tables containing the results of response generation to younger and older sounding prompts (i.e., Tables \ref{tab:ctg_results_ws_young_prompt_young_model}, \ref{tab:ctg_results_ws_young_prompt_old_model}, \ref{tab:ctg_results_ws_old_prompt_young_model}, and \ref{tab:ctg_results_ws_old_prompt_old_model}). The results of those experiments are discussed in Section \ref{subsec:ctg_anal_prompt_class}.

%%%%%%%
% Bring Tables here
\begin{table*}[h]
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{l | c c c c | c c}
    \toprule
    \textbf{Model} & \textbf{ppl.} & \textbf{Dist-1} & \textbf{Dist-2} & \textbf{Dist-3} & $\boldsymbol{\bar{P}_Y}$ & \textbf{Acc.}\\
    % -plus)}$\\
     & $\downarrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better\\
    \midrule
    \midrule
    G-baseline & \textbf{27.50} (6.58) & 0.87 (0.09) & \textbf{0.94} (0.04) & \textcolor{blue}{0.90} (0.06) & 0.62 (0.42) & -\\
    G-100MCW & \textcolor{blue}{27.56} (6.60) & 0.86 (0.10) & \textcolor{blue}{0.93} (0.04) & \textbf{0.90} (0.05) & 0.63 (0.42) & -\\
    \midrule
    G-BoW$_{FB}$ & 27.91 (7.18) & 0.87 (0.10) & 0.93 (0.05) & \textcolor{blue}{0.90} (0.06) & 0.69 (0.41) & 70.4\%\\
    G-BoW$_{100MIU}$ & 28.37 (7.31) & 0.87 (0.09) & \textcolor{blue}{0.93} (0.04) & \textcolor{blue}{0.90} (0.06) & 0.67 (0.41) & 67.4\%\\
    \midrule
    G-Discrim & 32.09 (18.98) & 0.77 (0.20) & 0.86 (0.13) & 0.84 (0.15) & 0.66 (0.43) & 67.8\%\\
    \midrule
    \midrule
    D-baseline & 37.52 (12.06) & 0.86 (0.13) & 0.90 (0.08) & 0.85 (0.10) & 0.76 (0.37) & -\\
    D-100MCW & 37.80 (10.89) & 0.85 (0.14) & 0.89 (0.10) & 0.85 (0.10) & 0.82 (0.33) & -\\
    \midrule
    D-BoW$_{FB}$ & 38.53 (12.64) & 0.87 (0.12) & 0.90 (0.08) & 0.86 (0.10) & 0.82 (0.33) & 83.0\%\\
    D-BoW$_{100MIU}$ & 38.67 (11.70) & \textcolor{blue}{0.88} (0.11) & 0.91 (0.07) & 0.86 (0.10) & \textbf{0.87} (0.28) & \textbf{88.5\%}\\
    \midrule
    D-Discrim & 42.01 (16.94) & \textbf{0.90} (0.12) & 0.86 (0.14) & 0.77 (0.22) & \textcolor{blue}{0.86} (0.29) & \textcolor{blue}{85.9\%}\\
    \bottomrule
    \end{tabular}
    }
    \caption{Results of age-controlled dialogue generation: \textbf{younger}-targeted models, conditioned on \textbf{neutral prompts}. Format: \textit{average metric (standard error)}. \textbf{ppl.} is perplexity w.r.t. GPT-1. \textbf{Dist-$n$} (for $n = 1, 2, 3$) is the number of distinct $n$-grams normalized by text length, as a measure of diversity. $\boldsymbol{\bar{P}_Y}$ is the sample's average probability to contain features learned to be younger by BERT$_{FT}$. \textbf{Acc.} is BERT$_{FT}$'s accuracy when classifying the row's samples. Values in \textbf{bold} are the best in the column; in \textcolor{blue}{blue}, the second-best.}
    \label{tab:ctg_results_ws_neutral_prompt_young_models}
\end{table*}

\begin{table*}[h]
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{l | c c c c | c c }
    \toprule
    \textbf{Model} & \textbf{ppl.} & \textbf{Dist-1} & \textbf{Dist-2} & \textbf{Dist-3} & $\boldsymbol{\bar{P}_O}$ & \textbf{Acc.}\\
    % -plus)}$\\
     & $\downarrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better\\
    \midrule
    \midrule
    G-baseline & \textcolor{blue}{27.50} (6.58) & \textbf{0.87} (0.09) & \textbf{0.94} (0.04) & \textcolor{blue}{0.90} (0.06) & 0.38 (0.42) & -\\
    G-100MCW & 27.56 (6.60) & 0.86 (0.10) & \textcolor{blue}{0.93} (0.04) & \textbf{0.90} (0.05) & 0.37 (0.42) & -\\
    \midrule
    G-BoW$_{FB}$ & 27.58 (7.07) & 0.86 (0.10) & \textcolor{blue}{0.93} (0.04) & \textcolor{blue}{0.90} (0.06) & 0.42 (0.42) & 43.0\%\\
    G-BoW$_{100MIU}$ & \textbf{27.25} (6.15) & \textbf{0.87} (0.09) & \textcolor{blue}{0.93} (0.04) & \textcolor{blue}{0.90} (0.06) & 0.38 (0.42) & 37.4\%\\
    \midrule
    G-Discrim & 47.15 (47.56) & 0.73 (0.24) & 0.75 (0.28) & 0.75 (0.27) & \textbf{0.76} (0.36) & \textbf{74.3\%}\\
    \midrule
    \midrule
    D-baseline & 37.52 (12.06) & 0.86 (0.13) & 0.90 (0.08) & 0.85 (0.10) & 0.24 (0.37) & -\\
    D-100MCW & 37.80 (10.89) & 0.85 (0.14) & 0.89 (0.10) & 0.85 (0.10) & 0.18 (0.33) & -\\
    \midrule
    D-BoW$_{FB}$ & 37.85 (11.17) & 0.87 (0.12) & 0.90 (0.08) & 0.86 (0.09) & 0.22 (0.35) & 21.5\%\\
    D-BoW$_{100MIU}$ & 37.91 (12.27) & \textcolor{blue}{0.87} (0.11) & 0.90 (0.07) & 0.85 (0.10) & 0.22 (0.34) & 21.9\%\\
    \midrule
    D-Discrim & 41.17 (20.72) & 0.87 (0.12) & 0.89 (0.13) & 0.83 (0.16) & \textcolor{blue}{0.57} (0.41) & \textcolor{blue}{56.7\%}\\
    \bottomrule
    \end{tabular}
    }
    \caption{Results of age-controlled dialogue generation: \textbf{older}-targeted models, conditioned on \textbf{neutral prompts}. Format: \textit{average metric (standard error)}. ppl. is perplexity w.r.t. GPT-1. Dist-$n$ (for $n = 1, 2, 3$) is the number of distinct $n$-grams normalized by text length, as a measure of diversity. $\boldsymbol{\bar{P}_O}$ is the sample's average probability to contain features learned to be older by BERT$_{FT}$. Acc. is BERT$_{FT}$'s accuracy when classifying the row's samples. Values in \textbf{bold} are the best in the column; in \textcolor{blue}{blue}, the second-best.}
    \label{tab:ctg_results_ws_neutral_prompt_old_model}
\end{table*}
%%%%%%%

\paragraph{Uncontrolled Baseline Models} As one would expect, Tables \ref{tab:ctg_results_ws_neutral_prompt_young_models} and \ref{tab:ctg_results_ws_neutral_prompt_old_model} show that the GPT-2 baseline consistently scores among the best on perplexity (best perplexity compared to younger generation models, and second-best compared to older generation models) and diversity of generation (the Dist-$n |_{n = 1,2,3}$ scores are almost consistently in the upper registers). Similarly, the uncontrolled DialoGPT baseline also scores best in terms of perplexity, when compared to other DialoGPT-based setups. This means that the responses generated by GPT-2 and DialoGPT are found to be among the least perplexing to GPT-1. This is unsurprising, as GPT-2, and thereby also DialoGPT, are pre-trained in a similar fashion to GPT-1 \citep{radford2018improving, radford2019language, zhang2019dialogpt}. Additionally, the target probabilities ($\bar{P}_Y = 0.62$ in Table~\ref{tab:ctg_results_ws_neutral_prompt_young_models}, and $\bar{P}_O = 0.38$ in Table~\ref{tab:ctg_results_ws_neutral_prompt_old_model}) indicate that the GPT-2 baseline is biased towards generating younger language. That is, given a neutral prompt, GPT-2 is inclined to produce responses that are likely to contain features learned to be younger by BERT$_{FT}$. This could be attributable to GPT-2 being pre-trained on WebText, a corpus of high-quality documents scraped from web pages, which could be over-represented by millennials~\footnote{\url{https://www.statista.com/statistics/272365/age-distribution-of-internet-users-worldwide/}}. Moreover, DialoGPT has a very strong bias towards generating younger sounding responses, given a neutral prompt (0.76 average probability to contain detectable younger features). This is most likely due to DialoGPT having been fine-tuned on Reddit threads \citep{zhang2019dialogpt}, as the majority of Reddit users are between the ages 20 and 29~\footnote{\url{https://www.statista.com/statistics/1125159/reddit-us-app-users-age/}}.
The uncontrolled DialoGPT baseline also produces more perplexing and less diverse text than GPT-2 according to GPT-1 perplexity and the Dist-$n |_{n = 1,2,3}$ scores. The higher perplexity is to be expected, as DialoGPT's pre-training and fine-tuning methods deviates more from GPT-1's than GPT-2, making it likely to produce more unexpected sentences \citep{zhang2019dialogpt}.

\paragraph{BoW-based PPLM-setups} The G-BoW$_{100MCW}$ setup performs on par with baseline w.r.t. perplexity and diversity (second-best perplexity, second-best Dist-2, best Dist-3), when compared to the younger generation models. A similar pattern can be seen for older models, where G-100MCW has the second-best Dist-2, and best Dist-3 scores. Additionally, the target probabilities seem virtually unaffected by the 100MCW setups, suggesting that perturbing GPT-2's output with an age-agnostic bag-of-words of the most frequently used words in the dialogue dataset does not noticeably shift the writing style towards that of the younger or older age group. This is to be expected, as such a wordlist should be an unbiased representation of the dataset's language style, given similar sample sizes per class.
However, when using DialoGPT as an underlying language model, the BoW-based models (including 100MCW) seem to reinforce younger bias for DialoGPT, regardless of age (i.e., for all younger targeted BoW-based models $\bar{P}_Y$ goes up, and $\bar{P}_O$ goes down for all older targeted BoW-based models).

Compared to discriminator-based models, the BoW-based models seem to generate responses that are slightly more likely to contain features of the target age (younger GPT2-BoW$_{FB}$ models result in 0.06 target probability improvement over the baseline, and older GPT2-BoW$_{FB}$ model in 0.04 target probability improvement over baseline). However, these differences could also be due to randomness. For the 50-plus style GPT-2-based response models, the BoW$_{100MIU}$ setup does not manage to generate older sounding language better than the baseline. Furthermore, BoW-based models seem to barely impact the syntactical structure of generated responses, because changes are more local than those made by discriminator-based setups \cite{dathathri2019plug}. This is confirmed by the barely altered perplexity and Dist-scores. 
% \len{But this will be studied in more detail in the qualitative analyses.}

\paragraph{Discriminator-based PPLM-setups} The GPT-2 discriminator-based older targeted model manages to generate responses that more convincingly resemble the style of the target group (0.38 $\bar{P}_O$ improvement over the GPT-2 baseline). However, this comes at the cost of perplexity ($+19.65$ compared to baseline) and diversity (much lower dist-scores and higher corresponding standard deviations). By contrast, the GPT-2 discriminator-based younger setup does not generate convincingly more younger sounding responses (only 0.04 average target probability improvement over baseline), despite having noticeably worse and less precise perplexity ($4.59$ increase over baseline) and diversity.
And the discriminator-based DialoGPT models, are superior w.r.t. target probability (+0.10 $\bar{P}_Y$ difference compared to DialoGPT baseline for younger models, and +0.34 $\bar{P}_O$ compared to baseline for older models). However, this again comes at the cost of much higher and more volatile perplexity.

% The uncontrolled DialoGPT baseline produces more perplexing and less diverse text than GPT-2 according to GPT-1 perplexity and the Dist-$n |_{n = 1,2,3}$ scores. The higher perplexity is to be expected, as DialoGPT pre-training and fine-tuning method deviates more from GPT-1's than GPT-2, making it likely to produce more unexpected sentences \citep{zhang2019dialogpt}. 
% When using DialoGPT as an underlying language model, the BoW-based models (including 100MCW) seem to reinforce younger bias for DialoGPT, regardless of age (i.e., for all younger targeted BoW-based models $\bar{P}_Y$ goes up, and $\bar{P}_O$ goes down for all older targeted BoW-based models).
% And the discriminator-based DialoGPT models, are superior w.r.t. target probability (+0.10 $\bar{P}_Y$ difference compared to DialoGPT baseline for younger models, and +0.34 $\bar{P}_O$ compared to baseline for older models). However, this again comes at the cost of much higher and more volatile perplexity.

\paragraph{Key Takeaways} Overall, according to these results it seems to be possible to control dialogue responses for a certain age group. The used underlying language models are biased (in varying degrees) towards generating younger sounding language. In these tested PPLM-setups, there seems to be a tradeoff between increased control and decreasing perplexity and diversity of generated language. Furthermore, the BoW-based models achieve less detectable levels of control, but preserve the fluency and diversity of generated text. In other words, the discriminator-based models make more invasive changes to the uncontrolled sentences, which can result in less fluent and more repetitive text. However, they do produce more detectably age-appropriate passages, as indicated by BERT$_{FT}$'s assigned target probabilities.

% \textbf{Initial observations and interpretations neutrally prompted ctg results (Tables \ref{tab:ctg_results_ws_neutral_prompt_young_models} and \ref{tab:ctg_results_ws_neutral_prompt_old_model})}
% \begin{itemize}
%     \item Style of prompt heavily influences control of response. Also confirmed by Tables \ref{tab:ctg_results_ws_young_prompt_young_model}, \ref{tab:ctg_results_ws_young_prompt_old_model}, \ref{tab:ctg_results_ws_old_prompt_young_model}, and \ref{tab:ctg_results_ws_old_prompt_old_model}. Remind reader of ctg formula $p(\textbf{x} | a, \texttt{prompt})$.
    % \item GPT-2 baseline scores best w.r.t. fluency (lowest perplexity) and diversity of generation (highest Dist-2, second highest Dist-3).
    % \item GPT-2 + BoW$_{100MCW}$ on par with baseline w.r.t. fluency and diversity (second best perplexity, second best Dist-2, best Dist-3).
    % \item Very similar pattern for old models: baseline second best perplexity and Dist-3, best Dist-1 and Dist-2; 100MCW second best Dist-2, and best Dist-3.
    % \item Baseline is moderately biased towards generating young language. I.e., GPT-2 is inclined to produce responses, given a neutral prompt, that are likely to contain features learned to be young by BERT$_{FT}$.
    % \item BoW-based models seem to result in language that is slightly more likely to contain features of target age (Young bow-models result in 0.06 probability increase wrt baseline, and old-bow-fb model in 0.04 increase wrt baseline). Differences are also possibly due to randomness.
    % \item BoW-based models barely impact the syntactical structure of generated sequences, i.e., changes made at lexical-level. This is shown by the barely altered perplexity (sometimes improved , G-B$_{100MIU,O}$ 0.25 lower average perplexity than baseline), and Dist-scores. \len{But this will be studied in more detail in the qualitative analyses.} 
    % \item BoW-fb slightly superior to BoW-100MIU -> consistently higher accuracy for BERT$_{FT}$.
    % \item For Old-models, BoW still doesn't fully overcome young-bias to result in convincingly old language.
    % \item Discriminator-based old model manages to generate language that is more convincingly similar to target age (0.38 old prob improvement). This comes at the cost of fluency and diversity (much higher perplexity and std wrt baseline), noticeable lower dist-scores and higher std's.
    % \item GPT2-disc young not convincingly more young sounding response. Noticeably worse and less precise fluency and diversity though. Only 0.04 average probability improvement.
    % \item DialoGPT has very strong young-bias, given a neutral prompt (0.76 average probability to contain detectable young features). --> Most likely due to DialoGPT being GPT-2, fine-tuned on Reddit Thread data \citep{zhang2019dialogpt} and include reddit age dist reference.
    % \item DialoGPT baseline produces less fluent and less diverse text than GPT-2 according to GPT-1 perplexity.
    % \item BoW-based models (including 100MCW) seem to reinforce young-bias for DialoGPT, regardless of age (young prob goes up for both BoW, and old prob goes down for both BoW-models).
    % \item Discriminator based models, again, outperform significantly w.r.t. target probability (0.10 prob difference wrt baseline for young, and 0.34 prob difference wrt baseline for old). Again, at the cost of on average worse and more volatile perplexity.
    % \item Janie's suggestion: it could be that there are some detectable young-sounding tokens that make BoW-based young control easier, and that old-sounding features are more salient at the structural/syntactical level and harder to control for.
    % \item Overall, it seems to be possible to control dialogue responses for a certain age group. The used base language models are biased towards generating young-sounding language. In the current PPLM-setup, there seems to be a tradeoff between increased control and decreasing fluency and diversity. BoW-based models achieve less detectable levels of control, but preserve the fluency and diversity of generated text. Discriminator based models make more invasive changes to the unperturbed sentences, which can result in less fluent and more repetitive text. However, they do produce more detectably age-appropriate passages.
    % \item \len{TODO - Examine the nonsensical generated sequences that are correctly labeled as old or young. What patterns do you see? It could be that BERT$_{FT}$ is picking up non-language patterns that give away age.}
% \end{itemize}

% \begin{table*}[h]
%     \centering
%     \resizebox{\linewidth}{!}{
%     \begin{tabular}{l | c c c c | c c}
%     \toprule
%     \textbf{Model} & \textbf{ppl.} & \textbf{Dist-1} & \textbf{Dist-2} & \textbf{Dist-3} & $\boldsymbol{\bar{P}_Y}$ & \textbf{Acc.}\\
%     % -plus)}$\\
%      & $\downarrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better\\
%     \midrule
%     \midrule
%     G-baseline & \textbf{27.50} (6.58) & 0.87 (0.09) & \textbf{0.94} (0.04) & \textcolor{blue}{0.90} (0.06) & 0.62 (0.42) & -\\
%     G-100MCW & \textcolor{blue}{27.56} (6.60) & 0.86 (0.10) & \textcolor{blue}{0.93} (0.04) & \textbf{0.90} (0.05) & 0.63 (0.42) & -\\
%     \midrule
%     G-BoW$_{FB}$ & 27.91 (7.18) & 0.87 (0.10) & 0.93 (0.05) & \textcolor{blue}{0.90} (0.06) & 0.69 (0.41) & 70.4\%\\
%     G-BoW$_{100MIU}$ & 28.37 (7.31) & 0.87 (0.09) & \textcolor{blue}{0.93} (0.04) & \textcolor{blue}{0.90} (0.06) & 0.67 (0.41) & 67.4\%\\
%     \midrule
%     G-Discrim & 32.09 (18.98) & 0.77 (0.20) & 0.86 (0.13) & 0.84 (0.15) & 0.66 (0.43) & 67.8\%\\
%     \midrule
%     \midrule
%     D-baseline & 37.52 (12.06) & 0.86 (0.13) & 0.90 (0.08) & 0.85 (0.10) & 0.76 (0.37) & -\\
%     D-100MCW & 37.80 (10.89) & 0.85 (0.14) & 0.89 (0.10) & 0.85 (0.10) & 0.82 (0.33) & -\\
%     \midrule
%     D-BoW$_{FB}$ & 38.53 (12.64) & 0.87 (0.12) & 0.90 (0.08) & 0.86 (0.10) & 0.82 (0.33) & 83.0\%\\
%     D-BoW$_{100MIU}$ & 38.67 (11.70) & \textcolor{blue}{0.88} (0.11) & 0.91 (0.07) & 0.86 (0.10) & \textbf{0.87} (0.28) & \textcolor{blue}{88.5\%}\\
%     \midrule
%     D-Discrim & 42.01 (16.94) & \textbf{0.90} (0.12) & 0.86 (0.14) & 0.77 (0.22) & \textcolor{blue}{0.86} (0.29) & \textbf{85.9\%}\\
%     \bottomrule
%     \end{tabular}
%     }
%     \caption{Results of age-controlled dialogue generation: \textbf{younger}-targeted models, conditioned on \textbf{neutral prompts}. Format: \textit{average metric (standard error)}. \textbf{ppl.} is perplexity w.r.t. GPT-1. \textbf{Dist-$n$} (for $n = 1, 2, 3$) is number of distinct $n$-grams normalized by text length, as a measure of diversity. $\boldsymbol{\bar{P}_Y}$ is the sample's average probability to contain features learned to be younger by BERT$_{FT}$. \textbf{Acc.} is BERT$_{FT}$'s accuracy when classifying the row's samples.}
%     \label{tab:ctg_results_ws_neutral_prompt_young_models}
% \end{table*}

% \begin{table*}[h]
%     \centering
%     \resizebox{\linewidth}{!}{
%     \begin{tabular}{l | c c c c | c c }
%     \toprule
%     \textbf{Model} & \textbf{ppl.} & \textbf{Dist-1} & \textbf{Dist-2} & \textbf{Dist-3} & $\boldsymbol{\bar{P}_O}$ & \textbf{Acc.}\\
%     % -plus)}$\\
%      & $\downarrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better\\
%     \midrule
%     \midrule
%     G-baseline & \textcolor{blue}{27.50} (6.58) & \textbf{0.87} (0.09) & \textbf{0.94} (0.04) & \textcolor{blue}{0.90} (0.06) & 0.38 (0.42) & -\\
%     G-100MCW & 27.56 (6.60) & 0.86 (0.10) & \textcolor{blue}{0.93} (0.04) & \textbf{0.90} (0.05) & 0.37 (0.42) & -\\
%     \midrule
%     G-BoW$_{FB}$ & 27.58 (7.07) & 0.86 (0.10) & \textcolor{blue}{0.93} (0.04) & \textcolor{blue}{0.90} (0.06) & 0.42 (0.42) & 43.0\%\\
%     G-BoW$_{100MIU}$ & \textbf{27.25} (6.15) & \textbf{0.87} (0.09) & \textcolor{blue}{0.93} (0.04) & \textcolor{blue}{0.90} (0.06) & 0.38 (0.42) & 37.4\%\\
%     \midrule
%     G-Discrim & 47.15 (47.56) & 0.73 (0.24) & 0.75 (0.28) & 0.75 (0.27) & \textbf{0.76} (0.36) & \textbf{74.3\%}\\
%     \midrule
%     \midrule
%     D-baseline & 37.52 (12.06) & 0.86 (0.13) & 0.90 (0.08) & 0.85 (0.10) & 0.24 (0.37) & -\\
%     D-100MCW & 37.80 (10.89) & 0.85 (0.14) & 0.89 (0.10) & 0.85 (0.10) & 0.18 (0.33) & -\\
%     \midrule
%     D-BoW$_{FB}$ & 37.85 (11.17) & 0.87 (0.12) & 0.90 (0.08) & 0.86 (0.09) & 0.22 (0.35) & 21.5\%\\
%     D-BoW$_{100MIU}$ & 37.91 (12.27) & \textcolor{blue}{0.87} (0.11) & 0.90 (0.07) & 0.85 (0.10) & 0.22 (0.34) & 21.9\%\\
%     \midrule
%     D-Discrim & 41.17 (20.72) & 0.87 (0.12) & 0.89 (0.13) & 0.83 (0.16) & \textcolor{blue}{0.57} (0.41) & \textcolor{blue}{56.7\%}\\
%     \bottomrule
%     \end{tabular}
%     }
%     \caption{Results of age-controlled dialogue generation: \textbf{older}-targeted models, conditioned on \textbf{neutral prompts}. Format: \textit{average metric (standard error)}. ppl. is perplexity w.r.t. GPT-1. Dist-$n$ (for $n = 1, 2, 3$) is number of distinct $n$-grams normalized by text length, as a measure of diversity. $\boldsymbol{\bar{P}_O}$ is the sample's average probability to contain features learned to be older by BERT$_{FT}$. Acc. is BERT$_{FT}$'s accuracy when classifying the row's samples.}
%     \label{tab:ctg_results_ws_neutral_prompt_old_model}
% \end{table*}


% TABLE 5.6 WITH YOUNG AND OLD PROB. JUST IN CASE %
% \begin{table*}[h]
%     \centering
%     \begin{tabular}{l c c c c c c c}
%     \toprule
%     \textbf{Model} & \textbf{ppl.} & \textbf{Dist-1} & \textbf{Dist-2} & \textbf{Dist-3} & \textbf{Young prob.} & \textbf{Old prob.} & \textbf{Acc.}\\
%     % -plus)}$\\
%      & $\downarrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & - & - & $\uparrow$ better\\
%     \midrule
%     \midrule
%     Baseline & 27.45 ($\pm$7.27) & 0.90 ($\pm$0.10) & 0.92 ($\pm$0.05) & 0.86 ($\pm$0.09) & 0.52 ($\pm$0.32) & 0.48 ($\pm$0.32) & 57.5\%\\
%     \midrule
%     B$_{100MCW}$ & 26.68 ($\pm$8.77) & 0.89 ($\pm$0.10) & 0.92 ($\pm$0.05) & 0.86 ($\pm$0.09) & 0.50 ($\pm$0.29) & 0.50 ($\pm$0.29) & 51.7\%\\
%     B$_{Y, FB}$ & 27.11 ($\pm$7.45) & \textbf{0.91} ($\pm$0.09) & \textbf{0.92} ($\pm$0.04) & \textbf{0.87} ($\pm$0.09) & 0.60 ($\pm$0.29) & 0.40 ($\pm$0.29) & 68.3\%\\
%     B$_{O, FB}$ & 25.99 ($\pm$6.41) & 0.88 ($\pm$0.11) & 0.92 ($\pm$0.05) & 0.86 ($\pm$0.09) & 0.35 ($\pm$0.31) & 0.65 ($\pm$0.31) & 62.5\%\\
%     B$_{Y, 100MIU}$ & 28.48 ($\pm$11.96) & 0.88 ($\pm$0.12) & 0.91 ($\pm$0.06) & 0.86 ($\pm$0.10) & 0.62 ($\pm$0.31) & 0.38 ($\pm$0.31) &69.2\%\\
%     B$_{O, 100MIU}$ & \textbf{25.57} ($\pm$7.44) & 0.88 ($\pm$0.11) & 0.92 ($\pm$0.05) & \textbf{0.87} ($\pm$0.09) & 0.38 ($\pm$0.31) & 0.62 ($\pm$0.31) & 58.3\%\\
%     \midrule
%     D$_{Y, GPT2}$ & 33.02 ($\pm$12.24) & 0.85 ($\pm$0.16) & 0.89 ($\pm$0.07) & 0.83 ($\pm$0.12) & 0.70 ($\pm$0.31) & 0.30 ($\pm$0.31) & 73.9\%\\
%     D$_{O, GPT2}$ & 32.86 ($\pm$18.08) & 0.80 ($\pm$0.21) & 0.84 ($\pm$0.13) & 0.79 ($\pm$0.19) & 0.37 ($\pm$0.29) & 0.63 ($\pm$0.29) & 63.3\%\\
%     D$_{Y, GPT2*}$ & 30.98 ($\pm$13.95) & 0.86 ($\pm$0.15) & 0.90 ($\pm$0.06) & 0.84 ($\pm$0.11) & \textcolor{blue}{0.76} ($\pm$0.29) & 0.29 ($\pm$0.29) & 80.0\%\\
%     D$_{O, GPT2*}$ & 34.81 ($\pm$26.76) & 0.84 ($\pm$0.17) & 0.85 ($\pm$0.13) & 0.77 ($\pm$0.23) & 0.31 ($\pm$0.25) & \textcolor{red}{0.69} ($\pm$0.25) & 75.8\%\\
%     \bottomrule
%     \end{tabular}
%     \caption{Results of age-controlled language generation. Perplexity is perplexity w.r.t. GPT-1. Dist-n is number of distinct n-grams normalized by text length, as a measure of diversity. Young and old accuracy are the assigned probabilities of belonging to the young or old age categories.}
%     \label{tab:ctg_results}
% \end{table*}


%%% THIS ISN'T RELEVANT ANYMORE --CONSIDER DELETING IT %%%%%%%%%%%%%%%%%%%%%%%%%
% \paragraph{Notes on Table \ref{tab:ctg_results}}
% \begin{itemize}
%     \item These are initial results.
%     \item All metrics are averaged over 120 samples: 30 samples per group of sequence lengths 8, 16, 32, and 64.
%     \item Young and old accuracy (last two columns) denote the probability of belonging to the young or old age-groups assigned by the best performing BERT-based classifier.
%     \item I use the same parameter settings as Table 6 of \cite{dathathri2019plug} to make the results comparable, i.e.:
%     \begin{itemize}
%         \item Step-size 0.02. Step-size is $\alpha$ in Equation \ref{eq:H_update_rule}.
%         \item Temperature 1.0.
%         \item Number of update iterations: 3.
%         \item $\gamma$ 1.5.
%         \item GM-scale 0.9.
%         \item KL-scale 0.01.
%     \end{itemize}
%     \item The current baseline is uncontrolled/unperturbed GPT-2.
%     \item There are four settings for BoW-based control:
%     \begin{itemize}
%         \item Young frequency-based wordlist.
%         \item Old frequency-based wordlist.
%         \item Young + most informative unigrams as wordlist.
%         \item Old + most informative unigrams as wordlist.
%     \end{itemize}
%     \item Initial observations:
%     \begin{itemize}
%         \item Fractions of distinct uni-,bi, and trigrams do not change.
%         \item Perplexity seems to improve when controlling generation for each age-group, which isn't necessarily what one would expect.
%         \item The baseline starts off with a higher average probability of belonging to the young age group
%         \item Controlling for young-language does result in a slightly greater assigned probability of belonging to young age-bracket.
%         \item Controlling for old-language results in a doubling of the assigned probability of belonging to the old age-bracket.
%     \end{itemize}
% \end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{itemize}
%     \item \len{Include examples of same original sequence being perturbed differently at the unigram-level between corresponding young and old BoW-based CTG. E.g., \textit{I think you're a nice person (old)} vs. \textit{I think you're a nice guy (young)}}
% \end{itemize}

% \subsubsection{Frequency-based wordlist generation}

% Steps taken to create age-specific wordlists (full imbalanced BNC used):
% \begin{itemize}
%     \item Remove all stopwords. List of stopwords from NLTK's English stopword list. \textbf{TODO: does this make sense? What if differences in use of stopwords are strong indicators of an age-group's speech?}
%     \item Order all unique words by frequency per age-group.
%     \item For both lists, keep the words that account for at least 80\% of the respective cumulative probability densities.
%     \item From both sets of words, remove the words that are in the \textit{union} (i.e., the overlapping set) of the young and old sets.
%     \item For both sets, order the words by frequency.
%     \item For both remaining lists, keep the words that account for at least 80\% of the respective cumulative probability densities.
%     \item \textbf{TODO:} remove curse-words?
%     \item Resulting wordlist lengths:
%         \begin{itemize}
%             \item Young (19-29): 90 words
%             \item Old (50 plus): 225 words
%         \end{itemize}
% \end{itemize}

% \subsubsection{Most informative unigrams as wordlists}

% \subsection{Discriminator-based control}




% \textbf{Notes on the experimental details of Table \ref{tab:ctg_results_ws}:}

% \begin{itemize}
%     \item All sequences are generated unconditionally. I.e., from $\texttt{|<endoftext>|}$ token.
%     \item All results are averaged over 240 samples.
%     \item 
% \end{itemize}






\section{Controlled Dialogue Generation Analyses}
\label{sec:exp2_analyses}

By means of quantitative and qualitative analyses, I seek to study which relationships affect the quality and attribute relevance of the generated responses. The discriminator-based setups, and the BoW-models with the highest average target probabilities (i.e., BoW$_{FB}$ for GPT-2, and BoW$_{100MIU}$ for DialoGPT) are considered for the analyses. The following sections report a series of analyses about the relationship between perplexity and target probability (Section \ref{subsec:ctg_anal_ppl_target_prob}), the effects of response length on generation quality (Section \ref{subsec:ctg_anal_response_length}), the impact of the prompt's style on generation style and quality (Section \ref{subsec:ctg_anal_prompt_class}), and qualitatively observable patterns in generated samples \ref{subsec:ctg_anal_qualitative}.



% \len{TODO - Add examples of generated sequences along with their model's configurations, age-group, etc. Similar to dialogue snippets earlier.}

\subsection{The Relationship between Perplexity and Target Probability}
\label{subsec:ctg_anal_ppl_target_prob}


% \len{NB - THE FOLLOWING PARAGRAPH IS ABOUT THE (DEPRECATED) UNPROMPTED SETUP RESULT. FROM HERE...}
% Figure~\ref{fig:ctg_lineplot_fluency_vs_control} attempts to depict the relationship between fluency and control, as measured by perplexity and BERT's classification accuracy, respectively. On the y-axis, ``mean accuracy'' refers to the average fraction of generated sequences, controlled for young or old language, that are correctly labeled as such by Experiment 1's best BERT classifier. The bars around the averages in Figure~\ref{fig:ctg_lineplot_fluency_vs_control} are 90\% confidence intervals.
% % It can be seen as a proxy for control, because it indicates how resemblant of an age group's vernacular a generated text is deemed to be. 
% % Perplexity, measured by a different language model (GPT-1 \citep{radford2018improving}), is a measure of a language model's uncertainty when posed with the task of predicting a succession of words. Assuming a language model to be a reliable representation of relationships within an actual language, low perplexity can serve as a rough proxy for fluency of a text. However, a major caveat of perplexity is that it only measures uncertainty w.r.t. one language model, making it less generalizable. To slightly reduce this effect, I choose to evaluate perplexity with respect to a different language model than the one used for generation.
% % \len{Disclose the confidence interval level}
% It appears that increasing perplexity is slightly negatively correlated with accuracy. It is also clear from Figure~\ref{fig:ctg_lineplot_fluency_vs_control} that uncertainty about prediction strongly increases for greater perplexity. These two observations indicate that sentences deemed less coherent by GPT-1 tend to be harder to classify by BERT$_{FT}$ with certainty. BERT$_{FT}$ is pre-trained and fine-tuned to pick up syntactic features from dialogue that can indicate a speaker's age. It is therefore plausible that structural deviations from proper syntax (i.e., high perplexity) can obfuscate the age-related linguistic signal BERT$_{FT}$ leverages. Finally, it seems that, on average, the discriminator-based models are more capable of producing correctly classifiable high-perplexity sentences. \len{Why would that be?} However, none of the differences between the average accuracies are statistically significant at the 10\% level, so this conclusion should be taken tentatively.
% \len{...TO HERE.}

% \len{\textbf{TODO!!!: Re-write this paragraph s.t. it fits with the new plots.}}
% \begin{itemize}
%     \item Low, medium, and high perplexity are found using the terciles (i.e., the two points that divide the distribution of perplexities into 3 parts, each containing a third of the population.
%     \item low perplexity: $\text{ppl}\leq27.52$
%     \item medium perplexity: $27.52 < \text{ppl} \leq 35.63$
%     \item high perplexity: $>35.63$
% \end{itemize}

% \len{TODO - Refine the following text. Especially the last part:}
Figures~\ref{fig:barplot_ppl_target_prob_np_gpt2} and \ref{fig:barplot_ppl_target_prob_np_dgpt} show bar charts depicting the relationship between the average target probability ($y$-axes) and perplexity ($x$-axes) assigned to the dialogue responses to neutral prompts (see Table \ref{tab:prompts_per_class}) generated by various PPLM-model setups. The error bars around the average target probabilities are 95\% confidence intervals. Based on the distribution of perplexity observed over all generated responses to neutral prompts, perplexity is binned into three consecutive intervals, bordered by the tertiles of distribution (i.e., the two points that divide the distribution of perplexity into three parts, each containing a third of the distribution). These intervals are named low perplexity ($\text{ppl}<27.52$), medium perplexity ($27.52 \leq \text{ppl} < 35.63$), and high perplexity ($\text{ppl}\geq35.63$).
% Based on the distributions of perplexity among generated samples and the necessity to have sufficiently large sub-sample sizes, perplexity is binned into three consecutive intervals, corresponding to low (0-25), medium (25-50), and high (50+) perplexity. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Bring the plots here
\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_gpt2_disc_np_y.png}
        \caption{}
        \label{subfig:barplot_ppl_target_prob_np_gpt2_disc_young}
     \end{subfigure}
    %  \hfill
     \quad
     \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_gpt2_disc_np_o.png}
        \caption{}
        \label{subfig:barplot_ppl_target_prob_np_gpt2_disc_old}
     \end{subfigure}
    \medskip
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_gpt2_bow_fb_np_y.png}
        \caption{}
        \label{subfig:barplot_ppl_target_prob_np_gpt2_bow_young}
     \end{subfigure}
    %  \hfill
    \quad
     \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_gpt2_bow_fb_np_o.png}
        \caption{}
        \label{subfig:barplot_ppl_target_prob_np_gpt2_bow_old}
     \end{subfigure}
    \caption{Mean target probability ($x$-axes) assigned to GPT-2-based models' samples by BERT$_{FT}$ for increasing ranges of GPT-1 perplexity ($y$-axes). Error bars are 95\% confidence intervals.}
    \label{fig:barplot_ppl_target_prob_np_gpt2}
\end{figure}

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_dgpt_disc_np_y.png}
        \caption{}
        \label{subfig:barplot_ppl_target_prob_np_dgpt_disc_young}
     \end{subfigure}
    %  \hfill
     \quad
     \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_dgpt_disc_np_o.png}
        \caption{}
        \label{subfig:barplot_ppl_target_prob_np_dgpt_disc_old}
     \end{subfigure}
    \medskip
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_dgpt_bow_miu_np_y.png}
        \caption{}
        \label{subfig:barplot_ppl_target_prob_np_dgpt_bow_young}
     \end{subfigure}
    %  \hfill
    \quad
     \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_dgpt_bow_miu_np_o.png}
        \caption{}
        \label{subfig:barplot_ppl_target_prob_np_dgpt_bow_old}
     \end{subfigure}
    \caption{Mean target probability ($y$-axes) assigned to DialoGPT-based models' samples by BERT$_{FT}$ for increasing ranges of GPT-1 perplexity ($x$-axes). Error bars are 95\% confidence intervals.}
    \label{fig:barplot_ppl_target_prob_np_dgpt}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{GPT2-based older targeted PPLM-setups} The GPT2-based older models (Figures~\ref{subfig:barplot_ppl_target_prob_np_gpt2_disc_old} and \ref{subfig:barplot_ppl_target_prob_np_gpt2_bow_old}) show a pattern of increasing perplexity coinciding with higher and more precise assigned target probabilities. Especially so for the older targeted discriminator-based GPT-2 setup, whose responses with relatively high perplexity (50+) are (at a 5\% level) significantly more likely than those with low perplexity to contain features learned to be older by BERT$_{FT}$. High-perplexity responses of this model are also assigned probabilities with more precision, as indicated by the narrower confidence regions. These observations suggest that, controlling the output of GPT-2 to contain more older related features, the responses become more perplexing (and arguably less fluent). This relationship is more salient for discriminator-based control, because the perturbations are more invasive to the sentence structure, which is in line with earlier observations. It also suggests that PPLM prioritizes enforcing attribute control over promoting fluency, when making perturbations to the underlying language model's output distribution.  
% For the GPT-2 Young models' responses (Figures~\ref{subfig:barplot_ppl_target_prob_np_gpt2_disc_young} and \ref{subfig:barplot_ppl_target_prob_np_gpt2_bow_young}) I observe a similar pattern of slight increase of average assigned target probability between low (0-25) and medium (25-50) perplexity. 
\paragraph{GPT2-based younger targeted PPLM-setups} By contrast, there does not appear to be a clear pattern for the younger targeted GPT-2-based models' responses (Figures~\ref{subfig:barplot_ppl_target_prob_np_gpt2_disc_young} and \ref{subfig:barplot_ppl_target_prob_np_gpt2_bow_young}). Higher perplexity responses generated by younger targeted BoW-based GPT-2's seem to coincide being less detectably younger sounding (with lower precision) than lower perplexity ones. And the responses generated by the younger targeted discriminator-based GPT-2 PPLM setups appear to receive roughly equal average target probabilities for increasing perplexity, with slightly lower precision. It must be noted that there are no significant differences at the 5\% level between the average $\bar{P}_Y$, so conclusions about the relationship between perplexity and target probability should be taken tentatively.
% However, in both cases this is followed by a large drop in both average assigned target probability and precision for high-perplexity responses. 

\paragraph{DialoGPT-based older targeted PPLM-setups} The DGPT-based (i.e., DialoGPT-based) models targeted towards generating older related features (Figures~\ref{subfig:barplot_ppl_target_prob_np_dgpt_disc_old} and \ref{subfig:barplot_ppl_target_prob_np_dgpt_bow_old}) display patterns of decreasing target probabilities for increasing perplexity. However, it must be emphasized that responses generated by both these models are rarely seen by BERT$_{FT}$ as likely to contain linguistic features associated with their target age (overall $\bar{P}_O$ of 0.22 and 0.57 for DGPT-BoW Old and DPGT-Discrim Old, respectively). This makes it less reliable to draw conclusions about the relationship between the style-adherence and perplexity of their samples, as they are often not style-adherent to begin with.

\paragraph{DialoGPT-based younger targeted PPLM-setups} DialoGPT's strong proclivity to generate younger sounding responses is noticeable in Figures~\ref{subfig:barplot_ppl_target_prob_np_dgpt_disc_young} and \ref{subfig:barplot_ppl_target_prob_np_dgpt_bow_young}, as depicted by the high average target probabilities and relatively narrow confidence intervals. Furthermore, Figure \ref{subfig:barplot_ppl_target_prob_np_dgpt_disc_young} shows a similar pattern as the ones observed for the older targeted GPT-2-based setups, that is, increasing detectability of target age features for increasing perplexity, with an almost significant difference in average assigned target probabilities between the low and high perplexity responses (as depicted by their slightly overlapping confidence intervals). 
Additionally, one could argue that the BoW-based DGPT younger targeted setup (Figure \ref{subfig:barplot_ppl_target_prob_np_dgpt_bow_young}) shows a similar, yet much less pronounced, pattern to its GPT-2-based counterpart (Figure \ref{subfig:barplot_ppl_target_prob_np_gpt2_bow_young}), where the average assigned target probability decreases for increasing perplexity. However, the differences between the average target probabilities are not statistically significant and too small to draw a conclusion from this result alone.

% \paragraph{Key Takeaways} \len{TODO?}

% That being said, there seem to be no clear patterns between perplexity and target probability in DialoGPT-based models. It could be that DialoGPT's strong bias makes it less reliable to draw conclusions about the effects of PPLM-control for age-related style, given default parameter settings.

% BERT$_{FT}$ seems to have least certainty (i.e., low precision aka high variance) about low-perplexity responses in every case, except DialoGPT-BoW Young (Figure~\ref{subfig:barplot_ppl_target_prob_np_dgpt_bow_young}).

% Both sets of graphs show that patterns in the relationship between target probability and perplexity seem to persist between different types of control (i.e., discriminator-based or BoW-based), when holding the age and underlying language model constant.


% \begin{figure}[H]
%      \centering
%      \begin{subfigure}[b]{0.48\textwidth}
%         \centering
%         \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_gpt2_disc_np_y.png}
%         \caption{}
%         \label{subfig:barplot_ppl_target_prob_np_gpt2_disc_young}
%      \end{subfigure}
%     %  \hfill
%      \quad
%      \begin{subfigure}[b]{0.48\textwidth}
%         \centering
%         \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_gpt2_disc_np_o.png}
%         \caption{}
%         \label{subfig:barplot_ppl_target_prob_np_gpt2_disc_old}
%      \end{subfigure}
%     \medskip
%     \begin{subfigure}[b]{0.48\textwidth}
%         \centering
%         \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_gpt2_bow_fb_np_y.png}
%         \caption{}
%         \label{subfig:barplot_ppl_target_prob_np_gpt2_bow_young}
%      \end{subfigure}
%     %  \hfill
%     \quad
%      \begin{subfigure}[b]{0.48\textwidth}
%         \centering
%         \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_gpt2_bow_fb_np_o.png}
%         \caption{}
%         \label{subfig:barplot_ppl_target_prob_np_gpt2_bow_old}
%      \end{subfigure}
%     \caption{Mean target probability ($x$-axes) assigned to GPT-2-based models' samples by BERT$_{FT}$ for increasing ranges of GPT-1 perplexity ($y$-axes). Error bars are 95\% confidence intervals.}
%     \label{fig:barplot_ppl_target_prob_np_gpt2}
% \end{figure}

% \begin{figure}[H]
%      \centering
%      \begin{subfigure}[b]{0.48\textwidth}
%         \centering
%         \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_dgpt_disc_np_y.png}
%         \caption{}
%         \label{subfig:barplot_ppl_target_prob_np_dgpt_disc_young}
%      \end{subfigure}
%     %  \hfill
%      \quad
%      \begin{subfigure}[b]{0.48\textwidth}
%         \centering
%         \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_dgpt_disc_np_o.png}
%         \caption{}
%         \label{subfig:barplot_ppl_target_prob_np_dgpt_disc_old}
%      \end{subfigure}
%     \medskip
%     \begin{subfigure}[b]{0.48\textwidth}
%         \centering
%         \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_dgpt_bow_miu_np_y.png}
%         \caption{}
%         \label{subfig:barplot_ppl_target_prob_np_dgpt_bow_young}
%      \end{subfigure}
%     %  \hfill
%     \quad
%      \begin{subfigure}[b]{0.48\textwidth}
%         \centering
%         \includegraphics[width=1\columnwidth]{figures/exp2/fluency_control/barplot_ppl_target_prob_dgpt_bow_miu_np_o.png}
%         \caption{}
%         \label{subfig:barplot_ppl_target_prob_np_dgpt_bow_old}
%      \end{subfigure}
%     \caption{Mean target probability ($y$-axes) assigned to DialoGPT-based models' samples by BERT$_{FT}$ for increasing ranges of GPT-1 perplexity ($x$-axes). Error bars are 95\% confidence intervals.}
%     \label{fig:barplot_ppl_target_prob_np_dgpt}
% \end{figure}

% \len{\textbf{Observed patterns in perplexity target-prob plots}}:

% \begin{itemize}
%     % \item For GPT2-based Old models (both discrim (Figure~\ref{subfig:barplot_ppl_target_prob_np_gpt2_disc_old}) and bow (Figure~\ref{subfig:barplot_ppl_target_prob_np_gpt2_bow_old})), there is a very clear pattern of increasing perplexity coinciding with higher assigned target probabilities. Responses with relatively high perplexities (50+) are significantly more likely to contain features learned to be old by BERT$_{FT}$. This suggests there could be a tradeoff between increased levels of attribute relevance (i.e., control) and fluency (i.e., lower perplexity). High-perplexity responses are of the GPT2-old models are also assigned probabilities with more precision (i.e., smaller confidence region).
%     % \item For the GPT-2 Young models' responses I observe a pattern of slight increase of average assigned target probability between low (0-25) and medium (25-50) perplexity, followed by a extreme decrease of assigned target probability and associated precision for high-perplexity responses.
%     % \item DialoGPT's young-bias is noticeable in Figures~\ref{subfig:barplot_ppl_target_prob_np_dgpt_disc_young} and \ref{subfig:barplot_ppl_target_prob_np_dgpt_bow_young}: all high average target probabilities with relatively high certainty.
%     % \item No clear pattern of tradeoff between perplexity and target probability in DialoGPT-based models.
%     % \item BERT$_{FT}$ seems to have least certainty (i.e., low precision aka high variance) about low-perplexity responses in every case, except DialoGPT-BoW Young (Figure~\ref{subfig:barplot_ppl_target_prob_np_dgpt_bow_young}).
%     \item \len{Using the term fluency as a generalization of perplexity can be misleading. Think of another word, just use perplexity, or provide a disclaimer.}
% \end{itemize}


\subsection{The Relationship between Response Length and Various Evaluation Metrics}
\label{subsec:ctg_anal_response_length}

The number of tokens in a generated response coincides with noticeable differences in the used automated evaluation metrics. It is therefore important to get a clearer picture of how the various measures for fluency and control change for different sequence lengths. Moreover, properly understanding these relationships can inform developers of adaptive dialogue systems about preserving output quality and adaptation of responses of arbitrary lengths.

Response length (on the $x$-axes) is plotted against various evaluation metrics in Figures~\ref{fig:lineplots_length_acc_np_gpt2_dgpt} (average BERT$_{FT}$ accuracy), \ref{fig:lineplots_length_ppl_np_gpt2_dgpt} (GPT-1 perplexity), \ref{fig:lineplots_length_dist1_np_gpt2_dgpt} (normalized number of distinct unigrams), \ref{fig:lineplots_length_dist2_np_gpt2_dgpt} (normalized number of distinct bigrams), and \ref{fig:lineplots_length_dist3_np_gpt2_dgpt} (normalized number of distinct trigrams).

% \begin{itemize}
%     \item \textit{Main question: how is generated sequence length related to fluency and control?}
    
%     \item \textit{Study the relationship between generated sequence length (measured in number of tokens) and automated evaluation metrics (i.e., perplexity, dist-n, and accuracy).}
    
%     \item \textit{For every metric and for (all?) models, plot sequence length on the x-axis, and the average metric with confidence intervals on the y-axis.}
    
%     \item \textit{Which patterns do you observe?} 
% \end{itemize}

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.49\textwidth}
        \centering
\includegraphics[width=1\columnwidth]{figures/exp2/sequence_length/lineplot_len_acc_best_gpt2_disc_bow_neutral_prompt_ci_95_errstyle_band.png}
        \caption{}
        \label{subfig:lineplot_length_acc_np_gpt2}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/sequence_length/lineplot_len_acc_best_dgpt_disc_bow_neutral_prompt_ci_95_errstyle_band.png}
        \caption{}
        \label{subfig:lineplot_length_acc_np_dgpt}
     \end{subfigure}
        \caption{Mean BERT$_{FT}$ accuracy. GPT-2-based models (left), DialoGPT-based models (right). Translucent error bands represent 95\% confidence intervals. Plots best viewed in color.}
        \label{fig:lineplots_length_acc_np_gpt2_dgpt}
\end{figure}

% \len{\textbf{Patterns in Figure~\ref{fig:lineplots_length_acc_np_gpt2_dgpt}}}:
% \begin{itemize}
%     % \item No clear trends.
%     % \item BoW-based Old (GPT-2 and DialoGPT) has significantly lower accuracy at almost every length bracket.
%     % \item Shortest responses generated by GPT-2-based models appear to be most challenging to classify for BERT$_{FT}$.
% \end{itemize}

\paragraph{BERT$_{FT}$ Accuracy versus Response Length} Figure~\ref{subfig:lineplot_length_acc_np_gpt2} shows a slight upward trend in average accuracy with greater uncertainty for increasing response length for all GPT-2-based models, except for the BoW-based older generation model. That is, longer sequences are, on average, slightly easier to classify, though with less precision. This is probably due to the fact that longer sentences contain more information to base predictions on. 
By contrast, the DialoGPT-based models in Figure~\ref{fig:lineplots_length_acc_np_gpt2_dgpt} do not seem to show a clear general trend that mean accuracy follows for increasing response length. However, it does seem that DialoGPT's strong bias towards generating younger sounding responses causes output from DialoGPT-based younger generation models to be much easier to classify than that from the older generation models. Overall, it can be seen that the BoW-based older targeted models (GPT-2 and DialoGPT) are significantly more challenging to classify at almost every length bracket.

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.49\textwidth}
        \centering
\includegraphics[width=1\columnwidth]{figures/exp2/sequence_length/lineplot_len_ppl_best_gpt2_disc_bow_neutral_prompt_ci_95_errstyle_band.png}
        \caption{}
        \label{subfig:lineplot_length_ppl_np_gpt2}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/sequence_length/lineplot_len_ppl_best_dgpt_disc_bow_neutral_prompt_ci_95_errstyle_band.png}
        \caption{}
        \label{subfig:lineplot_length_ppl_np_dgpt}
     \end{subfigure}
        % \setlength{\belowcaptionskip}{-39pt}
        \caption{Perplexity. GPT-2-based models (left), DialoGPT-based models (right). Translucent error bands represent 95\% confidence intervals. Plots best viewed in color.}
        \label{fig:lineplots_length_ppl_np_gpt2_dgpt}
\end{figure}

\paragraph{Perplexity versus Response Length} Figure~\ref{fig:lineplots_length_ppl_np_gpt2_dgpt} shows a clear downward trend for both sets of PPLM-setups. Irrespective of the underlying language model being used, longer responses are deemed less perplexing, with more certainty, by GPT-1 than shorter ones. It is worth emphasizing that the model with the highest target probability improvement over its relevant baseline, G-Discrim$_{Old}$, is found to produce significantly more perplexing responses than its GPT-2-based counterparts at most length brackets (see Figure~\ref{subfig:lineplot_length_ppl_np_gpt2}). This finding resonates with Figure~\ref{subfig:barplot_ppl_target_prob_np_gpt2_disc_old} and the idea, that especially for older targeted generation models, increased levels of attribute relevance coincide with worse perplexity.
However, it must be noted that the downward slope of perplexity for increasing response length could be attributable to the nature of calculating perplexity, rather than generation properties of the models. Namely, perplexity essentially averages the sum of the negative exponentiated probabilities $p(\texttt{word} | \texttt{context})$, for every word in a sentence. Because the context increases with every successive word, and larger contexts typically result in less uncertainty, shorter sequences are often given unfairly high perplexities.

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.49\textwidth}
        \centering
\includegraphics[width=1\columnwidth]{figures/exp2/sequence_length/lineplot_len_dist1_best_gpt2_disc_bow__neutral_prompt_ci_95_errstyle_band.png}
        \caption{}
        \label{subfig:lineplot_length_dist1_np_gpt2}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/sequence_length/lineplot_len_dist1_best_dgpt_disc_bow__neutral_prompt_ci_95_errstyle_band.png}
        \caption{}
        \label{subfig:lineplot_length_dist1_np_dgpt}
     \end{subfigure}
        \caption{Dist-1. GPT-2-based models (left), DialoGPT-based models (right). Translucent error bands represent 95\% confidence intervals. Plots best viewed in color.}
        \label{fig:lineplots_length_dist1_np_gpt2_dgpt}
\end{figure}

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.49\textwidth}
        \centering
\includegraphics[width=1\columnwidth]{figures/exp2/sequence_length/lineplot_len_dist2_best_gpt2_disc_bow_neutral_prompt_ci_95_errstyle_band.png}
        \caption{}
        \label{subfig:lineplot_length_dist2_np_gpt2}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/sequence_length/lineplot_len_dist2_best_dgpt_disc_bow_neutral_prompt_ci_95_errstyle_band.png}
        \caption{}
        \label{subfig:lineplot_length_dist2_np_dgpt}
     \end{subfigure}
        \caption{Dist-2. GPT-2-based models (left), DialoGPT-based models (right). Translucent error bands represent 95\% confidence intervals. Plots best viewed in color.}
        \label{fig:lineplots_length_dist2_np_gpt2_dgpt}
\end{figure}

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.49\textwidth}
        \centering
\includegraphics[width=1\columnwidth]{figures/exp2/sequence_length/lineplot_len_dist3_best_gpt2_disc_bow__neutral_prompt_ci_95_errstyle_band.png}
        \caption{}
        \label{subfig:lineplot_length_dist3_np_gpt2}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/sequence_length/lineplot_len_dist3_best_dgpt_disc_bow__neutral_prompt_ci_95_errstyle_band.png}
        \caption{}
        \label{subfig:lineplot_length_dist3_np_dgpt}
     \end{subfigure}
        \caption{Dist-3. GPT-2-based models (left), DialoGPT-based models (right). Translucent error bands represent 95\% confidence intervals. Plots best viewed in color.}
        \label{fig:lineplots_length_dist3_np_gpt2_dgpt}
\end{figure}

% \len{\textbf{Patterns in Figures~\ref{fig:lineplots_length_dist1_np_gpt2_dgpt}, \ref{fig:lineplots_length_dist2_np_gpt2_dgpt}, and \ref{fig:lineplots_length_dist3_np_gpt2_dgpt}}:}

% \begin{itemize}
    % \item Figure~\ref{fig:lineplots_length_dist1_np_gpt2_dgpt} shows that diversity w.r.t. unigrams increases for longer responses. This is most likely just due to the fact that longer sentences have an \textit{a priori} higher probability of repeating words. E.g., stopwords like "the" and "of" are likely to appear multiple times in longer sentences. \len{Is this a valid suggestion?}
    % \item The same figure shows an interesting difference: GPT-2-BoW models generate significantly more diverse responses w.r.t. unigrams for almost every bracket of response length. This could be attributable to BoW-based control altering base-GPT2's generated sentences at the token-level, thus being more likely to preserve the unigram diversity of the unperturbed baseline (G-Baseline's Dist-1 is always in the upper register when looking at the columns in Tables \ref{tab:ctg_results_ws_neutral_prompt_young_models} and \ref{tab:ctg_results_ws_neutral_prompt_old_model}.
    % \item Figure~\ref{fig:lineplots_length_dist2_np_gpt2_dgpt} and shows that variety w.r.t. bigrams makes an initial upward jump between response length of 1-10 and 10-20. Dist-2 then follows a mild downward trend for both GPT2- and DialoGPT-based models. The GPT2-based models' trend is more pronounced and less volatile than DialoGPT's.
    % \item Figure \ref{subfig:lineplot_length_dist2_np_gpt2} shows the BoW-based GPT-2 models also produce significantly more diverse language w.r.t. bigrams for most response lengths.
    % \item Figure~\ref{fig:lineplots_length_dist3_np_gpt2_dgpt} shows similar patterns: initial upward jump in trigram diversity between shortest and second-to-shortest length brackets. GPT-2 models then show a slight downward trend from the 20-30 lengths onward. However, DialoGPT actually show a decreasing increase in trigram diversity for all models.
% \end{itemize}

\paragraph{Diversity versus Response Length} Figure~\ref{fig:lineplots_length_dist1_np_gpt2_dgpt} shows that diversity w.r.t. unigrams decreases for longer responses. This is most likely due to the fact that longer sentences have an \textit{a priori} higher probability of containing repeated words. E.g., stopwords like "the" and "of" are likely to appear multiple times in longer sentences. The same figure shows that GPT-2-BoW models generate significantly more diverse responses w.r.t. unigrams for almost every bracket of response length. This could be attributable to BoW-based control altering base-GPT2's generated sentences at the token-level, thus being more likely to preserve the unigram diversity of the uncontrolled baseline (the GPT-2 baseline's Dist-1 is always in the upper register in Tables \ref{tab:ctg_results_ws_neutral_prompt_young_models} and \ref{tab:ctg_results_ws_neutral_prompt_old_model}).

Figure~\ref{fig:lineplots_length_dist2_np_gpt2_dgpt} shows that variety w.r.t. bigrams makes an initial upward jump between response lengths of 1-10 and 10-20. Dist-2 then follows a mild downward trend for both GPT2- and DialoGPT-based models. However, a detailed inspection of Figure~\ref{subfig:lineplot_length_dist1_np_gpt2} shows that only the discriminator-based setups have a negative slope, whereas the BoW-based setups follow a very slight upward trend. Thus, the BoW-based GPT-2 models produce significantly more diverse language w.r.t. bigrams for most response lengths, attributable to the same reason mentioned above.

Figure~\ref{fig:lineplots_length_dist3_np_gpt2_dgpt} shows similar patterns: an initial upward jump in trigram diversity between shortest and second-to-shortest length brackets. GPT-2 models then show a slight downward trend for the discriminator-based setups from the 20-30 lengths onward, while the BoW-based models become slightly more diverse w.r.t. trigrams.

Overall, it can again be seen that BoW-based models generate detectably more diverse responses (with greater precision), and remain to do so as response length increases. The decreasing diversity of discriminator-based generated responses further confirms that more invasive control during generation impedes textual variety.

% \textbf{Patterns in (obsolete) unprompted results \len{DELETE OR MOVE TO APPENDIX. FROM HERE....}:}
% \begin{itemize}
%     \item \len{NB: These are all patterns observed in the unprompted results. Once prompted results are in, I can interpret them as if length of dialogue response.}
%     \item Increasing sequence length is correlated with decreasing perplexity. Longer sentences are deemed more coherent by GPT-2
%     \item Increasing length seems very slighty positively correlated with average accuracy (and more uncertainty). I.e., longer sequences are, on average, easier to classify, though less precision.
%     \item BoW-based models significantly more distinct  w.r.t. unigrams than dirscrim-based.
%     \item Overall, repetitiveness seems to increase as generated sequences become longer.
%     \item The differences between young and old perplexity are smaller for BoW-based models than for Discrim-based. Same pattern holds for repetitiveness.
% \end{itemize}

% \len{NB: These are all patterns observed in the unprompted results. Once prompted results are in, I can interpret them as if length of dialogue response.}

% The number of tokens being generated in an utterance seems to coincide with noticeable differences in my automated evaluation metrics. It is therefore important to get a clearer picture of how the various measures for fluency and control change for varying sequence lengths. Properly understanding this relationship can inform developers of adaptive dialogue systems about preserving output quality for responses of arbitrary lengths.

% Figure~\ref{fig:ctg_lineplots_len_vs_metrics} presents plots of the relationships between generated sequence length (on the x-axes) and average perplexity (Figure~\ref{fig:ctg_lineplot_len_vs_ppl}), average BERT$_{FT}$ accuracy (Figure~\ref{fig:ctg_lineplot_len_vs_acc}), and average normalized number of distinct unigrams (Figure~\ref{fig:ctg_lineplot_len_vs_dist1}), bigrams (Figure~\ref{fig:ctg_lineplot_len_vs_dist2}), and trigrams (Figure~\ref{fig:ctg_lineplot_len_vs_dist3}).


% Starting with Figure~\ref{fig:ctg_lineplot_len_vs_ppl}, it appears that, for all models, increases in generated utterance length coincide with decreases in perplexity. This is most likely attributable to the nature of calculating perplexity than generation properties of the models. Namely, perplexity essentially averages the sum of the negative exponentiated probabilities $p(\texttt{word} | \texttt{context})$, for every word in a sentence. Because the context increases with every successive word, and larger contexts typically result in less uncertainty, shorter sequences are often given unfairly high perplexities.

% In Figure~\ref{fig:ctg_lineplot_len_vs_acc}, I can see that increasing length seems very slightly positively correlated with average accuracy (and more uncertainty). That is, longer sequences are, on average, slightly easier to classify, though with less precision. This is probably due to the fact that longer sentences contains more information to base predictions on.

% Focusing on repetitive use of unigrams, it appears that BoW-based models generate significantly more diverse utterances than discriminator-based models. 

% Repetitiveness w.r.t. bigrams and trigrams seems to increase as generated sequences become longer.

% Overall, the differences between young and old perplexity are smaller for BoW-based models than for Discriminator-based. Same pattern holds for repetitiveness.

% \len{...TO HERE}


% \begin{figure}[H]
%      \centering
%      \begin{subfigure}[b]{0.49\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{figures/exp2/lineplot_len_dist1_best_gpt2_disc_bow_ci_90_errstyle_bars_nolegend.png}
%         \caption{...}
%         \label{fig:ctg_lineplot_len_vs_dist1}
%      \end{subfigure}
%     %  \hfill
%      \begin{subfigure}[b]{0.49\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{figures/exp2/lineplot_len_dist2_best_gpt2_disc_bow_ci_90_errstyle_bars_nolegend.png}
%         \caption{...}
%         \label{fig:ctg_lineplot_len_vs_dist2}
%      \end{subfigure}
%         \caption{}
%         \label{}
%     % \hfill
%      \begin{subfigure}[b]{0.49\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{figures/exp2/lineplot_len_dist3_best_gpt2_disc_bow_ci_90_errstyle_bars_nolegend.png}
%         \caption{...}
%         \label{fig:ctg_lineplot_len_vs_dist3}
%      \end{subfigure}
%         \caption{}
%         \label{}
% \end{figure}

% \begin{figure}[H]
% \centering
% \includegraphics[width=.4\textwidth]{figures/exp2/lineplot_len_ppl_best_gpt2_disc_bow_ci_90_errstyle_bars.png}\quad
% \includegraphics[width=.4\textwidth]{figures/exp2/lineplot_len_acc_best_gpt2_disc_bow_ci_90_errstyle_bars_nolegend.png}
% % \includegraphics[width=.3\textwidth]{figures/exp2/lineplot_len_dist1_best_gpt2_disc_bow_ci_90_errstyle_bars_nolegend.png}

% \medskip
% \includegraphics[width=.4\textwidth]{figures/exp2/lineplot_len_dist1_best_gpt2_disc_bow_ci_90_errstyle_bars_nolegend.png}\quad
% \includegraphics[width=.4\textwidth]{figures/exp2/lineplot_len_dist2_best_gpt2_disc_bow_ci_90_errstyle_bars_nolegend.png}\quad
% \includegraphics[width=.4\textwidth]{figures/exp2/lineplot_len_dist3_best_gpt2_disc_bow_ci_90_errstyle_bars_nolegend.png}

% \caption{Generated sequence length against various automated metrics.}
% \label{fig:seq_len_vs_auto_metrics}
% \end{figure}

\subsection{The Effects of Prompt Style on PPLM Control}
\label{subsec:ctg_anal_prompt_class}

Recall that given a conditioning text, i.e., $\texttt{prompt}$, a predefined style attribute $a$, and some controlled dialogue generation model parameterized by $\theta$, generating a style-controlled piece of text $\textbf{x}$ entails modeling $p_{\theta}(\textbf{x} | a, \texttt{prompt})$. It is therefore reasonable to expect the output distribution of controlled generation model $p_{\theta}$ to depend (to some extent) on the content and style of the conditioning text, $\texttt{prompt}$. Indeed, the content and style of prompts are found to strongly influence the output of neural text generation models \citep{fan-etal-2018-hierarchical, lester2021power}. Thus, studying the effects of a prompt's age style (i.e., whether a prompt is considered younger, older, or neutral by BERT$_{FT}$) on the style and grammatical quality of PPLM-setups is of great importance, as it could inform developers of adaptive dialogue systems about mitigation of prompt-induced biases.

It is worth mentioning that the effects of prompt style on PPLM-generation are not considered by \cite{dathathri2019plug} and \cite{madotto-etal-2020-plug}. Studying these effects is an important extension of their methods, as not quantitatively taking into account the effects prompt style obfuscates the degree to which one can conclude whether detectable attribute-adherence is the result of controlled generation or prompt-induced bias.
% This is actually a non-negligible fault in their research, because you can bias the style of generation by giving it a biased prompt. 

Figures~\ref{fig:catplot_prompt_class_target_prob} and \ref{fig:catplot_prompt_class_ppl} depict the average target probability and perplexity over responses generated by the baseline, the best BoW-based model, and the discriminator-based model, when prompted with a prompt of either younger, neutral, or older style. More specifically, each bar represents a metric (target probability or perplexity) averaged over $N=270$ samples generated by a single model, when presented with five prompts of the same age style. E.g., the blue bar in Figure~\ref{subfig:catplot_prompt_class_target_prob_gpt2_young} represents the average probability of samples generated by GPT-2 + frequency-based BoW to contain features learned to be younger by BERT$_{FT}$, when the model was presented younger sounding prompts. The explicit numerical values of Figures~\ref{fig:catplot_prompt_class_target_prob} and \ref{fig:catplot_prompt_class_ppl} are found in Tables \ref{tab:ctg_results_ws_young_prompt_young_model}, \ref{tab:ctg_results_ws_young_prompt_old_model}, \ref{tab:ctg_results_ws_old_prompt_young_model}, and \ref{tab:ctg_results_ws_old_prompt_old_model}.

Ideally, the neutrally prompted baseline's assigned probability of generating age-specific responses should be around 0.50. Furthermore, a prompt should shift the target probability in the direction of the prompt class, e.g., a younger sounding prompt should shift a younger targeted model's target probability upwards, and an older targeted model's target probability downwards. It is known from previous results in Tables \ref{tab:ctg_results_ws_neutral_prompt_young_models} and \ref{tab:ctg_results_ws_neutral_prompt_old_model} that the language model baselines are (in varying degrees) biased towards generating younger sounding responses to neutral prompts. Nevertheless, It can be expected that the impact of prompt style persists, albeit to differing degrees based on the (dis)similarity in style between the prompt and response, and the type of attribute model being used (BoW or discriminator).


Figure~\ref{fig:catplot_prompt_class_target_prob}
% and \ref{fig:catplot_prompt_class_ppl}, 
shows that the models' target probabilities indeed move accordingly with the prompts' styles. E.g., the younger prompted younger targeted models achieve the highest target probability, then the neutral prompted ones, and then the older prompted ones (Figures \ref{subfig:catplot_prompt_class_target_prob_gpt2_young} and \ref{subfig:catplot_prompt_class_target_prob_dgpt_young}). The same pattern holds the other way around: an older prompted older targeted model has the highest (older) target probability, then neutrally prompted, and then the younger prompted ones (Figures \ref{subfig:catplot_prompt_class_target_prob_gpt2_old} and \ref{subfig:catplot_prompt_class_target_prob_dgpt_old}). In these last two sub-figures, it can also be clearly seen that the discriminator-based older targeted generation models achieve substantial target probability improvements over the baseline (and BoW-based models), for every style of prompt. By contrast, the younger generation models (Figures \ref{subfig:catplot_prompt_class_target_prob_gpt2_young} and \ref{subfig:catplot_prompt_class_target_prob_dgpt_young}) do not show the same pattern: discriminator-based models achieve similarly subtle improvements in target probability over their baselines as the BoW-based models do. Figure~\ref{subfig:catplot_prompt_class_target_prob_gpt2_young} even shows the discriminator-based models to perform worse than the baseline and BoW-based models.

% So the class of the prompt strongly influences the style of the generated response.

Overall, Figures~\ref{fig:catplot_prompt_class_target_prob} and \ref{fig:catplot_prompt_class_ppl} and Tables \ref{tab:ctg_results_ws_young_prompt_young_model}, \ref{tab:ctg_results_ws_young_prompt_old_model}, \ref{tab:ctg_results_ws_old_prompt_young_model}, and \ref{tab:ctg_results_ws_old_prompt_old_model} show that the style of the prompt clearly nudges the assigned probability of containing age-related features in the direction of the prompt's style. Put more concisely, the style of the prompt strongly influences the style of the generated response. Moreover, using strongly younger prompts results in heavily reinforced younger bias for GPT2 and DialoGPT. Similarly, using an older sounding prompt results in a slightly neutralized younger bias for both language models. Additionally, the discriminator-based older targeted models (GPT-2 and DialoGPT) always yield the greatest relative improvements over the baselines. However, they fail to do so when attempting to generate younger sounding responses, which could suggest that the stylistic features learned to be younger and older by BERT$_{FT}$ lie at different linguistic levels, i.e., learned distinguishing features for younger language could lie mostly at the lexical level, and older ones at the syntactic level. Moreover, this could imply that the linguistic styles representing the younger and older age group are not equally challenging to control for a PPLM-setup. Finally, the aforementioned tables show that the effects of prompt style are largely limited to the target probabilities. For perplexity and distinctiveness, the younger and older prompted results show similar patterns to the neutral-prompted setting: BoW-based models achieve smaller increases in control, but maintain relatively desirable perplexity and diversity. Whereas the discriminator-based models achieve higher levels of control, at the cost of worse perplexity and Dist-scores.

% \len{\textbf{TODO - Add table with used prompts and their assigned target probabilities.}}

\begin{figure}[H]
     \centering
    %  \resizebox{\linewidth}{!}{
     \begin{subfigure}[b]{0.46\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/prompt_class/catplot_prompt_class_target_prob_gpt2_young_models.png}
        \caption{}
        \label{subfig:catplot_prompt_class_target_prob_gpt2_young}
     \end{subfigure}
    %  \hfill
     \quad
     \begin{subfigure}[b]{0.46\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/prompt_class/catplot_prompt_class_target_prob_gpt2_old_models.png}
        \caption{}
        \label{subfig:catplot_prompt_class_target_prob_gpt2_old}
     \end{subfigure}
    \medskip
    \begin{subfigure}[b]{0.46\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/prompt_class/catplot_prompt_class_target_prob_dgpt_young_models.png}
        \caption{}
        \label{subfig:catplot_prompt_class_target_prob_dgpt_young}
     \end{subfigure}
    %  \hfill
    \quad
     \begin{subfigure}[b]{0.46\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/prompt_class/catplot_prompt_class_target_prob_dgpt_old_models.png}
        \caption{}
        \label{subfig:catplot_prompt_class_target_prob_dgpt_old}
     \end{subfigure}
    %  }
    \caption{The average target probabilities assigned to responses generated by various PPLM-setups, conditioned on younger, neutral, or older prompts. The plots are best viewed in color.}
    \label{fig:catplot_prompt_class_target_prob}
\end{figure}
\vspace{-6mm}
\begin{figure}[H]
     \centering
    %  \resizebox{\linewidth}{!}{
     \begin{subfigure}[b]{0.46\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/prompt_class/catplot_prompt_class_ppl_gpt2_young_models.png}
        \caption{}
        \label{subfig:catplot_prompt_class_ppl_gpt2_young}
     \end{subfigure}
    %  \hfill
     \quad
     \begin{subfigure}[b]{0.46\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/prompt_class/catplot_prompt_class_ppl_gpt2_old_models.png}
        \caption{}
        \label{subfig:catplot_prompt_class_ppl_gpt2_old}
     \end{subfigure}
    \medskip
    \begin{subfigure}[b]{0.46\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/prompt_class/catplot_prompt_class_ppl_dgpt_young_models.png}
        \caption{}
        \label{subfig:catplot_prompt_class_ppl_dgpt_young}
     \end{subfigure}
    %  \hfill
    \quad
     \begin{subfigure}[b]{0.46\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/prompt_class/catplot_prompt_class_ppl_dgpt_old_models.png}
        \caption{}
        \label{subfig:catplot_prompt_class_ppl_dgpt_old}
     \end{subfigure}
    %  }
    \caption{The average perplexities of responses generated by various PPLM-setups, conditioned on younger, neutral, or older prompts. The plots are best viewed in color. The plots are best viewed in color.}
    \label{fig:catplot_prompt_class_ppl}
\end{figure}



% Initial observations and interpretations of Tables \ref{tab:ctg_results_ws_young_prompt_young_model}, \ref{tab:ctg_results_ws_young_prompt_old_model}, \ref{tab:ctg_results_ws_old_prompt_young_model}, \ref{tab:ctg_results_ws_old_prompt_old_model}.

% \begin{itemize}
%     % \item Using strongly young-prompt results in heavily reinforced young-bias for GPT2 and DialoGPT.
%     % \item Similarly, old-prompt results in slightly neutralized young-bias for both language models.
%     \item Neutrally prompted patterns persist...
%     \begin{itemize}
%         \item Trade-off between control and fluency + diversity.
%         \item BoW achieves smaller increases in control, but leaves fluency and dist intact.
%         \item Discrim higher levels of control increase wrt baseline, worse quality of text wrt fluency and diversity.
%     \end{itemize}
%     \item Overall, stylistic aspects of prompts heavily influence controllability of response.
% \end{itemize}

\begin{table*}[h!]
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{l | c c c c | c c}
    \toprule
    \textbf{Model} & \textbf{ppl.} & \textbf{Dist-1} & \textbf{Dist-2} & \textbf{Dist-3} & $\boldsymbol{\bar{P}_Y}$ & \textbf{Acc.}\\
    % -plus)}$\\
     & $\downarrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better\\
    \midrule
    \midrule
    G-baseline & \textcolor{blue}{28.05} ($\pm$6.12) & 0.85 ($\pm$0.13) & 0.91 ($\pm$0.08) & 0.88 ($\pm$0.08) & 0.80 ($\pm$0.33) & -\\
    G-100MCW & \textbf{27.71} ($\pm$6.20) & 0.85 ($\pm$0.12) & 0.91 ($\pm$0.09) & 0.88 ($\pm$0.09) & 0.75 ($\pm$0.37) & -\\
    \midrule
    G-B$_{FB, Y}$ & 28.81 ($\pm$7.09) & 0.86 ($\pm$0.12) & \textbf{0.92} ($\pm$0.08) & \textbf{0.89} ($\pm$0.08) & 0.82 ($\pm$0.32) & 83.3\%\\
    G-B$_{100MIU, Y}$ & 28.49 ($\pm$6.49) & 0.86 ($\pm$0.12) & 0.91 ($\pm$0.08) & 0.88 ($\pm$0.08) & 0.83 ($\pm$0.32) & 83.0\%\\
    \midrule
    G-D$_{Y}$ & 39.32 ($\pm$37.49) & 0.84 ($\pm$0.21) & 0.61 ($\pm$0.40) & 0.57 ($\pm$0.40) & 0.70 ($\pm$0.40) & 70.7\%\\
    \midrule
    \midrule
    D-baseline & 36.69 ($\pm$9.11) & 0.87 ($\pm$0.10) & \textcolor{blue}{0.91} ($\pm$0.06) & 0.87 ($\pm$0.08) & \textcolor{blue}{0.90} ($\pm$0.24) & -\\
    D-100MCW & 36.93 ($\pm$9.18) & 0.86 ($\pm$0.11) & \textcolor{blue}{0.91} ($\pm$0.06) & \textcolor{blue}{0.88} ($\pm$0.07) & 0.90 ($\pm$0.25) & -\\
    \midrule
    D-B$_{FB, Y}$ & 37.35 ($\pm$8.60) & \textcolor{blue}{0.88} ($\pm$0.10) & \textcolor{blue}{0.91} ($\pm$0.06) & 0.87 ($\pm$0.08) & 0.90 ($\pm$0.26) & \textcolor{blue}{90.0\%}\\
    D-B$_{100MIU, Y}$ & 37.87 ($\pm$8.32) & \textcolor{blue}{0.88} ($\pm$0.10) & 0.91 ($\pm$0.07) & 0.87 ($\pm$0.09) & \textbf{0.91} ($\pm$0.24) & \textbf{92.6\%}\\
    \midrule
    D-D$_{Y}$ & 39.22 ($\pm$14.96) & \textbf{0.89} ($\pm$0.12) & 0.86 ($\pm$0.19) & 0.79 ($\pm$0.23) & 0.89 ($\pm$0.25) & 91.1\%\\
    \bottomrule
    \end{tabular}
    }
    \caption{Results of age-controlled dialogue generation: \textbf{younger}-targeted models, conditioned on \textbf{young prompts}. Format: \textit{average metric (standard error)}. \textbf{ppl.} is perplexity w.r.t. GPT-1. \textbf{Dist}-$n$ (for $n = 1, 2, 3$) is the number of distinct $n$-grams normalized by text length, as a measure of diversity. $\boldsymbol{\bar{P}_Y}$ is the sample's average probability to contain features learned to be younger by BERT$_{FT}$. \textbf{Acc.} is BERT$_{FT}$'s accuracy when classifying the row's samples. Values in \textbf{bold} are the best in the column; in \textcolor{blue}{blue}, the second-best.}
    \label{tab:ctg_results_ws_young_prompt_young_model}
\end{table*}

\begin{table*}[h!]
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{l | c c c c | c c}
    \toprule
    \textbf{Model} & \textbf{ppl.} & \textbf{Dist-1} & \textbf{Dist-2} & \textbf{Dist-3} & $\boldsymbol{\bar{P}_O}$ & \textbf{Acc.}\\
    % -plus)}$\\
     & $\downarrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better\\
    \midrule
    \midrule
    G-baseline & \textcolor{blue}{28.05} ($\pm$6.12) & 0.85 ($\pm$0.13) & 0.91 ($\pm$0.08) & 0.88 ($\pm$0.08) & 0.20 ($\pm$0.33) & -\\
    G-100MCW & \textbf{27.71} ($\pm$6.20) & 0.85 ($\pm$0.12) & 0.91 ($\pm$0.09) & 0.88 ($\pm$0.09) & 0.25 ($\pm$0.37) & -\\
    \midrule
    G-B$_{FB, O}$ & 28.54 ($\pm$6.45) & 0.86 ($\pm$0.12) & \textbf{0.92} ($\pm$0.08) & \textbf{0.89} ($\pm$0.08) & 0.23 ($\pm$0.36) & 22.6\%\\
    G-B$_{100MIU, O}$ & 28.18 ($\pm$5.70) & 0.87 ($\pm$0.11) & \textbf{0.92} ($\pm$0.08) & \textcolor{blue}{0.89} ($\pm$0.09) & 0.21 ($\pm$0.34) & 21.5\%\\
    \midrule
    G-D$_{O}$ & 85.40 ($\pm$150.28) & 0.67 ($\pm$0.30) & 0.62 ($\pm$0.31) & 0.62 ($\pm$0.32) & \textbf{0.71} ($\pm$0.40) & \textbf{70.5\%}\\
    \midrule
    \midrule
    D-baseline & 36.69 ($\pm$9.11) & \textcolor{blue}{0.87} ($\pm$0.10) & 0.91 ($\pm$0.06) & 0.87 ($\pm$0.08) & 0.10 ($\pm$0.24) & -\\
    D-100MCW & 36.93 ($\pm$9.18) & 0.86 ($\pm$0.11) & 0.91 ($\pm$0.06) & 0.88 ($\pm$0.07) & 0.10 ($\pm$0.25) & -\\
    \midrule
    D-B$_{FB, O}$ & 37.25 ($\pm$9.45) & 0.87 ($\pm$0.11) & 0.91 ($\pm$0.06) & 0.87 ($\pm$0.08) & 0.12 ($\pm$0.29) & 11.1\%\\
    D-B$_{100MIU, O}$ & 37.04 ($\pm$8.78) & \textbf{0.88} ($\pm$0.10) & \textcolor{blue}{0.91} ($\pm$0.05) & 0.88 ($\pm$0.07) & 0.15 ($\pm$0.32) & 15.2\%\\
    \midrule
    D-D$_{O}$ & 38.46 ($\pm$14.91) & 0.82 ($\pm$0.15) & 0.87 ($\pm$0.15) & 0.83 ($\pm$0.17) & \textcolor{blue}{0.48} ($\pm$0.44) & \textcolor{blue}{47.4\%}\\
    \bottomrule
    \end{tabular}
    }
    \caption{Results of age-controlled dialogue generation: \textbf{older} targeted models, conditioned on \textbf{younger prompts}. Format: \textit{average metric (standard error)}. \textbf{ppl.} is perplexity w.r.t. GPT-1. \textbf{Dist}-$n$ (for $n = 1, 2, 3$) is the number of distinct $n$-grams normalized by text length, as a measure of diversity. $\boldsymbol{\bar{P}_O}$ is the sample's average probability to contain features learned to be older by BERT$_{FT}$. \textbf{Acc.} is BERT$_{FT}$'s accuracy when classifying the row's samples. Values in \textbf{bold} are the best in the column; in \textcolor{blue}{blue}, the second-best.}
    \label{tab:ctg_results_ws_young_prompt_old_model}
\end{table*}

\begin{table*}[h!]
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{l | c c c c | c c}
    \toprule
    \textbf{Model} & \textbf{ppl.} & \textbf{Dist-1} & \textbf{Dist-2} & \textbf{Dist-3} & $\boldsymbol{\bar{P}_Y}$ & \textbf{Acc.}\\
    % -plus)}$\\
     & $\downarrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better\\
    \midrule
    \midrule
    G-baseline & \textcolor{blue}{29.34} ($\pm$10.30) & 0.86 ($\pm$0.09) & \textbf{0.94} ($\pm$0.04) & \textcolor{blue}{0.90} ($\pm$0.06) & 0.60 ($\pm$0.43) & -\\
    G-100MCW & \textbf{29.14} ($\pm$10.11) & 0.86 ($\pm$0.10) & \textcolor{blue}{0.93} ($\pm$0.04) & \textcolor{blue}{0.90} ($\pm$0.06) & 0.60 ($\pm$0.44) & -\\
    \midrule
    G-B$_{Y, FB}$ & 29.61 ($\pm$10.28) & 0.86 ($\pm$0.10) & 0.93 ($\pm$0.04) & \textbf{0.91} ($\pm$0.06) & 0.62 ($\pm$0.43) & 61.1\%\\
    G-B$_{Y, 100MIU}$ & 29.51 ($\pm$0.09) & \textcolor{blue}{0.87} ($\pm$0.09) & 0.93 ($\pm$0.05) & \textcolor{blue}{0.90} ($\pm$0.06) & 0.68 ($\pm$0.42) & 68.5\%\\
    \midrule
    G-D$_{Y}$ & 32.34 ($\pm$19.88) & 0.77 ($\pm$0.20) & 0.84 ($\pm$0.19) & 0.80 ($\pm$0.23) & 0.65 ($\pm$0.43) & 65.4\%\\
    \midrule
    \midrule
    D-baseline & 38.18 ($\pm$12.03) & 0.86 ($\pm$0.12) & 0.90 ($\pm$0.08) & 0.86 ($\pm$0.09) & 0.72 ($\pm$0.38) & -\\
    D-100MCW & 37.73 ($\pm$11.88) & 0.85 ($\pm$0.13) & 0.90 ($\pm$0.08) & 0.86 ($\pm$0.09) & 0.73 ($\pm$0.39) & -\\
    \midrule
    D-B$_{Y, FB}$ & 38.24 ($\pm$11.53) & 0.86 ($\pm$0.12) & 0.90 ($\pm$0.08) & 0.86 ($\pm$0.10) & 0.81 ($\pm$0.34) & \textcolor{blue}{82.6\%}\\
    D-B$_{Y, 100MIU}$ & 38.66 ($\pm$11.57) & 0.85 ($\pm$0.12) & 0.90 ($\pm$0.07) & 0.86 ($\pm$0.09) & \textcolor{blue}{0.81} ($\pm$0.33) & 80.7\%\\
    \midrule
    D-D$_{Y}$ & 42.93 ($\pm$20.18) & \textbf{0.90} ($\pm$0.14) & 0.79 ($\pm$0.22) & 0.68 ($\pm$0.28) & \textbf{0.84} ($\pm$0.30) & \textbf{85.2\%}\\
    \bottomrule
    \end{tabular}
    }
    \caption{Results of age-controlled dialogue generation: \textbf{younger}-targeted models, conditioned on \textbf{older prompts}. Format: \textit{average metric (standard error)}. \textbf{ppl.} is perplexity w.r.t. GPT-1. \textbf{Dist}-$n$ (for $n = 1, 2, 3$) is the number of distinct $n$-grams normalized by text length, as a measure of diversity. $\boldsymbol{\bar{P}_Y}$ is the sample's average probability to contain features learned to be younger by BERT$_{FT}$. \textbf{Acc.} is BERT$_{FT}$'s accuracy when classifying the row's samples. Values in \textbf{bold} are the best in the column; in \textcolor{blue}{blue}, the second-best.}
    \label{tab:ctg_results_ws_old_prompt_young_model}
\end{table*}

\begin{table*}[h]
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{l | c c c c | c c}
    \toprule
    \textbf{Model} & \textbf{ppl.} & \textbf{Dist-1} & \textbf{Dist-2} & \textbf{Dist-3} & $\boldsymbol{\bar{P}_O}$ & \textbf{Acc.}\\
    % -plus)}$\\
     & $\downarrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better & $\uparrow$ better\\
    \midrule
    \midrule
    G-baseline & 29.34 ($\pm$10.30) & \textcolor{blue}{0.86} ($\pm$0.09) & \textbf{0.94} ($\pm$0.04) & \textbf{0.90} ($\pm$0.06) & 0.40 ($\pm$0.43) & -\\
    G-100MCW & 29.14 ($\pm$10.11) & 0.86 ($\pm$0.10) & \textcolor{blue}{0.93} ($\pm$0.04) & \textbf{0.90} ($\pm$0.06) & 0.40 ($\pm$0.44) & -\\
    \midrule
    G-B$_{O, FB}$ & \textbf{28.81} ($\pm$10.10) & 0.86 ($\pm$0.10) & 0.93 ($\pm$0.05) & \textbf{0.90} ($\pm$0.06) & 0.41 ($\pm$0.43) & 41.1\%\\
    G-B$_{O, 100MIU}$ & 29.05 ($\pm$9.80) & \textcolor{blue}{0.86} ($\pm$0.09) & \textcolor{blue}{0.93} ($\pm$0.04) & \textbf{0.90} ($\pm$0.06) & 0.40 ($\pm$0.43) & 39.6\%\\
    \midrule
    G-D$_{O}$ & 95.21 ($\pm$174.42) & 0.65 ($\pm$0.27) & 0.78 ($\pm$0.18) & 0.78 ($\pm$0.18) & \textbf{0.90} ($\pm$0.25) & \textbf{90.3\%}\\
    \midrule
    \midrule
    D-baseline & 38.18 ($\pm$12.03) & 0.86 ($\pm$0.12) & 0.90 ($\pm$0.08) & 0.86 ($\pm$0.09) & 0.28 ($\pm$0.38) & -\\
    D-100MCW & 37.73 ($\pm$11.88) & 0.85 ($\pm$0.13) & 0.90 ($\pm$0.08) & 0.86 ($\pm$0.09) & 0.27 ($\pm$0.39) & -\\
    \midrule
    D-B$_{O, FB}$ & 37.80 ($\pm$11.74) & 0.86 ($\pm$0.12) & 0.90 ($\pm$0.07) & \textcolor{blue}{0.87} ($\pm$0.08) & 0.28 ($\pm$0.39) & 29.3\%\\
    D-B$_{O, 100MIU}$ & 36.93 ($\pm$11.68) & \textbf{0.87} ($\pm$0.12) & 0.90 ($\pm$0.09) & 0.86 ($\pm$0.09) & 0.31 ($\pm$0.41) & 29.6\%\\
    \midrule
    D-D$_{O}$ & 40.08 ($\pm$16.77) & 0.85 ($\pm$0.14) & 0.88 ($\pm$0.10) & 0.83 ($\pm$0.14) & \textcolor{blue}{0.61} ($\pm$0.42) & \textcolor{blue}{61.1\%}\\
    \bottomrule
    \end{tabular}
    }
    \caption{Results of age-controlled dialogue generation: \textbf{older} targeted models, conditioned on \textbf{older prompts}. Format: \textit{average metric (standard error)}. \textbf{ppl.} is perplexity w.r.t. GPT-1. \textbf{Dist}-$n$ (for $n = 1, 2, 3$) is the number of distinct $n$-grams normalized by text length, as a measure of diversity. $\boldsymbol{\bar{P}_O}$ is the sample's average probability to contain features learned to be older by BERT$_{FT}$. \textbf{Acc.} is BERT$_{FT}$'s accuracy when classifying the row's samples. Values in \textbf{bold} are the best in the column; in \textcolor{blue}{blue}, the second-best.}
    \label{tab:ctg_results_ws_old_prompt_old_model}
\end{table*}


% \subsubsection{Quantitative 3: The Effects of PPLM-Parameters on Fluency and Control}

% \begin{itemize}
%     \item \textit{Plot and examine the relationship between fluency and control, and various PPLM-parameters (step-size, number of iterations, temperature, top $k$, gamma, KL-scale).}
%     \item \textit{Which patterns do you observe?}
%     \item \len{How much sense does it make to study this, though? Is that the purpose of my thesis? Hasn't this been studied enough in the PPLM-paper? Which parameters do I choose?}
% \end{itemize}
\newpage
\subsection{Visual Analysis of BERT$_{FT}$ Attention Patterns}
I use visualizations of attention mechanisms \citep{vig-2019-multiscale} in BERT$_{FT}$'s attention heads to analyze recurring patterns when assigning target probabilities to generated prompt-response pairs. An attention weight can be interpreted as an indication of how important a particular token is when producing the next representation of the current token \citep{DBLP:journals/corr/BahdanauCB14, clark-etal-2019-bert}. Please note that the PPLM-method does not change the attention weights of the underlying language models, so visualizing the attention weights of the generation models would not reveal any age-related attention patterns. By contrast, BERT$_{FT}$ is fine-tuned to detect age-related patterns, so visualizing its attention maps can inform decisions about which features are important when assigning a target-age probability to a generated sentence. Despite this seemingly natural interpretation, there is much debate about the validity of using attention mechanisms (as opposed to, e.g., saliency methods) as explanations for model output \citep{jain-wallace-2019-attention, wiegreffe-pinter-2019-attention, bastings-filippova-2020-elephant}. However, as \cite{vig-2019-multiscale} and \cite{clark-etal-2019-bert} suggest, attention weight visualization can be used tentatively as a complementary analysis tool to add to sets of different analysis methods to inform researchers about, e.g., possible linguistic patterns that may be attended to by attention-based models.

To provide a clear reading experience of the analyses presented below, I recapitulate a few important concepts about BERT and how to read attention weight visualizations. During pre-processing, BERT tokenizes the input text and adds a special token \texttt{[CLS]} to the beginning of the text, and another special token \texttt{[SEP]} is appended to the text. If an input sequence consists of multiple sentences (e.g., a question-answer, or prompt-response input), \texttt{[SEP]} tokens are also used to separate the sentences. BERT$_{FT}$ is a fine-tuned version of BERT-base-uncased \citep{devlin-etal-2019-bert}, which consists of 12 layers of 12 attention heads. A specific attention head is referred to as Head \texttt{layer\_number}-\texttt{head\_number}, where \texttt{layer\_number} and \texttt{head\_number} both range from 0 to 11. E.g., Head 3-1 refers to Head 1 in Layer 3. Furthermore, attention weights are visualized as colored lines between tokens of the input sequence, where a thicker line corresponds to a greater attention weight, and the color represents the layer in which the head is present. The input text is displayed twice in parallel columns, to make visualizations of self-attention possible (visualized as lines between identical tokens in the same positions). Because BERT is designed to be deeply bidirectional, tokens can also attend to tokens in previous positions in the input text.

Figures \ref{fig:bertviz_model_view_ypr1}, \ref{fig:bertviz_model_view_ypr2}, \ref{fig:bertviz_model_view_opr1}, and \ref{fig:bertviz_model_view_opr2} show attention visualizations of BERT$_{FT}$ when processing prompt-response pairs that are cherry-picked from the age-targeted prompted results, presented in Tables \ref{tab:ctg_results_ws_young_prompt_young_model} and \ref{tab:ctg_results_ws_old_prompt_old_model}. The generated sequences are chosen to display more pronounced examples of recurring attention patterns. Two younger targeted generated responses to younger sounding prompts are shown in Figures \ref{fig:bertviz_model_view_ypr1} and \ref{fig:bertviz_model_view_ypr2}, and two older targeted generated responses to older sounding prompts are shown in Figures \ref{fig:bertviz_model_view_opr1} and \ref{fig:bertviz_model_view_opr2}. All prompts and responses received target probabilities from BERT$_{FT}$ of at least 95\%.

Heads in the same layer have the tendency to attend to similar patterns and linguistic phenomena \cite{clark-etal-2019-bert}. The results of the analyses seem to confirm this behavior, as recurring patterns are observed for heads in the same layers. For instance, it can be seen (in Figures \ref{subfig:bertviz_model_view_ypr1_broad}, \ref{subfig:bertviz_model_view_ypr2_broad}, \ref{subfig:bertviz_model_view_opr1_broad}, and \ref{subfig:bertviz_model_view_opr2_broad}) that heads in the last layer (11) tend to broadly disperse attention among all tokens. Recurring patterns are also observed in earlier layers, such as Head 2-9 attending to the next token in the sequence (Figures \ref{subfig:bertviz_model_view_ypr1_next}, \ref{subfig:bertviz_model_view_ypr2_next}, \ref{subfig:bertviz_model_view_opr1_next}, and \ref{subfig:bertviz_model_view_opr2_next}), and Head 4-4 attending to the special tokens (Figures \ref{subfig:bertviz_model_view_ypr1_special}, \ref{subfig:bertviz_model_view_ypr2_special}, \ref{subfig:bertviz_model_view_opr1_special}, and \ref{subfig:bertviz_model_view_opr2_special}). Certain heads also seem to pay special attention to age-related linguistic features, specifically certain tokens associated with an age group (mentioned in Section \ref{subsec:ctg_anal_qualitative}). This is most noticeable in Head 9-0 (Figures \ref{subfig:bertviz_model_view_ypr1_age}, \ref{subfig:bertviz_model_view_ypr2_age}, \ref{subfig:bertviz_model_view_opr1_age}, and \ref{subfig:bertviz_model_view_opr2_age}), which seems to consistently devote the majority of its attention to tokens that are found to be indicative of age. For instance, Head 9-0 attends strongly to younger sounding tokens like \textit{Facebook}, \textit{awesome}, \textit{cool}, and slang and swear words in Figures \ref{subfig:bertviz_model_view_ypr1_age} and \ref{subfig:bertviz_model_view_ypr2_age}. And the same attention head then focuses strongly on tokens associated with older age in Figures \ref{subfig:bertviz_model_view_opr1_age} and \ref{subfig:bertviz_model_view_opr2_age}: e.g., \textit{workers}, \textit{union}, \textit{greetings}, or \textit{fellow}.

% \vspace{-10mm}

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/bertviz/ypr1/bert_model_view_ypr1_layer_11_head_1.png}
        \captionsetup{font=footnotesize,labelfont=footnotesize}
        \caption{Attends broadly.}
        \label{subfig:bertviz_model_view_ypr1_broad}
     \end{subfigure}
    %  \hfill
     \quad
     \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/bertviz/ypr1/bert_model_view_ypr1_layer_2_head_9.png}
        \captionsetup{font=footnotesize,labelfont=footnotesize}
        \caption{Attends to next token.}
        \label{subfig:bertviz_model_view_ypr1_next}
     \end{subfigure}
    \quad
    \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/bertviz/ypr1/bert_model_view_ypr1_layer_4_head_4.png}
        \captionsetup{font=footnotesize,labelfont=footnotesize}
        \caption{Attends to special tokens.}
        \label{subfig:bertviz_model_view_ypr1_special}
     \end{subfigure}
    %  \hfill
    \quad
     \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/bertviz/ypr1/bert_model_view_ypr1_layer_9_head_0.png}
        \captionsetup{font=footnotesize,labelfont=footnotesize}
        \caption{Age-related attention.}
        \label{subfig:bertviz_model_view_ypr1_age}
     \end{subfigure}
    \caption{Attention weights visualizations of four of BERT$_{FT}$'s attentions heads and the patterns to which they presumably attend when processing representations for a cherry-picked prompt-response pair generated by \textbf{younger} targeted GPT2-Discrim.}
    \label{fig:bertviz_model_view_ypr1}
\end{figure}

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/bertviz/ypr2/bert_model_view_ypr2_layer_11_head_1.png}
        \captionsetup{font=footnotesize,labelfont=footnotesize}
        \caption{Attends broadly.}
        \label{subfig:bertviz_model_view_ypr2_broad}
     \end{subfigure}
    %  \hfill
     \quad
     \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/bertviz/ypr2/bert_model_view_ypr2_layer_2_head_9.png}
        \captionsetup{font=footnotesize,labelfont=footnotesize}
        \caption{Attends to next token.}
        \label{subfig:bertviz_model_view_ypr2_next}
     \end{subfigure}
    \quad
    \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/bertviz/ypr2/bert_model_view_ypr2_layer_4_head_4.png}
        \captionsetup{font=footnotesize,labelfont=footnotesize}
        \caption{Attends to special tokens.}
        \label{subfig:bertviz_model_view_ypr2_special}
     \end{subfigure}
    %  \hfill
    \quad
     \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/bertviz/ypr2/bert_model_view_ypr2_layer_9_head_0.png}
        \captionsetup{font=footnotesize,labelfont=footnotesize}
        \caption{Age-related attention.}
        \label{subfig:bertviz_model_view_ypr2_age}
     \end{subfigure}
    \caption{Attention weights visualizations of four of BERT$_{FT}$'s attentions heads and the patterns to which they presumably attend when processing representations for a cherry-picked prompt-response pair generated by \textbf{younger} targeted GPT2-BoW$_{100MIU}$.}
    \label{fig:bertviz_model_view_ypr2}
\end{figure}

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/bertviz/opr1/bert_model_view_opr1_layer_11_head_1.png}
        \captionsetup{font=footnotesize,labelfont=footnotesize}
        \caption{Attends broadly.}
        \label{subfig:bertviz_model_view_opr1_broad}
     \end{subfigure}
    %  \hfill
     \quad
     \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/bertviz/opr1/bert_model_view_opr1_layer_2_head_9.png}
        \captionsetup{font=footnotesize,labelfont=footnotesize}
        \caption{Attends to next token.}
        \label{subfig:bertviz_model_view_opr1_next}
     \end{subfigure}
    \quad
    \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/bertviz/opr1/bert_model_view_opr1_layer_4_head_4.png}
        \captionsetup{font=footnotesize,labelfont=footnotesize}
        \caption{Attends to special tokens.}
        \label{subfig:bertviz_model_view_opr1_special}
     \end{subfigure}
    %  \hfill
    \quad
     \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/bertviz/opr1/bert_model_view_opr1_layer_9_head_0.png}
        \captionsetup{font=footnotesize,labelfont=footnotesize}
        \caption{Age-related attention.}
        \label{subfig:bertviz_model_view_opr1_age}
     \end{subfigure}
    \caption{Attention weights visualizations of four of BERT$_{FT}$'s attentions heads and the patterns to which they presumably attend when processing representations for a cherry-picked prompt-response pair generated by \textbf{older} targeted GPT2-Discrim.}
    \label{fig:bertviz_model_view_opr1}
\end{figure}

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/bertviz/opr2/bert_model_view_opr2_layer_11_head_1.png}
        \captionsetup{font=footnotesize,labelfont=footnotesize}
        \caption{Attends broadly.}
        \label{subfig:bertviz_model_view_opr2_broad}
     \end{subfigure}
    %  \hfill
     \quad
     \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/bertviz/opr2/bert_model_view_opr2_layer_2_head_9.png}
        \captionsetup{font=footnotesize,labelfont=footnotesize}
        \caption{Attends to next token.}
        \label{subfig:bertviz_model_view_opr2_next}
     \end{subfigure}
    \quad
    \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/bertviz/opr2/bert_model_view_opr2_layer_4_head_4.png}
        \captionsetup{font=footnotesize,labelfont=footnotesize}
        \caption{Attends to special tokens.}
        \label{subfig:bertviz_model_view_opr2_special}
     \end{subfigure}
    %  \hfill
    \quad
     \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{figures/exp2/bertviz/opr2/bert_model_view_opr2_layer_9_head_0.png}
        \captionsetup{font=footnotesize,labelfont=footnotesize}
        \caption{Age-related attention.}
        \label{subfig:bertviz_model_view_opr2_age}
     \end{subfigure}
    \caption{Attention weights visualizations of four of BERT$_{FT}$'s attentions heads and the patterns to which they presumably attend when processing representations for a cherry-picked prompt-response pair generated by \textbf{older} targeted DGPT-Discrim.}
    \label{fig:bertviz_model_view_opr2}
\end{figure}

\subsection{Qualitative Analysis of Generated Dialogue Responses}
\label{subsec:ctg_anal_qualitative}

% \subsubsection{Qualitative 1: Summary Statistics and Qualitative Inspection of Various Cases}

% \begin{itemize}
%     \item \textit{Similar to (error)case analyses of Experiment 1.}
    
%     \item \textit{Provide summary statistics and (\textbf{qualitative}) inspection of generated sequences per case.}
    
%     \item \textit{Cases could be: (1) sequences with low, average, high, or very-high perplexity. (2) (in)correctly classified generated sequences.}
    
%     \item \textit{What patterns do you observe among, e.g., misclassified sequences with low perplexity?}
    
%     \item \textit{Provide table of examples per case and age-group. Similar to table \ref{tab:qualexamples}}
% \end{itemize}

% \len{\textbf{Structure as follows:}}

% \begin{itemize}
%     \item Split the generated responses by their (1) perplexity and (2) target probability/classification case.
%     \item Provide summary statistics 
% \end{itemize}

Similar to the previous manual inspection of dialogue utterances in Section \ref{subsec:exp1_comparing_model_preds} and most informative $n$-grams in Section \ref{subsec:exp1_most_inf_ngrams}, what follows now is a qualitative analysis of the generated dialogue responses for various cases.
This section reports a quick overview of how the responses generated by the best-performing models are distributed among various categories relating to their level of perplexity (low, medium, or high) and classification status (correctly or incorrectly classified).
Then, there follows a manual inspection of the most distinct sets of cases (also referred to as sub-samples) for observable age-related linguistic patterns, and discuss how they relate to my expectations, the previous qualitative analyses, and earlier work on the relationship between age and language.


The generated responses to neutral prompts are split by (1) whether or not BERT$_{FT}$ correctly classified a response as its target class, and (2) the level of perplexity: low ($\text{ppl.} < 27.52$), medium ($27.52 \leq \text{ppl.} < 35.63$), or high ($\text{ppl.} \geq 35.63$). See Section \ref{subsec:ctg_anal_ppl_target_prob} for an explanation of the rationale behind these intervals. Table \ref{tab:ctg_model_case_pcts} shows how the generated responses are distributed among these cases for the best-performing BoW-based models (among all BoW-based models), and discriminator-based models for both underlying language models and target age groups. As can be seen, the majority of the responses generated by GPT-2 BoW-based models lie in the low perplexity range, whereas the discriminator-based GPT-2 models also generate considerable amounts of high-perplexity responses (e.g., 37.2\% high-perplexity correctly classified for G-Discrim$_{Old}$). By contrast, the DialoGPT-based models all show the majority of their distributions lying in the medium-to-high perplexity range.

To narrow down the comparison, the qualitative inspection of samples is limited to responses generated by the discriminator-based models of both language models and age groups (i.e., samples generated by G-Discrim$_{Young}$, G-Discrim$_{Old}$, D-Discrim$_{Young}$, and D-Discrim$_{Old}$). Moreover, these models are all among those with the highest target probability improvements over their respective baselines in Tables \ref{tab:ctg_results_ws_neutral_prompt_young_models} and \ref{tab:ctg_results_ws_neutral_prompt_old_model}, so the differences in language style should be most pronounced between these setups. Furthermore, to emphasize the differences between perplexity, I only consider low versus high perplexity samples. Finally, the samples used for qualitative inspection are also split by whether or not they were correctly classified by BERT$_{FT}$. To summarize, the qualitative inspections are performed on a total of 16 splits: by model (G-Discrim$_{Young}$, G-Discrim$_{Old}$, D-Discrim$_{Young}$, or D-Discrim$_{Old}$), perplexity (low or high), and classification outcome (correct or incorrect). Table \ref{tab:ctg_case_examples} shows examples of generated responses containing the patterns and observations discussed in the remainder of this section.

\begin{table}[H]
    \begin{subtable}{0.5\linewidth}\centering
    {\begin{tabular}{r l}
    \hline
        \ \cellcolor{yellow!25}\textbf{\textit{PROMPT}} & \multicolumn{1}{>{\columncolor{yellow!10}}l}{\tabularCenterstack{l}{Good weather \\ we're having.}}\\
        \hline 
        \cellcolor{red!25}\textbf{\textit{GPT-2$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{It's awesome weather.}}\\
        \ \cellcolor{blue!25}\textbf{\textit{GPT-2$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{It's not been quite a\\good weather for long.}}\\
        \ \cellcolor{red!25}\textbf{\textit{DialoGPT$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{Gonna make the\\ weather better.}}\\
        \ \cellcolor{blue!25}\textbf{\textit{DialoGPT$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{It's not the best \\weather in the country.}}\\
        \hline
        \hline
        \ \cellcolor{yellow!25}\textbf{\textit{PROMPT}} & \multicolumn{1}{>{\columncolor{yellow!10}}l}{\tabularCenterstack{l}{Hi, how's it going?}}\\
        \hline 
        \cellcolor{red!25}\textbf{\textit{GPT-2$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{ It's been almost \\2 weeks now since\\ my boyfriend \\has been gone.}}\\
        \ \cellcolor{blue!25}\textbf{\textit{GPT-2$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{ I've had my first \\ surgery recently.}}\\
        \hline
        % \ \cellcolor{red!25}\textbf{\textit{DialoGPT$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{...}}\\
        \ \cellcolor{blue!25}\textbf{\textit{DialoGPT$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{You have you're \\ first born daughter\\ going on with \\the surgery????}}\\
        \hline
        \hline
        \ \cellcolor{yellow!25}\textbf{\textit{PROMPT}} & \multicolumn{1}{>{\columncolor{yellow!10}}l}{\tabularCenterstack{l}{Can we talk?}}\\
        \hline 
        \cellcolor{red!25}\textbf{\textit{GPT-2$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{We have to\\ stop talking \\about this is all \\going so stupid lol\\ lol, sh*t just\\ got weird lol LOL.}}\\
        \ \cellcolor{blue!25}\textbf{\textit{GPT-2$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{The question was\\ raised in a response\\ sent by an official.}}\\
        \ \cellcolor{red!25}\textbf{\textit{DialoGPT$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{You guys are \\doing a lot.}}\\
        \ \cellcolor{blue!25}\textbf{\textit{DialoGPT$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{ We have talked\\ about your past\\ your previous history.}}\\
    \hline
    \end{tabular}}
    \caption{Low perplexity \& correctly classified.}\label{subtab:ctg_case_examples_low_ppl_correct}
    \end{subtable}%
    \begin{subtable}{0.5\linewidth}\centering
    {\begin{tabular}{r l}
    \hline
        \ \cellcolor{yellow!25}\textbf{\textit{PROMPT}} & \multicolumn{1}{>{\columncolor{yellow!10}}l}{\tabularCenterstack{l}{Good weather \\ we're having.}}\\
        \hline 
        \cellcolor{red!25}\textbf{\textit{GPT-2$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{ The Weather\\ is nice,\\ the temperature \\cool,\\ the traffic good.}}\\
        \ \cellcolor{blue!25}\textbf{\textit{GPT-2$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{The sun was setting\\ when we were\\ getting up with\\ a huge rain.}}\\
        \ \cellcolor{red!25}\textbf{\textit{DialoGPT$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{Cold weather \\we can't handle it}}\\
        % \ \cellcolor{blue!25}\textbf{\textit{DialoGPT$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{...}}\\
        \hline
        \hline
        % \ \cellcolor{yellow!25}\textbf{\textit{PROMPT}} & \multicolumn{1}{>{\columncolor{yellow!10}}l}{\tabularCenterstack{l}{Can we talk?}}\\
        % \hline
        % \cellcolor{red!25}\textbf{\textit{GPT-2$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{ Can we talk\\ with some sense?}}\\
        % \ \cellcolor{blue!25}\textbf{\textit{GPT-2$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{ No, not about your \\ favourite club.}}\\
        % \ \cellcolor{red!25}\textbf{\textit{DialoGPT$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{We have a meeting\\ in a bit.}}\\
        % \ \cellcolor{blue!25}\textbf{\textit{DialoGPT$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{What I can't.}}\\
        % \hline
        % \ \cellcolor{blue!25}\textbf{\textit{DialoGPT$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{We have a couple\\ more people interested!}}\\
        % \hline
        % \hline
        \ \cellcolor{yellow!25}\textbf{\textit{PROMPT}} & \multicolumn{1}{>{\columncolor{yellow!10}}l}{\tabularCenterstack{l}{Hello, tell me \\about your \\ latest holiday.}}\\
        \hline 
        \cellcolor{red!25}\textbf{\textit{GPT-2$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{I'm trying hard \\to stay away.}}\\
        \ \cellcolor{blue!25}\textbf{\textit{GPT-2$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{It's not my \\ favorite holiday.}}\\
        % \ \cellcolor{red!25}\textbf{\textit{DialoGPT$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{...}}\\
        \ \cellcolor{blue!25}\textbf{\textit{DialoGPT$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{It was a \\great weekend!}}\\
        \hline
        \hline
        \ \cellcolor{yellow!25}\textbf{\textit{PROMPT}} & \multicolumn{1}{>{\columncolor{yellow!10}}l}{\tabularCenterstack{l}{Can we talk?}}\\
        \hline
        \cellcolor{red!25}\textbf{\textit{GPT-2$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{ Can we talk\\ with some sense?}}\\
        \ \cellcolor{blue!25}\textbf{\textit{GPT-2$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{ No, not about your \\ favourite club.}}\\
        \ \cellcolor{red!25}\textbf{\textit{DialoGPT$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{We have a meeting\\ in a bit.}}\\
        % \ \cellcolor{blue!25}\textbf{\textit{DialoGPT$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{What I can't.}}\\
        % \hline
        \ \cellcolor{blue!25}\textbf{\textit{DialoGPT$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{We have a couple\\ more people \\interested!}}\\
        % \hline
        % \ \cellcolor{yellow!25}\textbf{\textit{PROMPT}} & \multicolumn{1}{>{\columncolor{yellow!10}}l}{\tabularCenterstack{l}{Good weather \\ we're having.}}\\
        % \hline 
        % \cellcolor{red!25}\textbf{\textit{GPT-2$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{ The Weather is nice,\\ the temperature cool,\\ the traffic good.}}\\
        % \ \cellcolor{blue!25}\textbf{\textit{GPT-2$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{The sun was setting\\ when we were\\ getting up with\\ a huge rain.}}\\
        % \ \cellcolor{red!25}\textbf{\textit{DialoGPT$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{Cold weather \\we can't handle it}}\\
        % % \ \cellcolor{blue!25}\textbf{\textit{DialoGPT$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{...}}\\
    \hline
    \end{tabular}}
    \caption{Low perplexity \& incorrectly classified.}\label{subtab:ctg_case_examples_low_ppl_incorrect}
    \end{subtable}%
    
    % \medskip
    % \begin{subtable}{0.5\linewidth}\centering
    % {\begin{tabular}{r l}
    % \hline
    %     \ \cellcolor{yellow!25}\textbf{\textit{PROMPT}} & \multicolumn{1}{>{\columncolor{yellow!10}}l}{\tabularCenterstack{l}{Good weather \\ we're having.}}\\
    %     \hline 
    %     \cellcolor{red!25}\textbf{\textit{GPT-2$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{...}}\\
    %     \ \cellcolor{blue!25}\textbf{\textit{GPT-2$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{ We'll have more \\next week! ((:}}\\
    %     \ \cellcolor{red!25}\textbf{\textit{DialoGPT$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{...}}\\
    %     \ \cellcolor{blue!25}\textbf{\textit{DialoGPT$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{...}}\\
    %     \hline
    %     \ \cellcolor{yellow!25}\textbf{\textit{PROMPT}} & \multicolumn{1}{>{\columncolor{yellow!10}}l}{\tabularCenterstack{l}{Hi, how's it going?}}\\
    %     \hline 
    %     \cellcolor{red!25}\textbf{\textit{GPT-2$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{...}}\\
    %     \ \cellcolor{blue!25}\textbf{\textit{GPT-2$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{ My wife and I are \\ about 2 weeks away \\ from, and \\ and.1I (I I (}}\\
    %     \ \cellcolor{red!25}\textbf{\textit{DialoGPT$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{...}}\\
    %     \ \cellcolor{blue!25}\textbf{\textit{DialoGPT$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{...}}\\
    % \hline
    % \end{tabular}}
    % \caption{High perplexity \& correctly classified.}\label{subtab:ctg_case_examples_high_ppl_correct}
    % \end{subtable}%
    % \begin{subtable}{0.5\linewidth}\centering
    % {\begin{tabular}{r l}
    % \hline
    %     \ \cellcolor{yellow!25}\textbf{\textit{PROMPT}} & \multicolumn{1}{>{\columncolor{yellow!10}}l}{\tabularCenterstack{l}{Good weather \\ we're having.}}\\
    %     \hline 
    %     \cellcolor{red!25}\textbf{\textit{GPT-2$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{...}}\\
    %     \ \cellcolor{blue!25}\textbf{\textit{GPT-2$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{...}}\\
    %     \ \cellcolor{red!25}\textbf{\textit{DialoGPT$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{...}}\\
    %     \ \cellcolor{blue!25}\textbf{\textit{DialoGPT$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{...}}\\
    %     \hline
    %     \ \cellcolor{yellow!25}\textbf{\textit{PROMPT}} & \multicolumn{1}{>{\columncolor{yellow!10}}l}{\tabularCenterstack{l}{Hello, tell me \\about your \\ latest holiday.}}\\
    %     \hline 
    %     \cellcolor{red!25}\textbf{\textit{GPT-2$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{...}}\\
    %     \ \cellcolor{blue!25}\textbf{\textit{GPT-2$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{...}}\\
    %     \ \cellcolor{red!25}\textbf{\textit{DialoGPT$_{Young}$}} & \multicolumn{1}{>{\columncolor{red!10}}l}{\tabularCenterstack{l}{...}}\\
    %     \ \cellcolor{blue!25}\textbf{\textit{DialoGPT$_{Old}$}} & \multicolumn{1}{>{\columncolor{blue!10}}l}{\tabularCenterstack{l}{...}}\\
    % \hline
    % \end{tabular}}
    % \caption{High perplexity \& incorrectly classified.}\label{subtab:ctg_case_examples_high_ppl_incorrect}
    % \end{subtable}%
\caption{Cherry-picked examples of low-perplexity young-targeted (red rows) and old-targeted (blue rows) responses to neutral prompts (yellow rows) generated by various PPLM-setups, and grouped by whether or not they were correctly classified by BERT$_{FT}$. High-perplexity samples are omitted due to excessive amounts of gibberish and nonsensical strings present in the samples. 
% Note that some combinations of cases and prompts there are responses, because either have not been generated or are nonsensical strings. 
Note that some combinations of cases and prompts do not show responses generated by all four models, because these responses are either all nonsensical strings, or simply do not exist.
The shown responses are chosen because they most clearly display the manually observed patterns described in this section.}\label{tab:ctg_case_examples}
\end{table}

Manual inspection of the sub-samples (i.e., high or low perplexity, and correctly or incorrectly classified) shows that correctly classified low-perplexity samples from models targeted towards the older age group use more formal and complex words than their younger targeted counterparts, e.g., \textit{quite}, \textit{significant}, \textit{powerful}, or \textit{institutions}. 
This observation is in line with the findings of \cite{pennebaker2003words}, which suggest that verbal indicators of cognitive abilities are expected to increase until mid-adulthood (see Section \ref{subsec:background_lang_age}).
Samples generated by these older targeted models also show recurring topics that are typically associated with older age, e.g., children (\textit{my son} or \textit{your daughter}), history, or politics. 
Responses about healthcare-related subjects are also more common among the samples generated by these models, as indicated by the use of words like \textit{surgery}. This pattern is also observed in the BoWs that are empirically extracted from older dialogues of the BNC dialogue dataset, reported in Section \ref{sec:wordlists}. When viewing high-perplexity samples from the same set of models (i.e., those that are correctly classified and target towards the older age group), there appears to be a substantial increase in the number of gibberish and nonsensical sequences (space-less sequences of words, repetitions of the same words, or sequences of punctuation marks). Inspection of the incorrectly classified samples from models targeted towards the older class, there is also a considerable increase in the number of nonsensical strings. Remarkably, there also seem to be more linguistic patterns associated with younger age in this sub-sample, e.g., words of excitement like \textit{favourite} or \textit{best}, informal vocabulary (\textit{pretty much}).

The low-perplexity correctly classified samples generated by models targeted towards the younger age group also contain clear indications of their target age. Similar to the observations from the qualitative analysis of dialogue utterances in Section \ref{subsec:exp1_comparing_model_preds} and the findings of \cite{schler2006effects} relating to similar age groups, for the younger targeted models, there appears to be more usage of slang words, neologisms, swear words, and informal language, like \textit{yeah}, \textit{dude}, \textit{cool}, \textit{kinda}, and \textit{lol}. 
% The use of the word \textit{like} as a colloquial adverb, quotative, or filler is also more commonplace among the young-targeted models. \len{Add good examples of use of \textit{like} or remove sentence.} 
Furthermore, these sub-samples are also characterized by increased use of words of excitement and exclamation: e.g., \textit{awesome}, \textit{really}, \textit{love}, \textit{fun}, or \textit{amazing}. Especially in the correctly classified low-perplexity responses generated by G-Discrim$_{Young}$, it can be seen that there is a strong presence of topics such as dating (indicated by words such as \textit{girlfriend} or \textit{boyfriend)}, having parents (\textit{my dad}), parties, and student life (\textit{roommate}). An interesting pattern observed in this sub-sample is one often associated with millennial or social networking language: the tendency to end a (serious-sounding) statement with \textit{lol} or \textit{haha} as a means of softening the perceived severity of the statement or as a signal of interlocutor involvement \citep{newitz2019you, tagliamonte2008linguistic}. For example, \textit{We have to stop talking about this all going so stupid lol lol}. When inspecting the high-perplexity and/or incorrectly classified samples generated by the younger targeted models, similar patterns are observed. Namely, a substantial increase in non-alphabetical strings, and gibberish.

When comparing the samples from GPT-2 and DialoGPT-based models, it can be seen that the responses generated by DialoGPT are more dialogic, whereas GPT-2 sometimes generates sequences that look more like sentence completions. This is to be expected based on the differences in pre-training methods between the two language models \citep{zhang2019dialogpt}. Furthermore, there appear to be a lot more nonsensical low-perplexity responses generated by DialoGPT-based models. Perplexity remains a rough proxy for fluency, and observations like these confirm this problem. That is, low perplexity often does not imply lack of gibberish or nonsense. DialoGPT's strong bias towards generating younger sounding language is also noticeable in its generated samples. For example, DialoGPT-based models targeted towards the older group still produce lots of words of excitement. However, this older targeted DialoGPT-based model does succeed in producing significantly fewer usages of slang or swear words, when compared to its younger targeted counterpart.


% \subsubsection{Qualitative 2: Human evaluation of fluency, grammaticality, and relevancy}

% \begin{itemize}
%     \item \textit{Generate and sample text passages for a variety of model-configurations and age-groups.}
%     \item \textit{Have a group of human participants rate these sequences on a scale from 1 to 5 for their (1) fluency, (2) grammaticality, (3) relevance to the prompt (if there is one)}
%     \item \textit{Average the ratings, and compare the human evaluation metrics to the automated evaluation metrics reported in Table \ref{tab:ctg_results_ws}}
% \end{itemize}



\begin{table}[H]
    \centering
    \resizebox{\linewidth}{!}{
    \rowcolors{2}{gray!25}{white}
    \begin{tabular}{@{}l  c  c  c  c  c  c @{}}
    \toprule
    \rowcolor{white}
    \textbf{model} & \textbf{low ppl. | \cmark} & \textbf{low ppl. | \xmark} & \textbf{med ppl. | \cmark} & \textbf{med ppl. | \xmark} & \textbf{high ppl. | \cmark} & \textbf{high ppl. | \xmark}\\
    \midrule
    G-BoW$_{Young}$ & 48.0\% & 15.6\% & 15.6\% & 10.4\% & 6.7\% & 3.7\%\\
    G-BoW$_{Old}$ & 25.6\% & 37.7\% & 11.9\% & 14.8\% & 5.6\% & 4.4\%\\
    G-Discrim$_{Young}$ & 33.3\% & 15.9\% & 17.4\% & 8.5\% & 17.0\% & 7.9\%\\
    G-Discrim$_{Old}$ & 23.8\% & 18.2\% & 13.4\% & 3.3\% & 37.2\% & 4.1\%\\
    D-BoW$_{Young}$ & 5.2\% & 0.4\% & 40.0\% & 5.2\% & 43.3\% & 5.9\%\\
    D-BoW$_{Old}$ & 3.0\% & 5.9\% & 10.4\% & 35.2\% & 8.5\% & 37.0\%\\
    D-Discrim$_{Young}$ & 5.9\% & 2.7\% & 23.0\% & 5.6\% & 56.9\% & 5.9\%\\
    D-Discrim$_{Old}$ & 7.0\% & 4.1\% & 19.3\% & 11.5\% & 30.3\% & 27.8\%\\\bottomrule
    \end{tabular}
    }
    \vspace{2mm}
    \caption{Distribution of dialogue responses generated by various PPLM-setups (under the \textbf{model} column) into categories of low, medium, or high perplexity, and whether or not they are correctly classified as their target age group by BERT$_{FT}$ (\cmark: correctly classified, \xmark: incorrectly classified). Alternating row colors are for readability and bear no meaning.}
    % \caption{Percentages of (non-)overlapping (in)correctly predicted cases between trigram and BERT$_{FT}$ models for BNC. *Pre-processed sequence length is measured in tokens.}
    \label{tab:ctg_model_case_pcts}
\end{table}

% \begin{table*}[h]
% \resizebox{\linewidth}{!}{
% % \small
% \begin{tabular}{@{}lllll@{}}
% \toprule
% \bf age & \bf both correct                & \bf both wrong                 & \bf BERT$_{FT}$ correct | trigram wrong                              & \bf trigram correct | BERT$_{FT}$ wrong                                                            \\ \midrule
% 19-29     & oh that's cool              & A retrospective exhibition & what even on the green slope?             & really?                                                                    \\
% 19-29     & a text and then I'll do it  & chuck them in those pots   & yeah you told me to do you told me to do  & and she like won't eat any carbs and she's like                            \\
% 19-29     & yeah                        & mm                         & somebody made the f***ing table           & do you not like total greens? \\ \midrule
% % well er it's not acceptable just to ditch \textless{}unclear\textgreater{} \\ \hline
% 50+       & I said no I don't have them & yeah                       & really?                                   & my under stairs in the kitchen                                             \\
% 50+       & that's of course            & no no that's alright       & it's still I I frequently walk that way & in the first place                                                         \\
% 50+       & oh right                    & what a tragic life         & since this this was new this house?       & thank you very much                                                        \\ \bottomrule
% \end{tabular}
% }
% \caption{Examples
% % cherry-picked examples per age group 
% where both models are correct/wrong or only BERT$_{FT}$/trigram is correct.}\label{tab:qualexamples}
% \end{table*}

% Qualitative inspection focuses on low versus high perplexity (i.e., medium perplexity is omitted, both for feasibility (in total Table \ref{tab:ctg_model_case_pcts} describes 48 sets of responses), and only responses generated by the discriminator-based model with the highest target prob. gaing over baseline (compared to its age-opposite counterpart): so that's GPT-2 Discrim old vs. young. And the same for BoW

% \len{\textbf{Observations in a few of the best performing models:}}

% \begin{itemize}
%     \item GPT2 | Discrim-O | Low ppl | BERT correct:
%     \begin{itemize}
%         \item Not very dialogic 
%         \item Use of larger words like "significant", "powerful", "institutions"
%         \item Talks about "my son" and children
%         \item Talks about work.
%         \item Talks about hospitals, surgery, health care (which is to be expected if you look at the old-wordlists)
%         \item Older slang words "quite"
%         \item Talks about history and politics.
%     \end{itemize}
%     \item GPT2 | Discrim-O | Low ppl | BERT incorrect:
%     \begin{itemize}
%         \item Despite low GPT-1 perplexity, considerably more gibberish that BERT-correct counterpart, space-less repetitions of words mostly though, not nonsensical sequences of characters. First of all, this makes a case for a different proxy for fluency (find different measures to consider for future research, and/or suggest human evaluation).
%         \item The non-gibberish responses contain more words of excitement and positive sentiment "favourite", "best".
%         \item Gibberish most likely obfuscates BERT, hence worse prediction.
%         \item Talks about football clubs and premier league
%         \item Younger sounding slang "pretty much"
%         \item PPLM-discrim old (BERT incorrect) nonsense pattern is lots of punctuation marks, parentheses, and words without spaces.
%     \end{itemize}
%     \item GPT2 | Discrim-O | High ppl | BERT correct:
%     \begin{itemize}
%         \item Predominantly gibberish. 
%         Many sequences of non-alphabetical characters/punctuation marks (parentheses, apostrophes, etc. )
%         \item When non-gibberish, does talk about "my wife" and "work"
%     \end{itemize}
%     \item GPT2 | Discrim-O | High ppl | BERT incorrect:
%     \begin{itemize}
%         \item Very small subset (see Table \ref{tab:ctg_model_case_pcts}, and earlier plots about this model having a clear tradeoff between perplexity and target prob)
%         \item Mostly difluencies
%         \item Formal words like "precious"
%     \end{itemize}
%     \item GPT2 | Discrim-Y | Low ppl | BERT correct:
%     \begin{itemize}
%         \item Substantially more use of younger sounding slang words: "yeah", "dude", "cool", "awesome", "like", "kinda", "hot", "horny", "gonna", "lol". NB: "yeah" was also picked up by the trigram in Chapter 3 (make proper reference) to be strongly indicative of younger language
%         \item More swear words "fucking", "shit", "dick", "hell"
%         \item More words of excitement "awesome" "really" "love", "fun", "amazing"
%         \item More talk about dating "girlfriend", "boyfriend", "horny", "sex"
%         \item More talk about depression and anxiety
%         \item More tech-talk
%         \item Lots of disfluency and repetition though.
%         \item Talks about dancing and parties
%         \item Interesting pattern of millennial language: uttering something serious, but ending with a neutralizing, tension-breaking humoring expression, e.g., ``I have to stop talking about this all going so stupid lol lol.'' ``Shit just got weird LOL."
%         \item More topics that relate to student-life: roommate, parties, drinking, bars, clubs, tv series on Netflix
%     \end{itemize}
%     \item GPT2 | Discrim-Y | Low ppl | BERT incorrect:
%     \begin{itemize}
%         \item Considerably more nonsense than the BERT-correct counterpart. 
%         \item More non-language sequences of characters, \texttt{<|endoftext|>} tokens.
%         \item Similar word-use and topics: tv series (HBO Game of Thrones), swear words, "mom" and "dad(dy)"/
%         \item PPLM-discrim young (BERT incorrect) nonsense pattern is lots of \texttt{<|endoftext|>} tokens.
%     \end{itemize}
%     \item GPT2 | Discrim-Y | High ppl | BERT correct:
%     \begin{itemize}
%         \item Substantially more nonsense, disfluency, gibberish, non-alphabetical characters.
%         \item Similar patterns to low-perplexity counterpart. Actually same patterns, but with much more nonsense.
%     \end{itemize}
%     \item GPT2 | Discrim-Y | High ppl | BERT incorrect:
%     \begin{itemize}
%         \item Very small subset (look at Table \ref{tab:ctg_model_case_pcts} and perplexity-targetprob plots).
%         \item Same patterns
%         \item Mostly nonsense.
%     \end{itemize}
%     \item DialoGPT | Discrim-O | Low ppl | BERT correct:
%     \begin{itemize}
%         \item Very small subset (See table and graph).
%         \item Talks about surgery, hospital etc.
%         \item Talks about daughters.
%         \item Almost no slang words
%         \item More formal language, and complete sentences.
%         \item Quite some nonsense
%     \end{itemize}
%     \item DialoGPT | Discrim-O | Low ppl | BERT incorrect:
%     \begin{itemize}
%         \item Very small subset (See table and graph).
%         \item A lot of nonsense, repeated eot tokens.
%         \item Pretty much similar patterns to setup above.
%     \end{itemize}
%     \item DialoGPT | Discrim-O | High ppl | BERT correct:
%     \begin{itemize}
%         \item Lots of gibberish
%         \item Noticeably, a lot less typically "older" sounding language than GPT-2 counterpart. Which makes sense when you look at the difference in target probabilities.
%         \item More words of excitement and exclamation than other old discrim model. Likely due to DialoGPT's young-bias.
%         \item Barely any slang or swear words.
%         \item Pretty neat formal sentences when not gibberish.
%     \end{itemize}
%     \item DialoGPT | Discrim-O | High ppl | BERT incorrect:
%     \begin{itemize}
%         \item A lot more nonsensical/non-language sequences of characters.
%         \item Talks about days off from work
%         \item words like ``quite'', ``glad''
%         \item talks about other people's parents and children.
%     \end{itemize}
%     \item DialoGPT | Discrim-Y | Low ppl | BERT correct:
%     \begin{itemize}
%         \item Very small sample size
%         \item More informal language "gonna"
%         \item Talks about gifs and comments
%     \end{itemize}
%     \item DialoGPT | Discrim-Y | Low ppl | BERT incorrect:
%     \begin{itemize}
%         \item Predominantly nonsensical sequences.
%         \item Repetitions of words
%         \item No slang, or words of excitement or other clear giveaways of young language.
%         \item Very small sample size.
%     \end{itemize}
%     \item DialoGPT | Discrim-Y | High ppl | BERT correct:
%     \begin{itemize}
%         \item Lots of words of excitement and exclamation marks
%         \item slang and informal words: "dude", "buddy", "cool", referring to the basketball team, the Cleveland Cavalliers, as the "Cavs", "howdy"
%         \item Talks about going on vacation to the beach with friends.
%         \item Uses the word "like"
%         \item Uses emojis ":P", ":D"
%         \item Fair amount of gibberish.
%     \end{itemize}
%     \item DialoGPT | Discrim-Y | High ppl | BERT incorrect:
%     \begin{itemize}
%         \item Mostly gibberish.
%         \item Similar patterns to BERT-correct counterpart, just way more nonsense.
%     \end{itemize}
% \end{itemize}

% Overall, the GPT-2 ones are also often sentence completions, and not as often rebuttals as DialoGPT. This is understandable from the point of view of how the models have been pre-trained.